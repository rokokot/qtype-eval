SLURM_JOB_ID: 58113934
SLURM_JOB_USER: vsc37132
SLURM_JOB_ACCOUNT: intro_vsc37132
SLURM_JOB_NAME: arabic_sweep
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r24g37
SLURM_JOB_CPUS_PER_NODE: 3
SLURM_JOB_GPUS: 2
Date: Tue Apr 29 18:38:30 CEST 2025
Walltime: 00-06:00:00
========================================================================
Channels:
 - pytorch
 - nvidia
 - defaults
Platform: linux-64
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done


==> WARNING: A newer version of conda exists. <==
    current version: 25.1.1
    latest version: 25.3.1

Please update conda by running

    $ conda update -n base -c defaults conda



# All requested packages already installed.

Requirement already satisfied: hydra-core in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (1.3.2)
Requirement already satisfied: hydra-submitit-launcher in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (1.2.0)
Requirement already satisfied: omegaconf<2.4,>=2.2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from hydra-core) (2.3.0)
Requirement already satisfied: antlr4-python3-runtime==4.9.* in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from hydra-core) (4.9.3)
Requirement already satisfied: packaging in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from hydra-core) (24.2)
Requirement already satisfied: submitit>=1.3.3 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from hydra-submitit-launcher) (1.5.2)
Requirement already satisfied: PyYAML>=5.1.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)
Requirement already satisfied: cloudpickle>=1.2.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from submitit>=1.3.3->hydra-submitit-launcher) (3.1.1)
Requirement already satisfied: typing_extensions>=3.7.4.2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from submitit>=1.3.3->hydra-submitit-launcher) (4.12.2)
Requirement already satisfied: transformers<4.36.0,>=4.30.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (4.35.2)
Requirement already satisfied: torch in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (2.5.1)
Requirement already satisfied: datasets in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (3.5.0)
Requirement already satisfied: wandb in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (0.19.9)
Requirement already satisfied: filelock in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (3.18.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (0.30.1)
Requirement already satisfied: numpy>=1.17 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (24.2)
Requirement already satisfied: pyyaml>=5.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (2024.11.6)
Requirement already satisfied: requests in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (2.32.3)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (0.15.2)
Requirement already satisfied: safetensors>=0.3.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (0.5.3)
Requirement already satisfied: tqdm>=4.27 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from transformers<4.36.0,>=4.30.0) (4.67.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from torch) (4.12.2)
Requirement already satisfied: networkx in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from torch) (3.2.1)
Requirement already satisfied: jinja2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from torch) (2024.12.0)
Requirement already satisfied: sympy==1.13.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from torch) (1.13.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)
Requirement already satisfied: pyarrow>=15.0.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (19.0.1)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (2.2.3)
Requirement already satisfied: xxhash in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (0.70.16)
Requirement already satisfied: aiohttp in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from datasets) (3.11.16)
Requirement already satisfied: click!=8.0.0,>=7.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (8.1.8)
Requirement already satisfied: docker-pycreds>=0.4.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (0.4.0)
Requirement already satisfied: eval-type-backport in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (0.2.2)
Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (3.1.44)
Requirement already satisfied: platformdirs in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (4.3.7)
Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (5.29.4)
Requirement already satisfied: psutil>=5.0.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (7.0.0)
Requirement already satisfied: pydantic<3 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (2.11.1)
Requirement already satisfied: sentry-sdk>=2.0.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (2.25.0)
Requirement already satisfied: setproctitle in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (1.3.5)
Requirement already satisfied: setuptools in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from wandb) (78.1.0)
Requirement already satisfied: six>=1.4.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.1.2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)
Requirement already satisfied: async-timeout<6.0,>=4.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)
Requirement already satisfied: attrs>=17.3.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (6.3.1)
Requirement already satisfied: propcache>=0.2.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from aiohttp->datasets) (1.18.3)
Requirement already satisfied: gitdb<5,>=4.0.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)
Requirement already satisfied: annotated-types>=0.6.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)
Requirement already satisfied: pydantic-core==2.33.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pydantic<3->wandb) (2.33.0)
Requirement already satisfied: typing-inspection>=0.4.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from requests->transformers<4.36.0,>=4.30.0) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from requests->transformers<4.36.0,>=4.30.0) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from requests->transformers<4.36.0,>=4.30.0) (2.3.0)
Requirement already satisfied: certifi>=2017.4.17 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from requests->transformers<4.36.0,>=4.30.0) (2025.4.26)
Requirement already satisfied: MarkupSafe>=2.0 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: python-dateutil>=2.8.2 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: smmap<6,>=3.0.1 in /vsc-hard-mounts/leuven-data/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:39:34,231][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs8
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs8
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 8
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 1
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:39:34,232][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:39:34,232][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:39:34,232][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:39:34,236][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:39:34,237][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:39:35,739][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:39:38,456][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:39:38,456][src.data.datasets][INFO] - Loading 'control_question_type_seed1' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:39:38,576][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:39:38,626][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:39:38,776][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:39:38,785][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:39:38,786][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:39:38,787][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:39:38,801][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:39:38,831][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:39:38,842][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:39:38,843][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:39:38,843][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:39:38,844][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:39:38,868][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:39:38,900][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:39:38,910][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:39:38,911][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:39:38,912][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:39:38,912][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:39:38,913][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:39:38,913][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:39:38,913][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:39:38,913][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:39:38,913][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:39:38,914][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:39:38,914][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:39:38,914][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:39:38,915][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:39:38,915][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:39:38,915][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:39:38,916][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:39:38,916][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:39:38,916][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:39:38,916][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:39:38,916][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:39:38,918][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:39:38,919][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:39:43,024][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:39:43,025][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:39:43,026][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:39:43,026][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:39:43,026][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   1%|          | 1/125 [00:00<01:51,  1.11it/s]Epoch 1/10:   4%|▍         | 5/125 [00:01<00:19,  6.15it/s]Epoch 1/10:   7%|▋         | 9/125 [00:01<00:10, 10.97it/s]Epoch 1/10:  10%|█         | 13/125 [00:01<00:07, 15.28it/s]Epoch 1/10:  14%|█▎        | 17/125 [00:01<00:05, 18.96it/s]Epoch 1/10:  17%|█▋        | 21/125 [00:01<00:04, 21.95it/s]Epoch 1/10:  20%|██        | 25/125 [00:01<00:04, 24.31it/s]Epoch 1/10:  23%|██▎       | 29/125 [00:01<00:03, 26.09it/s]Epoch 1/10:  26%|██▋       | 33/125 [00:01<00:03, 27.42it/s]Epoch 1/10:  30%|██▉       | 37/125 [00:02<00:03, 28.38it/s]Epoch 1/10:  33%|███▎      | 41/125 [00:02<00:02, 29.08it/s]Epoch 1/10:  36%|███▌      | 45/125 [00:02<00:02, 29.54it/s]Epoch 1/10:  39%|███▉      | 49/125 [00:02<00:02, 29.89it/s]Epoch 1/10:  42%|████▏     | 53/125 [00:02<00:02, 30.16it/s]Epoch 1/10:  46%|████▌     | 57/125 [00:02<00:02, 30.35it/s]Epoch 1/10:  49%|████▉     | 61/125 [00:02<00:02, 30.49it/s]Epoch 1/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.58it/s]Epoch 1/10:  55%|█████▌    | 69/125 [00:03<00:01, 30.65it/s]Epoch 1/10:  58%|█████▊    | 73/125 [00:03<00:01, 30.71it/s]Epoch 1/10:  62%|██████▏   | 77/125 [00:03<00:01, 30.74it/s]Epoch 1/10:  65%|██████▍   | 81/125 [00:03<00:01, 30.77it/s]Epoch 1/10:  68%|██████▊   | 85/125 [00:03<00:01, 30.78it/s]Epoch 1/10:  71%|███████   | 89/125 [00:03<00:01, 30.78it/s]Epoch 1/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.79it/s]Epoch 1/10:  78%|███████▊  | 97/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  81%|████████  | 101/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  84%|████████▍ | 105/125 [00:04<00:00, 30.81it/s]Epoch 1/10:  87%|████████▋ | 109/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  90%|█████████ | 113/125 [00:04<00:00, 30.81it/s]Epoch 1/10:  94%|█████████▎| 117/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.84it/s]Epoch 1/10: 100%|██████████| 125/125 [00:04<00:00, 32.15it/s]Epoch 1/10: 100%|██████████| 125/125 [00:04<00:00, 25.21it/s]
[2025-04-29 18:39:50,180][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6971
[2025-04-29 18:39:50,481][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6856, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   1%|          | 1/125 [00:00<00:15,  7.83it/s]Epoch 2/10:   4%|▍         | 5/125 [00:00<00:05, 21.36it/s]Epoch 2/10:   7%|▋         | 9/125 [00:00<00:04, 25.69it/s]Epoch 2/10:  10%|█         | 13/125 [00:00<00:04, 27.71it/s]Epoch 2/10:  14%|█▎        | 17/125 [00:00<00:03, 28.83it/s]Epoch 2/10:  17%|█▋        | 21/125 [00:00<00:03, 29.50it/s]Epoch 2/10:  20%|██        | 25/125 [00:00<00:03, 29.92it/s]Epoch 2/10:  23%|██▎       | 29/125 [00:01<00:03, 30.19it/s]Epoch 2/10:  26%|██▋       | 33/125 [00:01<00:03, 30.35it/s]Epoch 2/10:  30%|██▉       | 37/125 [00:01<00:02, 30.50it/s]Epoch 2/10:  33%|███▎      | 41/125 [00:01<00:02, 30.58it/s]Epoch 2/10:  36%|███▌      | 45/125 [00:01<00:02, 30.64it/s]Epoch 2/10:  39%|███▉      | 49/125 [00:01<00:02, 30.68it/s]Epoch 2/10:  42%|████▏     | 53/125 [00:01<00:02, 30.71it/s]Epoch 2/10:  46%|████▌     | 57/125 [00:01<00:02, 30.73it/s]Epoch 2/10:  49%|████▉     | 61/125 [00:02<00:02, 30.74it/s]Epoch 2/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.78it/s]Epoch 2/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.78it/s]Epoch 2/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.79it/s]Epoch 2/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.78it/s]Epoch 2/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  71%|███████   | 89/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.78it/s]Epoch 2/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  81%|████████  | 101/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.79it/s]Epoch 2/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  90%|█████████ | 113/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.80it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 32.15it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 29.91it/s]
[2025-04-29 18:39:55,220][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6975
[2025-04-29 18:39:55,527][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6861, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   1%|          | 1/125 [00:00<00:15,  7.82it/s]Epoch 3/10:   4%|▍         | 5/125 [00:00<00:05, 21.28it/s]Epoch 3/10:   7%|▋         | 9/125 [00:00<00:04, 25.56it/s]Epoch 3/10:  10%|█         | 13/125 [00:00<00:04, 27.58it/s]Epoch 3/10:  14%|█▎        | 17/125 [00:00<00:03, 28.69it/s]Epoch 3/10:  17%|█▋        | 21/125 [00:00<00:03, 29.35it/s]Epoch 3/10:  20%|██        | 25/125 [00:00<00:03, 29.78it/s]Epoch 3/10:  23%|██▎       | 29/125 [00:01<00:03, 30.06it/s]Epoch 3/10:  26%|██▋       | 33/125 [00:01<00:03, 30.25it/s]Epoch 3/10:  30%|██▉       | 37/125 [00:01<00:02, 30.37it/s]Epoch 3/10:  33%|███▎      | 41/125 [00:01<00:02, 30.49it/s]Epoch 3/10:  36%|███▌      | 45/125 [00:01<00:02, 30.58it/s]Epoch 3/10:  39%|███▉      | 49/125 [00:01<00:02, 30.65it/s]Epoch 3/10:  42%|████▏     | 53/125 [00:01<00:02, 30.69it/s]Epoch 3/10:  46%|████▌     | 57/125 [00:01<00:02, 30.72it/s]Epoch 3/10:  49%|████▉     | 61/125 [00:02<00:02, 30.75it/s]Epoch 3/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.76it/s]Epoch 3/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.77it/s]Epoch 3/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.77it/s]Epoch 3/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.78it/s]Epoch 3/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.79it/s]Epoch 3/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.78it/s]Epoch 3/10:  71%|███████   | 89/125 [00:02<00:01, 30.79it/s]Epoch 3/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.78it/s]Epoch 3/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.78it/s]Epoch 3/10:  81%|████████  | 101/125 [00:03<00:00, 30.79it/s]Epoch 3/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.79it/s]Epoch 3/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.79it/s]Epoch 3/10:  90%|█████████ | 113/125 [00:03<00:00, 30.79it/s]Epoch 3/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.79it/s]Epoch 3/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.81it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 32.16it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 29.86it/s]
[2025-04-29 18:39:59,717][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6961
[2025-04-29 18:40:00,027][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6868, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   1%|          | 1/125 [00:00<00:16,  7.42it/s]Epoch 4/10:   4%|▍         | 5/125 [00:00<00:05, 20.88it/s]Epoch 4/10:   7%|▋         | 9/125 [00:00<00:04, 25.35it/s]Epoch 4/10:  10%|█         | 13/125 [00:00<00:04, 27.48it/s]Epoch 4/10:  14%|█▎        | 17/125 [00:00<00:03, 28.64it/s]Epoch 4/10:  17%|█▋        | 21/125 [00:00<00:03, 29.34it/s]Epoch 4/10:  20%|██        | 25/125 [00:00<00:03, 29.80it/s]Epoch 4/10:  23%|██▎       | 29/125 [00:01<00:03, 30.11it/s]Epoch 4/10:  26%|██▋       | 33/125 [00:01<00:03, 30.32it/s]Epoch 4/10:  30%|██▉       | 37/125 [00:01<00:02, 30.47it/s]Epoch 4/10:  33%|███▎      | 41/125 [00:01<00:02, 30.57it/s]Epoch 4/10:  36%|███▌      | 45/125 [00:01<00:02, 30.63it/s]Epoch 4/10:  39%|███▉      | 49/125 [00:01<00:02, 30.67it/s]Epoch 4/10:  42%|████▏     | 53/125 [00:01<00:02, 30.71it/s]Epoch 4/10:  46%|████▌     | 57/125 [00:01<00:02, 30.74it/s]Epoch 4/10:  49%|████▉     | 61/125 [00:02<00:02, 30.76it/s]Epoch 4/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.77it/s]Epoch 4/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.77it/s]Epoch 4/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.77it/s]Epoch 4/10:  71%|███████   | 89/125 [00:02<00:01, 30.77it/s]Epoch 4/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.77it/s]Epoch 4/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.76it/s]Epoch 4/10:  81%|████████  | 101/125 [00:03<00:00, 30.76it/s]Epoch 4/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.77it/s]Epoch 4/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.77it/s]Epoch 4/10:  90%|█████████ | 113/125 [00:03<00:00, 30.77it/s]Epoch 4/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.77it/s]Epoch 4/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.80it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 32.14it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 29.85it/s]
[2025-04-29 18:40:04,218][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6946
[2025-04-29 18:40:04,529][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6873, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:40:04,530][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss ▇█▅▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68564
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69456
wandb:           train_time 19.31035
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.6873
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_183934-qckojcrk
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_183934-qckojcrk/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs8 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs16
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:40:23,890][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs16
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs16
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 16
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 1
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:40:23,891][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:40:23,891][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:40:23,891][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:40:23,895][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:40:23,895][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:40:25,075][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:40:27,777][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:40:27,778][src.data.datasets][INFO] - Loading 'control_question_type_seed1' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:40:27,816][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:40:27,845][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:40:27,900][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:40:27,910][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:40:27,911][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:40:27,911][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:40:27,926][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:40:27,945][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:40:27,955][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:40:27,957][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:40:27,957][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:40:27,957][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:40:27,981][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:40:28,010][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:40:28,020][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:40:28,021][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:40:28,021][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:40:28,022][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:40:28,023][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:40:28,023][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:40:28,023][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:40:28,023][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:40:28,023][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:40:28,023][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:40:28,024][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:40:28,024][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:40:28,025][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:40:28,025][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:40:28,025][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:40:28,026][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:40:28,026][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:40:28,026][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:40:28,026][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:40:28,026][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:40:28,040][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:40:28,040][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:40:32,025][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:40:32,026][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:40:32,027][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:40:32,027][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:40:32,027][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   2%|▏         | 1/63 [00:00<00:58,  1.05it/s]Epoch 1/10:   5%|▍         | 3/63 [00:01<00:17,  3.48it/s]Epoch 1/10:   8%|▊         | 5/63 [00:01<00:09,  5.95it/s]Epoch 1/10:  11%|█         | 7/63 [00:01<00:06,  8.30it/s]Epoch 1/10:  14%|█▍        | 9/63 [00:01<00:05, 10.42it/s]Epoch 1/10:  17%|█▋        | 11/63 [00:01<00:04, 12.22it/s]Epoch 1/10:  21%|██        | 13/63 [00:01<00:03, 13.68it/s]Epoch 1/10:  24%|██▍       | 15/63 [00:01<00:03, 14.83it/s]Epoch 1/10:  27%|██▋       | 17/63 [00:01<00:02, 15.70it/s]Epoch 1/10:  30%|███       | 19/63 [00:01<00:02, 16.38it/s]Epoch 1/10:  33%|███▎      | 21/63 [00:02<00:02, 16.85it/s]Epoch 1/10:  37%|███▋      | 23/63 [00:02<00:02, 17.18it/s]Epoch 1/10:  40%|███▉      | 25/63 [00:02<00:02, 17.42it/s]Epoch 1/10:  43%|████▎     | 27/63 [00:02<00:02, 17.59it/s]Epoch 1/10:  46%|████▌     | 29/63 [00:02<00:01, 17.75it/s]Epoch 1/10:  49%|████▉     | 31/63 [00:02<00:01, 17.82it/s]Epoch 1/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.87it/s]Epoch 1/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.95it/s]Epoch 1/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.95it/s]Epoch 1/10:  62%|██████▏   | 39/63 [00:03<00:01, 17.98it/s]Epoch 1/10:  65%|██████▌   | 41/63 [00:03<00:01, 17.97it/s]Epoch 1/10:  68%|██████▊   | 43/63 [00:03<00:01, 18.00it/s]Epoch 1/10:  71%|███████▏  | 45/63 [00:03<00:01, 17.98it/s]Epoch 1/10:  75%|███████▍  | 47/63 [00:03<00:00, 18.00it/s]Epoch 1/10:  78%|███████▊  | 49/63 [00:03<00:00, 18.00it/s]Epoch 1/10:  81%|████████  | 51/63 [00:03<00:00, 18.00it/s]Epoch 1/10:  84%|████████▍ | 53/63 [00:03<00:00, 18.03it/s]Epoch 1/10:  87%|████████▋ | 55/63 [00:03<00:00, 18.00it/s]Epoch 1/10:  90%|█████████ | 57/63 [00:04<00:00, 18.02it/s]Epoch 1/10:  94%|█████████▎| 59/63 [00:04<00:00, 18.00it/s]Epoch 1/10:  97%|█████████▋| 61/63 [00:04<00:00, 18.02it/s]Epoch 1/10: 100%|██████████| 63/63 [00:04<00:00, 14.36it/s]
[2025-04-29 18:40:39,269][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6984
[2025-04-29 18:40:39,535][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   2%|▏         | 1/63 [00:00<00:09,  6.78it/s]Epoch 2/10:   5%|▍         | 3/63 [00:00<00:04, 12.58it/s]Epoch 2/10:   8%|▊         | 5/63 [00:00<00:03, 14.86it/s]Epoch 2/10:  11%|█         | 7/63 [00:00<00:03, 16.07it/s]Epoch 2/10:  14%|█▍        | 9/63 [00:00<00:03, 16.74it/s]Epoch 2/10:  17%|█▋        | 11/63 [00:00<00:03, 17.16it/s]Epoch 2/10:  21%|██        | 13/63 [00:00<00:02, 17.44it/s]Epoch 2/10:  24%|██▍       | 15/63 [00:00<00:02, 17.61it/s]Epoch 2/10:  27%|██▋       | 17/63 [00:01<00:02, 17.77it/s]Epoch 2/10:  30%|███       | 19/63 [00:01<00:02, 17.82it/s]Epoch 2/10:  33%|███▎      | 21/63 [00:01<00:02, 17.88it/s]Epoch 2/10:  37%|███▋      | 23/63 [00:01<00:02, 17.89it/s]Epoch 2/10:  40%|███▉      | 25/63 [00:01<00:02, 17.94it/s]Epoch 2/10:  43%|████▎     | 27/63 [00:01<00:02, 17.96it/s]Epoch 2/10:  46%|████▌     | 29/63 [00:01<00:01, 17.97it/s]Epoch 2/10:  49%|████▉     | 31/63 [00:01<00:01, 17.98it/s]Epoch 2/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.98it/s]Epoch 2/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.99it/s]Epoch 2/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.98it/s]Epoch 2/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.99it/s]Epoch 2/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.99it/s]Epoch 2/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.99it/s]Epoch 2/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.98it/s]Epoch 2/10:  75%|███████▍  | 47/63 [00:02<00:00, 18.00it/s]Epoch 2/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.99it/s]Epoch 2/10:  81%|████████  | 51/63 [00:02<00:00, 18.02it/s]Epoch 2/10:  84%|████████▍ | 53/63 [00:03<00:00, 18.00it/s]Epoch 2/10:  87%|████████▋ | 55/63 [00:03<00:00, 18.01it/s]Epoch 2/10:  90%|█████████ | 57/63 [00:03<00:00, 18.00it/s]Epoch 2/10:  94%|█████████▎| 59/63 [00:03<00:00, 18.02it/s]Epoch 2/10:  97%|█████████▋| 61/63 [00:03<00:00, 18.02it/s]Epoch 2/10: 100%|██████████| 63/63 [00:03<00:00, 17.52it/s]
[2025-04-29 18:40:43,704][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6972
[2025-04-29 18:40:43,985][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   2%|▏         | 1/63 [00:00<00:09,  6.38it/s]Epoch 3/10:   5%|▍         | 3/63 [00:00<00:04, 12.20it/s]Epoch 3/10:   8%|▊         | 5/63 [00:00<00:03, 14.59it/s]Epoch 3/10:  11%|█         | 7/63 [00:00<00:03, 15.86it/s]Epoch 3/10:  14%|█▍        | 9/63 [00:00<00:03, 16.58it/s]Epoch 3/10:  17%|█▋        | 11/63 [00:00<00:03, 17.07it/s]Epoch 3/10:  21%|██        | 13/63 [00:00<00:02, 17.34it/s]Epoch 3/10:  24%|██▍       | 15/63 [00:00<00:02, 17.55it/s]Epoch 3/10:  27%|██▋       | 17/63 [00:01<00:02, 17.68it/s]Epoch 3/10:  30%|███       | 19/63 [00:01<00:02, 17.76it/s]Epoch 3/10:  33%|███▎      | 21/63 [00:01<00:02, 17.84it/s]Epoch 3/10:  37%|███▋      | 23/63 [00:01<00:02, 17.87it/s]Epoch 3/10:  40%|███▉      | 25/63 [00:01<00:02, 17.90it/s]Epoch 3/10:  43%|████▎     | 27/63 [00:01<00:02, 17.92it/s]Epoch 3/10:  46%|████▌     | 29/63 [00:01<00:01, 17.93it/s]Epoch 3/10:  49%|████▉     | 31/63 [00:01<00:01, 17.94it/s]Epoch 3/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.95it/s]Epoch 3/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.95it/s]Epoch 3/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.95it/s]Epoch 3/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.96it/s]Epoch 3/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.97it/s]Epoch 3/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.96it/s]Epoch 3/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.96it/s]Epoch 3/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.97it/s]Epoch 3/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.98it/s]Epoch 3/10:  81%|████████  | 51/63 [00:02<00:00, 17.99it/s]Epoch 3/10:  84%|████████▍ | 53/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.99it/s]Epoch 3/10:  90%|█████████ | 57/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  94%|█████████▎| 59/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  97%|█████████▋| 61/63 [00:03<00:00, 18.04it/s]Epoch 3/10: 100%|██████████| 63/63 [00:03<00:00, 17.43it/s]
[2025-04-29 18:40:48,194][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6979
[2025-04-29 18:40:48,484][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   2%|▏         | 1/63 [00:00<00:09,  6.21it/s]Epoch 4/10:   5%|▍         | 3/63 [00:00<00:04, 12.02it/s]Epoch 4/10:   8%|▊         | 5/63 [00:00<00:04, 14.48it/s]Epoch 4/10:  11%|█         | 7/63 [00:00<00:03, 15.79it/s]Epoch 4/10:  14%|█▍        | 9/63 [00:00<00:03, 16.55it/s]Epoch 4/10:  17%|█▋        | 11/63 [00:00<00:03, 17.03it/s]Epoch 4/10:  21%|██        | 13/63 [00:00<00:02, 17.34it/s]Epoch 4/10:  24%|██▍       | 15/63 [00:00<00:02, 17.55it/s]Epoch 4/10:  27%|██▋       | 17/63 [00:01<00:02, 17.68it/s]Epoch 4/10:  30%|███       | 19/63 [00:01<00:02, 17.78it/s]Epoch 4/10:  33%|███▎      | 21/63 [00:01<00:02, 17.84it/s]Epoch 4/10:  37%|███▋      | 23/63 [00:01<00:02, 17.89it/s]Epoch 4/10:  40%|███▉      | 25/63 [00:01<00:02, 17.91it/s]Epoch 4/10:  43%|████▎     | 27/63 [00:01<00:02, 17.93it/s]Epoch 4/10:  46%|████▌     | 29/63 [00:01<00:01, 17.94it/s]Epoch 4/10:  49%|████▉     | 31/63 [00:01<00:01, 17.96it/s]Epoch 4/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.96it/s]Epoch 4/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.97it/s]Epoch 4/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.97it/s]Epoch 4/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.98it/s]Epoch 4/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.98it/s]Epoch 4/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.99it/s]Epoch 4/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.99it/s]Epoch 4/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.99it/s]Epoch 4/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.99it/s]Epoch 4/10:  81%|████████  | 51/63 [00:02<00:00, 17.99it/s]Epoch 4/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.99it/s]Epoch 4/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.99it/s]Epoch 4/10:  90%|█████████ | 57/63 [00:03<00:00, 17.99it/s]Epoch 4/10:  94%|█████████▎| 59/63 [00:03<00:00, 18.00it/s]Epoch 4/10:  97%|█████████▋| 61/63 [00:03<00:00, 18.00it/s]Epoch 4/10: 100%|██████████| 63/63 [00:03<00:00, 17.38it/s]
[2025-04-29 18:40:52,111][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6976
[2025-04-29 18:40:52,401][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6886, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   2%|▏         | 1/63 [00:00<00:10,  6.01it/s]Epoch 5/10:   5%|▍         | 3/63 [00:00<00:05, 11.84it/s]Epoch 5/10:   8%|▊         | 5/63 [00:00<00:04, 14.36it/s]Epoch 5/10:  11%|█         | 7/63 [00:00<00:03, 15.69it/s]Epoch 5/10:  14%|█▍        | 9/63 [00:00<00:03, 16.48it/s]Epoch 5/10:  17%|█▋        | 11/63 [00:00<00:03, 16.98it/s]Epoch 5/10:  21%|██        | 13/63 [00:00<00:02, 17.30it/s]Epoch 5/10:  24%|██▍       | 15/63 [00:00<00:02, 17.52it/s]Epoch 5/10:  27%|██▋       | 17/63 [00:01<00:02, 17.66it/s]Epoch 5/10:  30%|███       | 19/63 [00:01<00:02, 17.76it/s]Epoch 5/10:  33%|███▎      | 21/63 [00:01<00:02, 17.82it/s]Epoch 5/10:  37%|███▋      | 23/63 [00:01<00:02, 17.87it/s]Epoch 5/10:  40%|███▉      | 25/63 [00:01<00:02, 17.91it/s]Epoch 5/10:  43%|████▎     | 27/63 [00:01<00:02, 17.92it/s]Epoch 5/10:  46%|████▌     | 29/63 [00:01<00:01, 17.94it/s]Epoch 5/10:  49%|████▉     | 31/63 [00:01<00:01, 17.95it/s]Epoch 5/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.96it/s]Epoch 5/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.96it/s]Epoch 5/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.98it/s]Epoch 5/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.98it/s]Epoch 5/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.98it/s]Epoch 5/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.98it/s]Epoch 5/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.99it/s]Epoch 5/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.98it/s]Epoch 5/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.97it/s]Epoch 5/10:  81%|████████  | 51/63 [00:02<00:00, 17.95it/s]Epoch 5/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.96it/s]Epoch 5/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.96it/s]Epoch 5/10:  90%|█████████ | 57/63 [00:03<00:00, 17.96it/s]Epoch 5/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.95it/s]Epoch 5/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.96it/s]Epoch 5/10: 100%|██████████| 63/63 [00:03<00:00, 17.34it/s]
[2025-04-29 18:40:56,037][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6980
[2025-04-29 18:40:56,316][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:40:56,317][src.training.lm_trainer][INFO] - Early stopping at epoch 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss █▁▅▃▅
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▂▁▃▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68839
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69799
wandb:           train_time 21.43796
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68873
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184023-9cb95dw5
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184023-9cb95dw5/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs16 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs32
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:41:15,615][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs32
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs32
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 32
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 1
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:41:15,615][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:41:15,615][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:41:15,615][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:41:15,620][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:41:15,620][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:41:17,571][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:41:20,260][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:41:20,261][src.data.datasets][INFO] - Loading 'control_question_type_seed1' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:41:20,358][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:41:20,390][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:41:20,494][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:41:20,504][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:41:20,505][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:41:20,505][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:41:20,519][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:41:20,558][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:41:20,568][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:41:20,569][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:41:20,570][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:41:20,570][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:41:20,586][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:41:20,606][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:41:20,616][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:41:20,617][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:41:20,617][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:41:20,618][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:41:20,618][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:41:20,619][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:41:20,619][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:41:20,619][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:41:20,619][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:41:20,619][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:41:20,619][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:41:20,619][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:41:20,620][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:41:20,620][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:41:20,620][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:41:20,621][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:41:20,621][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:41:20,621][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:41:20,621][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:41:20,621][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:41:20,621][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:41:20,621][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:41:20,622][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:41:20,622][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:41:20,622][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:41:20,625][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:41:20,625][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:41:25,046][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:41:25,047][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:41:25,048][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:41:25,048][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:41:25,048][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   3%|▎         | 1/32 [00:01<00:32,  1.03s/it]Epoch 1/10:   6%|▋         | 2/32 [00:01<00:14,  2.04it/s]Epoch 1/10:   9%|▉         | 3/32 [00:01<00:09,  3.15it/s]Epoch 1/10:  12%|█▎        | 4/32 [00:01<00:06,  4.26it/s]Epoch 1/10:  16%|█▌        | 5/32 [00:01<00:05,  5.27it/s]Epoch 1/10:  19%|█▉        | 6/32 [00:01<00:04,  6.16it/s]Epoch 1/10:  22%|██▏       | 7/32 [00:01<00:03,  6.90it/s]Epoch 1/10:  25%|██▌       | 8/32 [00:01<00:03,  7.49it/s]Epoch 1/10:  28%|██▊       | 9/32 [00:01<00:02,  7.94it/s]Epoch 1/10:  31%|███▏      | 10/32 [00:02<00:02,  8.28it/s]Epoch 1/10:  34%|███▍      | 11/32 [00:02<00:02,  8.53it/s]Epoch 1/10:  38%|███▊      | 12/32 [00:02<00:02,  8.72it/s]Epoch 1/10:  41%|████      | 13/32 [00:02<00:02,  8.84it/s]Epoch 1/10:  44%|████▍     | 14/32 [00:02<00:02,  8.93it/s]Epoch 1/10:  47%|████▋     | 15/32 [00:02<00:01,  8.99it/s]Epoch 1/10:  50%|█████     | 16/32 [00:02<00:01,  9.04it/s]Epoch 1/10:  53%|█████▎    | 17/32 [00:02<00:01,  9.07it/s]Epoch 1/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.10it/s]Epoch 1/10:  59%|█████▉    | 19/32 [00:03<00:01,  9.11it/s]Epoch 1/10:  62%|██████▎   | 20/32 [00:03<00:01,  9.12it/s]Epoch 1/10:  66%|██████▌   | 21/32 [00:03<00:01,  9.13it/s]Epoch 1/10:  69%|██████▉   | 22/32 [00:03<00:01,  9.14it/s]Epoch 1/10:  72%|███████▏  | 23/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  75%|███████▌  | 24/32 [00:03<00:00,  9.15it/s]Epoch 1/10:  78%|███████▊  | 25/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  81%|████████▏ | 26/32 [00:03<00:00,  9.15it/s]Epoch 1/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.16it/s]Epoch 1/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.16it/s]Epoch 1/10:  91%|█████████ | 29/32 [00:04<00:00,  9.16it/s]Epoch 1/10:  94%|█████████▍| 30/32 [00:04<00:00,  9.16it/s]Epoch 1/10:  97%|█████████▋| 31/32 [00:04<00:00,  9.16it/s]Epoch 1/10: 100%|██████████| 32/32 [00:04<00:00,  7.32it/s]
[2025-04-29 18:41:31,901][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6980
[2025-04-29 18:41:32,170][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6865, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   3%|▎         | 1/32 [00:00<00:06,  4.46it/s]Epoch 2/10:   6%|▋         | 2/32 [00:00<00:04,  6.37it/s]Epoch 2/10:   9%|▉         | 3/32 [00:00<00:03,  7.39it/s]Epoch 2/10:  12%|█▎        | 4/32 [00:00<00:03,  8.00it/s]Epoch 2/10:  16%|█▌        | 5/32 [00:00<00:03,  8.38it/s]Epoch 2/10:  19%|█▉        | 6/32 [00:00<00:03,  8.63it/s]Epoch 2/10:  22%|██▏       | 7/32 [00:00<00:02,  8.80it/s]Epoch 2/10:  25%|██▌       | 8/32 [00:00<00:02,  8.91it/s]Epoch 2/10:  28%|██▊       | 9/32 [00:01<00:02,  8.99it/s]Epoch 2/10:  31%|███▏      | 10/32 [00:01<00:02,  9.03it/s]Epoch 2/10:  34%|███▍      | 11/32 [00:01<00:02,  9.08it/s]Epoch 2/10:  38%|███▊      | 12/32 [00:01<00:02,  9.09it/s]Epoch 2/10:  41%|████      | 13/32 [00:01<00:02,  9.12it/s]Epoch 2/10:  44%|████▍     | 14/32 [00:01<00:01,  9.12it/s]Epoch 2/10:  47%|████▋     | 15/32 [00:01<00:01,  9.13it/s]Epoch 2/10:  50%|█████     | 16/32 [00:01<00:01,  9.13it/s]Epoch 2/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.13it/s]Epoch 2/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.13it/s]Epoch 2/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.14it/s]Epoch 2/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.14it/s]Epoch 2/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.14it/s]Epoch 2/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.16it/s]Epoch 2/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  91%|█████████ | 29/32 [00:03<00:00,  9.14it/s]Epoch 2/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.15it/s]Epoch 2/10: 100%|██████████| 32/32 [00:03<00:00,  8.97it/s]
[2025-04-29 18:41:36,287][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.7017
[2025-04-29 18:41:36,563][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6866, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   3%|▎         | 1/32 [00:00<00:06,  4.69it/s]Epoch 3/10:   6%|▋         | 2/32 [00:00<00:04,  6.56it/s]Epoch 3/10:   9%|▉         | 3/32 [00:00<00:03,  7.53it/s]Epoch 3/10:  12%|█▎        | 4/32 [00:00<00:03,  8.10it/s]Epoch 3/10:  16%|█▌        | 5/32 [00:00<00:03,  8.46it/s]Epoch 3/10:  19%|█▉        | 6/32 [00:00<00:02,  8.68it/s]Epoch 3/10:  22%|██▏       | 7/32 [00:00<00:02,  8.83it/s]Epoch 3/10:  25%|██▌       | 8/32 [00:00<00:02,  8.93it/s]Epoch 3/10:  28%|██▊       | 9/32 [00:01<00:02,  8.99it/s]Epoch 3/10:  31%|███▏      | 10/32 [00:01<00:02,  9.04it/s]Epoch 3/10:  34%|███▍      | 11/32 [00:01<00:02,  9.08it/s]Epoch 3/10:  38%|███▊      | 12/32 [00:01<00:02,  9.10it/s]Epoch 3/10:  41%|████      | 13/32 [00:01<00:02,  9.12it/s]Epoch 3/10:  44%|████▍     | 14/32 [00:01<00:01,  9.13it/s]Epoch 3/10:  47%|████▋     | 15/32 [00:01<00:01,  9.14it/s]Epoch 3/10:  50%|█████     | 16/32 [00:01<00:01,  9.14it/s]Epoch 3/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.14it/s]Epoch 3/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.15it/s]Epoch 3/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.15it/s]Epoch 3/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.14it/s]Epoch 3/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 3/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.16it/s]Epoch 3/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.16it/s]Epoch 3/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.16it/s]Epoch 3/10:  91%|█████████ | 29/32 [00:03<00:00,  9.16it/s]Epoch 3/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.16it/s]Epoch 3/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.16it/s]Epoch 3/10: 100%|██████████| 32/32 [00:03<00:00,  8.99it/s]
[2025-04-29 18:41:40,125][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6984
[2025-04-29 18:41:40,417][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6867, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   3%|▎         | 1/32 [00:00<00:06,  4.61it/s]Epoch 4/10:   6%|▋         | 2/32 [00:00<00:04,  6.50it/s]Epoch 4/10:   9%|▉         | 3/32 [00:00<00:03,  7.30it/s]Epoch 4/10:  12%|█▎        | 4/32 [00:00<00:03,  7.93it/s]Epoch 4/10:  16%|█▌        | 5/32 [00:00<00:03,  8.33it/s]Epoch 4/10:  19%|█▉        | 6/32 [00:00<00:03,  8.59it/s]Epoch 4/10:  22%|██▏       | 7/32 [00:00<00:02,  8.76it/s]Epoch 4/10:  25%|██▌       | 8/32 [00:00<00:02,  8.88it/s]Epoch 4/10:  28%|██▊       | 9/32 [00:01<00:02,  8.96it/s]Epoch 4/10:  31%|███▏      | 10/32 [00:01<00:02,  9.01it/s]Epoch 4/10:  34%|███▍      | 11/32 [00:01<00:02,  9.06it/s]Epoch 4/10:  38%|███▊      | 12/32 [00:01<00:02,  9.09it/s]Epoch 4/10:  41%|████      | 13/32 [00:01<00:02,  9.10it/s]Epoch 4/10:  44%|████▍     | 14/32 [00:01<00:01,  9.12it/s]Epoch 4/10:  47%|████▋     | 15/32 [00:01<00:01,  9.12it/s]Epoch 4/10:  50%|█████     | 16/32 [00:01<00:01,  9.13it/s]Epoch 4/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.14it/s]Epoch 4/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.14it/s]Epoch 4/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]Epoch 4/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.14it/s]Epoch 4/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.13it/s]Epoch 4/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.14it/s]Epoch 4/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.14it/s]Epoch 4/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.15it/s]Epoch 4/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 4/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.14it/s]Epoch 4/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.14it/s]Epoch 4/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.15it/s]Epoch 4/10:  91%|█████████ | 29/32 [00:03<00:00,  9.15it/s]Epoch 4/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.15it/s]Epoch 4/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.15it/s]Epoch 4/10: 100%|██████████| 32/32 [00:03<00:00,  8.98it/s]
[2025-04-29 18:41:43,984][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6990
[2025-04-29 18:41:44,263][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6868, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:41:44,264][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss ▁█▂▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▂▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68654
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.699
wandb:           train_time 16.73787
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68683
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184115-5c2c7c11
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184115-5c2c7c11/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs32 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs64
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:42:03,725][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs64
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs64
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 64
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 1
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:42:03,725][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:42:03,725][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:42:03,725][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:42:03,729][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:42:03,730][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:42:04,920][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:42:07,601][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:42:07,601][src.data.datasets][INFO] - Loading 'control_question_type_seed1' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:42:07,636][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:42:07,667][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:42:07,735][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:42:07,745][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:42:07,746][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:42:07,747][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:42:07,783][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:42:07,813][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:42:07,832][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:42:07,833][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:42:07,834][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:42:07,834][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:42:07,858][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:42:07,880][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:42:07,891][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:42:07,893][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:42:07,893][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:42:07,904][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:42:07,904][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:42:07,904][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:42:07,904][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:42:07,904][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:42:07,905][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:42:07,905][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:42:07,905][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:42:07,905][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:42:07,905][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:42:07,905][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:42:07,905][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:42:07,906][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:42:07,906][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:42:07,906][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:42:07,907][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:42:07,907][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:42:07,907][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:42:07,907][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:42:07,907][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:42:07,907][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:42:07,909][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:42:07,910][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:42:12,030][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:42:12,031][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:42:12,032][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:42:12,032][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:42:12,032][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   6%|▋         | 1/16 [00:01<00:17,  1.14s/it]Epoch 1/10:  12%|█▎        | 2/16 [00:01<00:08,  1.63it/s]Epoch 1/10:  19%|█▉        | 3/16 [00:01<00:05,  2.25it/s]Epoch 1/10:  25%|██▌       | 4/16 [00:01<00:04,  2.74it/s]Epoch 1/10:  31%|███▏      | 5/16 [00:02<00:03,  3.12it/s]Epoch 1/10:  38%|███▊      | 6/16 [00:02<00:02,  3.40it/s]Epoch 1/10:  44%|████▍     | 7/16 [00:02<00:02,  3.60it/s]Epoch 1/10:  50%|█████     | 8/16 [00:02<00:02,  3.75it/s]Epoch 1/10:  56%|█████▋    | 9/16 [00:03<00:01,  3.86it/s]Epoch 1/10:  62%|██████▎   | 10/16 [00:03<00:01,  3.94it/s]Epoch 1/10:  69%|██████▉   | 11/16 [00:03<00:01,  4.00it/s]Epoch 1/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.03it/s]Epoch 1/10:  81%|████████▏ | 13/16 [00:04<00:00,  4.06it/s]Epoch 1/10:  88%|████████▊ | 14/16 [00:04<00:00,  4.08it/s]Epoch 1/10:  94%|█████████▍| 15/16 [00:04<00:00,  4.09it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  4.72it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  3.39it/s]
[2025-04-29 18:42:18,631][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7013
[2025-04-29 18:42:18,924][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6892, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   6%|▋         | 1/16 [00:00<00:05,  2.64it/s]Epoch 2/10:  12%|█▎        | 2/16 [00:00<00:04,  3.35it/s]Epoch 2/10:  19%|█▉        | 3/16 [00:00<00:03,  3.66it/s]Epoch 2/10:  25%|██▌       | 4/16 [00:01<00:03,  3.83it/s]Epoch 2/10:  31%|███▏      | 5/16 [00:01<00:02,  3.93it/s]Epoch 2/10:  38%|███▊      | 6/16 [00:01<00:02,  3.99it/s]Epoch 2/10:  44%|████▍     | 7/16 [00:01<00:02,  4.03it/s]Epoch 2/10:  50%|█████     | 8/16 [00:02<00:01,  4.06it/s]Epoch 2/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.08it/s]Epoch 2/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.10it/s]Epoch 2/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.11it/s]Epoch 2/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.13it/s]Epoch 2/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.13it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.75it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.04it/s]
[2025-04-29 18:42:23,456][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6988
[2025-04-29 18:42:23,753][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6891, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   6%|▋         | 1/16 [00:00<00:05,  2.54it/s]Epoch 3/10:  12%|█▎        | 2/16 [00:00<00:04,  3.27it/s]Epoch 3/10:  19%|█▉        | 3/16 [00:00<00:03,  3.62it/s]Epoch 3/10:  25%|██▌       | 4/16 [00:01<00:03,  3.80it/s]Epoch 3/10:  31%|███▏      | 5/16 [00:01<00:02,  3.91it/s]Epoch 3/10:  38%|███▊      | 6/16 [00:01<00:02,  3.98it/s]Epoch 3/10:  44%|████▍     | 7/16 [00:01<00:02,  4.02it/s]Epoch 3/10:  50%|█████     | 8/16 [00:02<00:01,  4.06it/s]Epoch 3/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.08it/s]Epoch 3/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.10it/s]Epoch 3/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.11it/s]Epoch 3/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.11it/s]Epoch 3/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.11it/s]Epoch 3/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.11it/s]Epoch 3/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.12it/s]Epoch 3/10: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]Epoch 3/10: 100%|██████████| 16/16 [00:03<00:00,  4.02it/s]
[2025-04-29 18:42:28,322][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6987
[2025-04-29 18:42:28,633][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6891, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   6%|▋         | 1/16 [00:00<00:05,  2.77it/s]Epoch 4/10:  12%|█▎        | 2/16 [00:00<00:04,  3.42it/s]Epoch 4/10:  19%|█▉        | 3/16 [00:00<00:03,  3.70it/s]Epoch 4/10:  25%|██▌       | 4/16 [00:01<00:03,  3.85it/s]Epoch 4/10:  31%|███▏      | 5/16 [00:01<00:02,  3.96it/s]Epoch 4/10:  38%|███▊      | 6/16 [00:01<00:02,  4.02it/s]Epoch 4/10:  44%|████▍     | 7/16 [00:01<00:02,  4.06it/s]Epoch 4/10:  50%|█████     | 8/16 [00:02<00:01,  4.09it/s]Epoch 4/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.11it/s]Epoch 4/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.12it/s]Epoch 4/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.12it/s]Epoch 4/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.12it/s]Epoch 4/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.12it/s]Epoch 4/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.12it/s]Epoch 4/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.12it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.05it/s]
[2025-04-29 18:42:33,125][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.7013
[2025-04-29 18:42:33,428][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   6%|▋         | 1/16 [00:00<00:05,  2.76it/s]Epoch 5/10:  12%|█▎        | 2/16 [00:00<00:04,  3.42it/s]Epoch 5/10:  19%|█▉        | 3/16 [00:00<00:03,  3.70it/s]Epoch 5/10:  25%|██▌       | 4/16 [00:01<00:03,  3.86it/s]Epoch 5/10:  31%|███▏      | 5/16 [00:01<00:02,  3.96it/s]Epoch 5/10:  38%|███▊      | 6/16 [00:01<00:02,  4.03it/s]Epoch 5/10:  44%|████▍     | 7/16 [00:01<00:02,  4.07it/s]Epoch 5/10:  50%|█████     | 8/16 [00:02<00:01,  4.10it/s]Epoch 5/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.12it/s]Epoch 5/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 5/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.14it/s]Epoch 5/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 5/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 5/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 5/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 5/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 5/10: 100%|██████████| 16/16 [00:03<00:00,  4.08it/s]
[2025-04-29 18:42:37,882][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6974
[2025-04-29 18:42:38,196][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 6/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 6/10:   6%|▋         | 1/16 [00:00<00:05,  2.72it/s]Epoch 6/10:  12%|█▎        | 2/16 [00:00<00:04,  3.40it/s]Epoch 6/10:  19%|█▉        | 3/16 [00:00<00:03,  3.70it/s]Epoch 6/10:  25%|██▌       | 4/16 [00:01<00:03,  3.86it/s]Epoch 6/10:  31%|███▏      | 5/16 [00:01<00:02,  3.95it/s]Epoch 6/10:  38%|███▊      | 6/16 [00:01<00:02,  4.00it/s]Epoch 6/10:  44%|████▍     | 7/16 [00:01<00:02,  4.04it/s]Epoch 6/10:  50%|█████     | 8/16 [00:02<00:01,  4.06it/s]Epoch 6/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.09it/s]Epoch 6/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.11it/s]Epoch 6/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.13it/s]Epoch 6/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.14it/s]Epoch 6/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 6/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.15it/s]Epoch 6/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.06it/s]
[2025-04-29 18:42:42,691][src.training.lm_trainer][INFO] - Epoch 6/10, Train Loss: 0.6984
[2025-04-29 18:42:43,009][src.training.lm_trainer][INFO] - Epoch 6/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 7/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 7/10:   6%|▋         | 1/16 [00:00<00:05,  2.64it/s]Epoch 7/10:  12%|█▎        | 2/16 [00:00<00:04,  3.35it/s]Epoch 7/10:  19%|█▉        | 3/16 [00:00<00:03,  3.68it/s]Epoch 7/10:  25%|██▌       | 4/16 [00:01<00:03,  3.86it/s]Epoch 7/10:  31%|███▏      | 5/16 [00:01<00:02,  3.96it/s]Epoch 7/10:  38%|███▊      | 6/16 [00:01<00:02,  4.03it/s]Epoch 7/10:  44%|████▍     | 7/16 [00:01<00:02,  4.07it/s]Epoch 7/10:  50%|█████     | 8/16 [00:02<00:01,  4.11it/s]Epoch 7/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.13it/s]Epoch 7/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.15it/s]Epoch 7/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.16it/s]Epoch 7/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.17it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.07it/s]
[2025-04-29 18:42:46,939][src.training.lm_trainer][INFO] - Epoch 7/10, Train Loss: 0.6974
[2025-04-29 18:42:47,253][src.training.lm_trainer][INFO] - Epoch 7/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 8/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 8/10:   6%|▋         | 1/16 [00:00<00:05,  2.68it/s]Epoch 8/10:  12%|█▎        | 2/16 [00:00<00:04,  3.39it/s]Epoch 8/10:  19%|█▉        | 3/16 [00:00<00:03,  3.71it/s]Epoch 8/10:  25%|██▌       | 4/16 [00:01<00:03,  3.88it/s]Epoch 8/10:  31%|███▏      | 5/16 [00:01<00:02,  3.98it/s]Epoch 8/10:  38%|███▊      | 6/16 [00:01<00:02,  4.04it/s]Epoch 8/10:  44%|████▍     | 7/16 [00:01<00:02,  4.08it/s]Epoch 8/10:  50%|█████     | 8/16 [00:02<00:01,  4.11it/s]Epoch 8/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.13it/s]Epoch 8/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.14it/s]Epoch 8/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.15it/s]Epoch 8/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.08it/s]
[2025-04-29 18:42:51,175][src.training.lm_trainer][INFO] - Epoch 8/10, Train Loss: 0.6964
[2025-04-29 18:42:51,491][src.training.lm_trainer][INFO] - Epoch 8/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:42:51,492][src.training.lm_trainer][INFO] - Early stopping at epoch 8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁
wandb:        best_val_loss █▅▃▂▁
wandb:                epoch ▁▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁
wandb:           train_loss █▄▄█▂▄▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁
wandb:             val_loss █▅▃▂▁▁▂▃
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68898
wandb:                epoch 8
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69642
wandb:           train_time 37.57687
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68904
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184203-jtyi29fe
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184203-jtyi29fe/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control1_bs64 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:43:12,533][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs8
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs8
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 8
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 2
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:43:12,533][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:43:12,533][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:43:12,533][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:43:12,538][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:43:12,538][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:43:14,130][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:43:16,852][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:43:16,852][src.data.datasets][INFO] - Loading 'control_question_type_seed2' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:43:16,939][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:43:16,968][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:43:17,180][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:43:17,190][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:43:17,190][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:43:17,191][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:43:17,207][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:43:17,247][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:43:17,267][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:43:17,268][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:43:17,268][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:43:17,269][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:43:17,283][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:43:17,314][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:43:17,323][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:43:17,324][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:43:17,325][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:43:17,325][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:43:17,326][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:43:17,326][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:43:17,326][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:43:17,326][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:43:17,326][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:43:17,326][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:43:17,327][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:43:17,327][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:43:17,327][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:43:17,328][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:43:17,328][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:43:17,328][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:43:17,329][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:43:17,329][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:43:17,329][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:43:17,329][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:43:17,334][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:43:17,335][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:43:21,892][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:43:21,893][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:43:21,894][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:43:21,894][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:43:21,894][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   1%|          | 1/125 [00:00<01:45,  1.18it/s]Epoch 1/10:   4%|▍         | 5/125 [00:00<00:18,  6.46it/s]Epoch 1/10:   7%|▋         | 9/125 [00:01<00:10, 11.40it/s]Epoch 1/10:  10%|█         | 13/125 [00:01<00:07, 15.77it/s]Epoch 1/10:  14%|█▎        | 17/125 [00:01<00:05, 19.42it/s]Epoch 1/10:  17%|█▋        | 21/125 [00:01<00:04, 22.34it/s]Epoch 1/10:  20%|██        | 25/125 [00:01<00:04, 24.60it/s]Epoch 1/10:  23%|██▎       | 29/125 [00:01<00:03, 26.30it/s]Epoch 1/10:  26%|██▋       | 33/125 [00:01<00:03, 27.55it/s]Epoch 1/10:  30%|██▉       | 37/125 [00:02<00:03, 28.48it/s]Epoch 1/10:  33%|███▎      | 41/125 [00:02<00:02, 29.11it/s]Epoch 1/10:  36%|███▌      | 45/125 [00:02<00:02, 29.59it/s]Epoch 1/10:  39%|███▉      | 49/125 [00:02<00:02, 29.94it/s]Epoch 1/10:  42%|████▏     | 53/125 [00:02<00:02, 30.18it/s]Epoch 1/10:  46%|████▌     | 57/125 [00:02<00:02, 30.35it/s]Epoch 1/10:  49%|████▉     | 61/125 [00:02<00:02, 30.47it/s]Epoch 1/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.55it/s]Epoch 1/10:  55%|█████▌    | 69/125 [00:03<00:01, 30.62it/s]Epoch 1/10:  58%|█████▊    | 73/125 [00:03<00:01, 30.66it/s]Epoch 1/10:  62%|██████▏   | 77/125 [00:03<00:01, 30.69it/s]Epoch 1/10:  65%|██████▍   | 81/125 [00:03<00:01, 30.72it/s]Epoch 1/10:  68%|██████▊   | 85/125 [00:03<00:01, 30.73it/s]Epoch 1/10:  71%|███████   | 89/125 [00:03<00:01, 30.74it/s]Epoch 1/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.75it/s]Epoch 1/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.76it/s]Epoch 1/10:  81%|████████  | 101/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  84%|████████▍ | 105/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  87%|████████▋ | 109/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  90%|█████████ | 113/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  94%|█████████▎| 117/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.78it/s]Epoch 1/10: 100%|██████████| 125/125 [00:04<00:00, 32.08it/s]Epoch 1/10: 100%|██████████| 125/125 [00:04<00:00, 25.45it/s]
[2025-04-29 18:43:29,410][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6987
[2025-04-29 18:43:29,722][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6857, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   1%|          | 1/125 [00:00<00:15,  7.81it/s]Epoch 2/10:   4%|▍         | 5/125 [00:00<00:05, 21.25it/s]Epoch 2/10:   7%|▋         | 9/125 [00:00<00:04, 25.54it/s]Epoch 2/10:  10%|█         | 13/125 [00:00<00:04, 27.55it/s]Epoch 2/10:  14%|█▎        | 17/125 [00:00<00:03, 28.67it/s]Epoch 2/10:  17%|█▋        | 21/125 [00:00<00:03, 29.36it/s]Epoch 2/10:  20%|██        | 25/125 [00:00<00:03, 29.77it/s]Epoch 2/10:  23%|██▎       | 29/125 [00:01<00:03, 30.05it/s]Epoch 2/10:  26%|██▋       | 33/125 [00:01<00:03, 30.24it/s]Epoch 2/10:  30%|██▉       | 37/125 [00:01<00:02, 30.38it/s]Epoch 2/10:  33%|███▎      | 41/125 [00:01<00:02, 30.46it/s]Epoch 2/10:  36%|███▌      | 45/125 [00:01<00:02, 30.52it/s]Epoch 2/10:  39%|███▉      | 49/125 [00:01<00:02, 30.57it/s]Epoch 2/10:  42%|████▏     | 53/125 [00:01<00:02, 30.60it/s]Epoch 2/10:  46%|████▌     | 57/125 [00:01<00:02, 30.61it/s]Epoch 2/10:  49%|████▉     | 61/125 [00:02<00:02, 30.63it/s]Epoch 2/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.64it/s]Epoch 2/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.65it/s]Epoch 2/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.65it/s]Epoch 2/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.65it/s]Epoch 2/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.65it/s]Epoch 2/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.66it/s]Epoch 2/10:  71%|███████   | 89/125 [00:02<00:01, 30.66it/s]Epoch 2/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.66it/s]Epoch 2/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.65it/s]Epoch 2/10:  81%|████████  | 101/125 [00:03<00:00, 30.66it/s]Epoch 2/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.66it/s]Epoch 2/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.66it/s]Epoch 2/10:  90%|█████████ | 113/125 [00:03<00:00, 30.65it/s]Epoch 2/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.65it/s]Epoch 2/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.68it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 32.00it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 29.76it/s]
[2025-04-29 18:43:34,473][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6964
[2025-04-29 18:43:34,765][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6863, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   1%|          | 1/125 [00:00<00:16,  7.72it/s]Epoch 3/10:   4%|▍         | 5/125 [00:00<00:05, 21.21it/s]Epoch 3/10:   7%|▋         | 9/125 [00:00<00:04, 25.57it/s]Epoch 3/10:  10%|█         | 13/125 [00:00<00:04, 27.62it/s]Epoch 3/10:  14%|█▎        | 17/125 [00:00<00:03, 28.75it/s]Epoch 3/10:  17%|█▋        | 21/125 [00:00<00:03, 29.43it/s]Epoch 3/10:  20%|██        | 25/125 [00:00<00:03, 29.86it/s]Epoch 3/10:  23%|██▎       | 29/125 [00:01<00:03, 30.15it/s]Epoch 3/10:  26%|██▋       | 33/125 [00:01<00:03, 30.36it/s]Epoch 3/10:  30%|██▉       | 37/125 [00:01<00:02, 30.47it/s]Epoch 3/10:  33%|███▎      | 41/125 [00:01<00:02, 30.54it/s]Epoch 3/10:  36%|███▌      | 45/125 [00:01<00:02, 30.61it/s]Epoch 3/10:  39%|███▉      | 49/125 [00:01<00:02, 30.65it/s]Epoch 3/10:  42%|████▏     | 53/125 [00:01<00:02, 30.69it/s]Epoch 3/10:  46%|████▌     | 57/125 [00:01<00:02, 30.71it/s]Epoch 3/10:  49%|████▉     | 61/125 [00:02<00:02, 30.73it/s]Epoch 3/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.74it/s]Epoch 3/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.75it/s]Epoch 3/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.77it/s]Epoch 3/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.76it/s]Epoch 3/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.76it/s]Epoch 3/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.76it/s]Epoch 3/10:  71%|███████   | 89/125 [00:02<00:01, 30.78it/s]Epoch 3/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.78it/s]Epoch 3/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.78it/s]Epoch 3/10:  81%|████████  | 101/125 [00:03<00:00, 30.77it/s]Epoch 3/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.77it/s]Epoch 3/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.76it/s]Epoch 3/10:  90%|█████████ | 113/125 [00:03<00:00, 30.77it/s]Epoch 3/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.76it/s]Epoch 3/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.79it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 32.13it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 29.86it/s]
[2025-04-29 18:43:38,954][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6985
[2025-04-29 18:43:39,275][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6870, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   1%|          | 1/125 [00:00<00:16,  7.73it/s]Epoch 4/10:   4%|▍         | 5/125 [00:00<00:05, 21.18it/s]Epoch 4/10:   7%|▋         | 9/125 [00:00<00:04, 25.50it/s]Epoch 4/10:  10%|█         | 13/125 [00:00<00:04, 27.53it/s]Epoch 4/10:  14%|█▎        | 17/125 [00:00<00:03, 28.65it/s]Epoch 4/10:  17%|█▋        | 21/125 [00:00<00:03, 29.32it/s]Epoch 4/10:  20%|██        | 25/125 [00:00<00:03, 29.78it/s]Epoch 4/10:  23%|██▎       | 29/125 [00:01<00:03, 30.10it/s]Epoch 4/10:  26%|██▋       | 33/125 [00:01<00:03, 30.30it/s]Epoch 4/10:  30%|██▉       | 37/125 [00:01<00:02, 30.44it/s]Epoch 4/10:  33%|███▎      | 41/125 [00:01<00:02, 30.55it/s]Epoch 4/10:  36%|███▌      | 45/125 [00:01<00:02, 30.61it/s]Epoch 4/10:  39%|███▉      | 49/125 [00:01<00:02, 30.66it/s]Epoch 4/10:  42%|████▏     | 53/125 [00:01<00:02, 30.70it/s]Epoch 4/10:  46%|████▌     | 57/125 [00:01<00:02, 30.72it/s]Epoch 4/10:  49%|████▉     | 61/125 [00:02<00:02, 30.74it/s]Epoch 4/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.74it/s]Epoch 4/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.75it/s]Epoch 4/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.75it/s]Epoch 4/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.76it/s]Epoch 4/10:  71%|███████   | 89/125 [00:02<00:01, 30.77it/s]Epoch 4/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.77it/s]Epoch 4/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.78it/s]Epoch 4/10:  81%|████████  | 101/125 [00:03<00:00, 30.78it/s]Epoch 4/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.78it/s]Epoch 4/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.77it/s]Epoch 4/10:  90%|█████████ | 113/125 [00:03<00:00, 30.78it/s]Epoch 4/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.78it/s]Epoch 4/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.80it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 32.15it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 29.84it/s]
[2025-04-29 18:43:43,466][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6938
[2025-04-29 18:43:43,774][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6878, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:43:43,774][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▅█▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68568
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69379
wandb:           train_time 19.27813
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68782
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184312-a1ih1dah
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184312-a1ih1dah/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs8 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs16
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:44:01,769][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs16
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs16
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 16
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 2
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:44:01,769][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:44:01,769][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:44:01,769][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:44:01,774][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:44:01,774][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:44:02,939][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:44:05,620][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:44:05,621][src.data.datasets][INFO] - Loading 'control_question_type_seed2' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:05,701][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:44:05,733][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:44:05,846][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:44:05,855][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:05,856][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:44:05,857][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:05,894][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:05,915][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:05,924][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:44:05,926][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:05,926][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:44:05,926][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:05,950][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:05,999][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:06,008][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:44:06,010][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:06,010][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:44:06,011][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:44:06,011][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:06,011][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:06,011][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:06,011][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:06,012][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:44:06,012][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:44:06,012][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:44:06,012][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 18:44:06,012][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:06,012][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:06,012][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:06,013][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:44:06,013][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:06,013][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:06,014][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:44:06,014][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:44:06,014][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:44:06,014][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:44:06,014][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:44:06,014][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:44:06,016][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:44:06,016][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:44:10,189][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:44:10,190][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:44:10,191][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:44:10,191][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:44:10,191][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   2%|▏         | 1/63 [00:00<00:58,  1.05it/s]Epoch 1/10:   5%|▍         | 3/63 [00:01<00:17,  3.47it/s]Epoch 1/10:   8%|▊         | 5/63 [00:01<00:09,  5.93it/s]Epoch 1/10:  11%|█         | 7/63 [00:01<00:06,  8.28it/s]Epoch 1/10:  14%|█▍        | 9/63 [00:01<00:05, 10.39it/s]Epoch 1/10:  17%|█▋        | 11/63 [00:01<00:04, 12.20it/s]Epoch 1/10:  21%|██        | 13/63 [00:01<00:03, 13.66it/s]Epoch 1/10:  24%|██▍       | 15/63 [00:01<00:03, 14.81it/s]Epoch 1/10:  27%|██▋       | 17/63 [00:01<00:02, 15.68it/s]Epoch 1/10:  30%|███       | 19/63 [00:01<00:02, 16.35it/s]Epoch 1/10:  33%|███▎      | 21/63 [00:02<00:02, 16.80it/s]Epoch 1/10:  37%|███▋      | 23/63 [00:02<00:02, 17.16it/s]Epoch 1/10:  40%|███▉      | 25/63 [00:02<00:02, 17.39it/s]Epoch 1/10:  43%|████▎     | 27/63 [00:02<00:02, 17.57it/s]Epoch 1/10:  46%|████▌     | 29/63 [00:02<00:01, 17.67it/s]Epoch 1/10:  49%|████▉     | 31/63 [00:02<00:01, 17.78it/s]Epoch 1/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.82it/s]Epoch 1/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.89it/s]Epoch 1/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.90it/s]Epoch 1/10:  62%|██████▏   | 39/63 [00:03<00:01, 17.94it/s]Epoch 1/10:  65%|██████▌   | 41/63 [00:03<00:01, 17.95it/s]Epoch 1/10:  68%|██████▊   | 43/63 [00:03<00:01, 17.97it/s]Epoch 1/10:  71%|███████▏  | 45/63 [00:03<00:01, 17.96it/s]Epoch 1/10:  75%|███████▍  | 47/63 [00:03<00:00, 17.99it/s]Epoch 1/10:  78%|███████▊  | 49/63 [00:03<00:00, 17.98it/s]Epoch 1/10:  81%|████████  | 51/63 [00:03<00:00, 17.99it/s]Epoch 1/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.98it/s]Epoch 1/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.99it/s]Epoch 1/10:  90%|█████████ | 57/63 [00:04<00:00, 17.98it/s]Epoch 1/10:  94%|█████████▎| 59/63 [00:04<00:00, 18.01it/s]Epoch 1/10:  97%|█████████▋| 61/63 [00:04<00:00, 18.00it/s]Epoch 1/10: 100%|██████████| 63/63 [00:04<00:00, 14.25it/s]
[2025-04-29 18:44:17,302][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7002
[2025-04-29 18:44:17,580][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   2%|▏         | 1/63 [00:00<00:09,  6.34it/s]Epoch 2/10:   5%|▍         | 3/63 [00:00<00:04, 12.18it/s]Epoch 2/10:   8%|▊         | 5/63 [00:00<00:03, 14.58it/s]Epoch 2/10:  11%|█         | 7/63 [00:00<00:03, 15.87it/s]Epoch 2/10:  14%|█▍        | 9/63 [00:00<00:03, 16.60it/s]Epoch 2/10:  17%|█▋        | 11/63 [00:00<00:03, 17.08it/s]Epoch 2/10:  21%|██        | 13/63 [00:00<00:02, 17.35it/s]Epoch 2/10:  24%|██▍       | 15/63 [00:00<00:02, 17.57it/s]Epoch 2/10:  27%|██▋       | 17/63 [00:01<00:02, 17.69it/s]Epoch 2/10:  30%|███       | 19/63 [00:01<00:02, 17.79it/s]Epoch 2/10:  33%|███▎      | 21/63 [00:01<00:02, 17.83it/s]Epoch 2/10:  37%|███▋      | 23/63 [00:01<00:02, 17.88it/s]Epoch 2/10:  40%|███▉      | 25/63 [00:01<00:02, 17.90it/s]Epoch 2/10:  43%|████▎     | 27/63 [00:01<00:02, 17.93it/s]Epoch 2/10:  46%|████▌     | 29/63 [00:01<00:01, 17.93it/s]Epoch 2/10:  49%|████▉     | 31/63 [00:01<00:01, 17.96it/s]Epoch 2/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.95it/s]Epoch 2/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.97it/s]Epoch 2/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.96it/s]Epoch 2/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.97it/s]Epoch 2/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.97it/s]Epoch 2/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.99it/s]Epoch 2/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.98it/s]Epoch 2/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.99it/s]Epoch 2/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.96it/s]Epoch 2/10:  81%|████████  | 51/63 [00:02<00:00, 17.98it/s]Epoch 2/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.97it/s]Epoch 2/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.98it/s]Epoch 2/10:  90%|█████████ | 57/63 [00:03<00:00, 17.97it/s]Epoch 2/10:  94%|█████████▎| 59/63 [00:03<00:00, 18.00it/s]Epoch 2/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.99it/s]Epoch 2/10: 100%|██████████| 63/63 [00:03<00:00, 17.41it/s]
[2025-04-29 18:44:21,768][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6976
[2025-04-29 18:44:22,045][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   2%|▏         | 1/63 [00:00<00:10,  5.73it/s]Epoch 3/10:   5%|▍         | 3/63 [00:00<00:05, 11.56it/s]Epoch 3/10:   8%|▊         | 5/63 [00:00<00:04, 14.13it/s]Epoch 3/10:  11%|█         | 7/63 [00:00<00:03, 15.55it/s]Epoch 3/10:  14%|█▍        | 9/63 [00:00<00:03, 16.37it/s]Epoch 3/10:  17%|█▋        | 11/63 [00:00<00:03, 16.90it/s]Epoch 3/10:  21%|██        | 13/63 [00:00<00:02, 17.22it/s]Epoch 3/10:  24%|██▍       | 15/63 [00:00<00:02, 17.46it/s]Epoch 3/10:  27%|██▋       | 17/63 [00:01<00:02, 17.59it/s]Epoch 3/10:  30%|███       | 19/63 [00:01<00:02, 17.72it/s]Epoch 3/10:  33%|███▎      | 21/63 [00:01<00:02, 17.78it/s]Epoch 3/10:  37%|███▋      | 23/63 [00:01<00:02, 17.85it/s]Epoch 3/10:  40%|███▉      | 25/63 [00:01<00:02, 17.87it/s]Epoch 3/10:  43%|████▎     | 27/63 [00:01<00:02, 17.90it/s]Epoch 3/10:  46%|████▌     | 29/63 [00:01<00:01, 17.91it/s]Epoch 3/10:  49%|████▉     | 31/63 [00:01<00:01, 17.94it/s]Epoch 3/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.93it/s]Epoch 3/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.94it/s]Epoch 3/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.93it/s]Epoch 3/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.94it/s]Epoch 3/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.94it/s]Epoch 3/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.94it/s]Epoch 3/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.94it/s]Epoch 3/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.93it/s]Epoch 3/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.93it/s]Epoch 3/10:  81%|████████  | 51/63 [00:02<00:00, 17.94it/s]Epoch 3/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.94it/s]Epoch 3/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.94it/s]Epoch 3/10:  90%|█████████ | 57/63 [00:03<00:00, 17.96it/s]Epoch 3/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.95it/s]Epoch 3/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.96it/s]Epoch 3/10: 100%|██████████| 63/63 [00:03<00:00, 17.30it/s]
[2025-04-29 18:44:26,268][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6972
[2025-04-29 18:44:26,552][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   2%|▏         | 1/63 [00:00<00:09,  6.52it/s]Epoch 4/10:   5%|▍         | 3/63 [00:00<00:04, 12.31it/s]Epoch 4/10:   8%|▊         | 5/63 [00:00<00:03, 14.67it/s]Epoch 4/10:  11%|█         | 7/63 [00:00<00:03, 15.90it/s]Epoch 4/10:  14%|█▍        | 9/63 [00:00<00:03, 16.61it/s]Epoch 4/10:  17%|█▋        | 11/63 [00:00<00:03, 17.05it/s]Epoch 4/10:  21%|██        | 13/63 [00:00<00:02, 17.32it/s]Epoch 4/10:  24%|██▍       | 15/63 [00:00<00:02, 17.52it/s]Epoch 4/10:  27%|██▋       | 17/63 [00:01<00:02, 17.65it/s]Epoch 4/10:  30%|███       | 19/63 [00:01<00:02, 17.75it/s]Epoch 4/10:  33%|███▎      | 21/63 [00:01<00:02, 17.82it/s]Epoch 4/10:  37%|███▋      | 23/63 [00:01<00:02, 17.86it/s]Epoch 4/10:  40%|███▉      | 25/63 [00:01<00:02, 17.86it/s]Epoch 4/10:  43%|████▎     | 27/63 [00:01<00:02, 17.88it/s]Epoch 4/10:  46%|████▌     | 29/63 [00:01<00:01, 17.89it/s]Epoch 4/10:  49%|████▉     | 31/63 [00:01<00:01, 17.89it/s]Epoch 4/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.89it/s]Epoch 4/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.90it/s]Epoch 4/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.90it/s]Epoch 4/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.90it/s]Epoch 4/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.90it/s]Epoch 4/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.91it/s]Epoch 4/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.91it/s]Epoch 4/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.92it/s]Epoch 4/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.90it/s]Epoch 4/10:  81%|████████  | 51/63 [00:02<00:00, 17.90it/s]Epoch 4/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.90it/s]Epoch 4/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.90it/s]Epoch 4/10:  90%|█████████ | 57/63 [00:03<00:00, 17.91it/s]Epoch 4/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.92it/s]Epoch 4/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.92it/s]Epoch 4/10: 100%|██████████| 63/63 [00:03<00:00, 17.37it/s]
[2025-04-29 18:44:30,182][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6953
[2025-04-29 18:44:30,476][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   2%|▏         | 1/63 [00:00<00:09,  6.21it/s]Epoch 5/10:   5%|▍         | 3/63 [00:00<00:04, 12.01it/s]Epoch 5/10:   8%|▊         | 5/63 [00:00<00:04, 14.46it/s]Epoch 5/10:  11%|█         | 7/63 [00:00<00:03, 15.76it/s]Epoch 5/10:  14%|█▍        | 9/63 [00:00<00:03, 16.52it/s]Epoch 5/10:  17%|█▋        | 11/63 [00:00<00:03, 16.99it/s]Epoch 5/10:  21%|██        | 13/63 [00:00<00:02, 17.29it/s]Epoch 5/10:  24%|██▍       | 15/63 [00:00<00:02, 17.50it/s]Epoch 5/10:  27%|██▋       | 17/63 [00:01<00:02, 17.63it/s]Epoch 5/10:  30%|███       | 19/63 [00:01<00:02, 17.72it/s]Epoch 5/10:  33%|███▎      | 21/63 [00:01<00:02, 17.78it/s]Epoch 5/10:  37%|███▋      | 23/63 [00:01<00:02, 17.83it/s]Epoch 5/10:  40%|███▉      | 25/63 [00:01<00:02, 17.86it/s]Epoch 5/10:  43%|████▎     | 27/63 [00:01<00:02, 17.88it/s]Epoch 5/10:  46%|████▌     | 29/63 [00:01<00:01, 17.90it/s]Epoch 5/10:  49%|████▉     | 31/63 [00:01<00:01, 17.92it/s]Epoch 5/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.93it/s]Epoch 5/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.93it/s]Epoch 5/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.93it/s]Epoch 5/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.94it/s]Epoch 5/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.94it/s]Epoch 5/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.94it/s]Epoch 5/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.93it/s]Epoch 5/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.93it/s]Epoch 5/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.93it/s]Epoch 5/10:  81%|████████  | 51/63 [00:02<00:00, 17.93it/s]Epoch 5/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.94it/s]Epoch 5/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.93it/s]Epoch 5/10:  90%|█████████ | 57/63 [00:03<00:00, 17.94it/s]Epoch 5/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.94it/s]Epoch 5/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.95it/s]Epoch 5/10: 100%|██████████| 63/63 [00:03<00:00, 17.39it/s]
[2025-04-29 18:44:34,101][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6975
[2025-04-29 18:44:34,392][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6888, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:44:34,393][src.training.lm_trainer][INFO] - Early stopping at epoch 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss █▄▄▁▄
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▁▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.6884
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69752
wandb:           train_time 21.51477
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68878
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184401-zygcbt7e
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184401-zygcbt7e/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs16 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs32
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:44:53,300][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs32
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs32
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 32
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 2
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:44:53,300][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:44:53,300][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:44:53,300][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:44:53,304][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:44:53,305][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:44:54,992][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:44:57,801][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:44:57,802][src.data.datasets][INFO] - Loading 'control_question_type_seed2' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:57,912][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:44:57,952][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:44:58,048][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:44:58,059][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:58,059][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:44:58,060][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:58,078][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:58,102][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:58,121][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:44:58,123][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:58,123][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:44:58,124][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:44:58,151][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:58,192][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:44:58,211][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:44:58,212][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:44:58,213][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:44:58,213][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:44:58,214][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:58,214][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:58,214][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:58,214][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:58,215][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:44:58,215][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:58,215][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:58,216][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:44:58,216][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:44:58,216][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:44:58,216][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:44:58,216][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:44:58,216][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:44:58,216][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:44:58,217][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:44:58,217][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:44:58,217][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:44:58,217][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:44:58,217][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:44:58,217][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:44:58,217][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:44:58,221][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:44:58,222][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:45:02,786][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:45:02,787][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:45:02,788][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:45:02,789][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:45:02,789][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   3%|▎         | 1/32 [00:01<00:32,  1.05s/it]Epoch 1/10:   6%|▋         | 2/32 [00:01<00:14,  2.01it/s]Epoch 1/10:   9%|▉         | 3/32 [00:01<00:09,  3.12it/s]Epoch 1/10:  12%|█▎        | 4/32 [00:01<00:06,  4.22it/s]Epoch 1/10:  16%|█▌        | 5/32 [00:01<00:05,  5.24it/s]Epoch 1/10:  19%|█▉        | 6/32 [00:01<00:04,  6.13it/s]Epoch 1/10:  22%|██▏       | 7/32 [00:01<00:03,  6.87it/s]Epoch 1/10:  25%|██▌       | 8/32 [00:01<00:03,  7.46it/s]Epoch 1/10:  28%|██▊       | 9/32 [00:01<00:02,  7.92it/s]Epoch 1/10:  31%|███▏      | 10/32 [00:02<00:02,  8.27it/s]Epoch 1/10:  34%|███▍      | 11/32 [00:02<00:02,  8.51it/s]Epoch 1/10:  38%|███▊      | 12/32 [00:02<00:02,  8.70it/s]Epoch 1/10:  41%|████      | 13/32 [00:02<00:02,  8.82it/s]Epoch 1/10:  44%|████▍     | 14/32 [00:02<00:02,  8.92it/s]Epoch 1/10:  47%|████▋     | 15/32 [00:02<00:01,  8.98it/s]Epoch 1/10:  50%|█████     | 16/32 [00:02<00:01,  9.04it/s]Epoch 1/10:  53%|█████▎    | 17/32 [00:02<00:01,  9.07it/s]Epoch 1/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.09it/s]Epoch 1/10:  59%|█████▉    | 19/32 [00:03<00:01,  9.11it/s]Epoch 1/10:  62%|██████▎   | 20/32 [00:03<00:01,  9.13it/s]Epoch 1/10:  66%|██████▌   | 21/32 [00:03<00:01,  9.13it/s]Epoch 1/10:  69%|██████▉   | 22/32 [00:03<00:01,  9.13it/s]Epoch 1/10:  72%|███████▏  | 23/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  75%|███████▌  | 24/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  78%|███████▊  | 25/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  81%|████████▏ | 26/32 [00:03<00:00,  9.15it/s]Epoch 1/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.16it/s]Epoch 1/10:  88%|████████▊ | 28/32 [00:04<00:00,  9.16it/s]Epoch 1/10:  91%|█████████ | 29/32 [00:04<00:00,  9.16it/s]Epoch 1/10:  94%|█████████▍| 30/32 [00:04<00:00,  9.17it/s]Epoch 1/10:  97%|█████████▋| 31/32 [00:04<00:00,  9.15it/s]Epoch 1/10: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]
[2025-04-29 18:45:09,419][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7016
[2025-04-29 18:45:09,693][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6866, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   3%|▎         | 1/32 [00:00<00:07,  4.42it/s]Epoch 2/10:   6%|▋         | 2/32 [00:00<00:04,  6.34it/s]Epoch 2/10:   9%|▉         | 3/32 [00:00<00:03,  7.37it/s]Epoch 2/10:  12%|█▎        | 4/32 [00:00<00:03,  7.98it/s]Epoch 2/10:  16%|█▌        | 5/32 [00:00<00:03,  8.37it/s]Epoch 2/10:  19%|█▉        | 6/32 [00:00<00:03,  8.62it/s]Epoch 2/10:  22%|██▏       | 7/32 [00:00<00:02,  8.79it/s]Epoch 2/10:  25%|██▌       | 8/32 [00:00<00:02,  8.90it/s]Epoch 2/10:  28%|██▊       | 9/32 [00:01<00:02,  8.97it/s]Epoch 2/10:  31%|███▏      | 10/32 [00:01<00:02,  9.03it/s]Epoch 2/10:  34%|███▍      | 11/32 [00:01<00:02,  9.07it/s]Epoch 2/10:  38%|███▊      | 12/32 [00:01<00:02,  9.09it/s]Epoch 2/10:  41%|████      | 13/32 [00:01<00:02,  9.11it/s]Epoch 2/10:  44%|████▍     | 14/32 [00:01<00:01,  9.14it/s]Epoch 2/10:  47%|████▋     | 15/32 [00:01<00:01,  9.14it/s]Epoch 2/10:  50%|█████     | 16/32 [00:01<00:01,  9.15it/s]Epoch 2/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.15it/s]Epoch 2/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.16it/s]Epoch 2/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.14it/s]Epoch 2/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.14it/s]Epoch 2/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  91%|█████████ | 29/32 [00:03<00:00,  9.15it/s]Epoch 2/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.16it/s]Epoch 2/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.16it/s]Epoch 2/10: 100%|██████████| 32/32 [00:03<00:00,  8.94it/s]
[2025-04-29 18:45:13,851][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6994
[2025-04-29 18:45:14,140][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6867, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   3%|▎         | 1/32 [00:00<00:06,  4.63it/s]Epoch 3/10:   6%|▋         | 2/32 [00:00<00:04,  6.50it/s]Epoch 3/10:   9%|▉         | 3/32 [00:00<00:03,  7.49it/s]Epoch 3/10:  12%|█▎        | 4/32 [00:00<00:03,  8.07it/s]Epoch 3/10:  16%|█▌        | 5/32 [00:00<00:03,  8.42it/s]Epoch 3/10:  19%|█▉        | 6/32 [00:00<00:03,  8.65it/s]Epoch 3/10:  22%|██▏       | 7/32 [00:00<00:02,  8.81it/s]Epoch 3/10:  25%|██▌       | 8/32 [00:00<00:02,  8.92it/s]Epoch 3/10:  28%|██▊       | 9/32 [00:01<00:02,  8.98it/s]Epoch 3/10:  31%|███▏      | 10/32 [00:01<00:02,  9.04it/s]Epoch 3/10:  34%|███▍      | 11/32 [00:01<00:02,  9.06it/s]Epoch 3/10:  38%|███▊      | 12/32 [00:01<00:02,  9.08it/s]Epoch 3/10:  41%|████      | 13/32 [00:01<00:02,  9.11it/s]Epoch 3/10:  44%|████▍     | 14/32 [00:01<00:01,  9.12it/s]Epoch 3/10:  47%|████▋     | 15/32 [00:01<00:01,  9.12it/s]Epoch 3/10:  50%|█████     | 16/32 [00:01<00:01,  9.13it/s]Epoch 3/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.13it/s]Epoch 3/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.15it/s]Epoch 3/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.13it/s]Epoch 3/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 3/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.14it/s]Epoch 3/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  91%|█████████ | 29/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.15it/s]Epoch 3/10: 100%|██████████| 32/32 [00:03<00:00,  8.98it/s]
[2025-04-29 18:45:17,706][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6987
[2025-04-29 18:45:17,994][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6868, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   3%|▎         | 1/32 [00:00<00:06,  4.77it/s]Epoch 4/10:   6%|▋         | 2/32 [00:00<00:04,  6.62it/s]Epoch 4/10:   9%|▉         | 3/32 [00:00<00:03,  7.58it/s]Epoch 4/10:  12%|█▎        | 4/32 [00:00<00:03,  8.12it/s]Epoch 4/10:  16%|█▌        | 5/32 [00:00<00:03,  8.47it/s]Epoch 4/10:  19%|█▉        | 6/32 [00:00<00:02,  8.69it/s]Epoch 4/10:  22%|██▏       | 7/32 [00:00<00:02,  8.83it/s]Epoch 4/10:  25%|██▌       | 8/32 [00:00<00:02,  8.93it/s]Epoch 4/10:  28%|██▊       | 9/32 [00:01<00:02,  8.99it/s]Epoch 4/10:  31%|███▏      | 10/32 [00:01<00:02,  9.04it/s]Epoch 4/10:  34%|███▍      | 11/32 [00:01<00:02,  9.07it/s]Epoch 4/10:  38%|███▊      | 12/32 [00:01<00:02,  9.09it/s]Epoch 4/10:  41%|████      | 13/32 [00:01<00:02,  9.10it/s]Epoch 4/10:  44%|████▍     | 14/32 [00:01<00:01,  9.11it/s]Epoch 4/10:  47%|████▋     | 15/32 [00:01<00:01,  9.11it/s]Epoch 4/10:  50%|█████     | 16/32 [00:01<00:01,  9.12it/s]Epoch 4/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.13it/s]Epoch 4/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.13it/s]Epoch 4/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.12it/s]Epoch 4/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.12it/s]Epoch 4/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.12it/s]Epoch 4/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.11it/s]Epoch 4/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.10it/s]Epoch 4/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.10it/s]Epoch 4/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.11it/s]Epoch 4/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.12it/s]Epoch 4/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.12it/s]Epoch 4/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.12it/s]Epoch 4/10:  91%|█████████ | 29/32 [00:03<00:00,  9.12it/s]Epoch 4/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.13it/s]Epoch 4/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.12it/s]Epoch 4/10: 100%|██████████| 32/32 [00:03<00:00,  8.99it/s]
[2025-04-29 18:45:21,554][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6940
[2025-04-29 18:45:21,845][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6870, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:45:21,846][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▆▅▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68655
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69401
wandb:           train_time 16.8324
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68702
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184453-4jj9pn85
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184453-4jj9pn85/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs32 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs64
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:45:40,150][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs64
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs64
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 64
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 2
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:45:40,150][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:45:40,150][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:45:40,150][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:45:40,154][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:45:40,155][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:45:41,598][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:45:44,336][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:45:44,336][src.data.datasets][INFO] - Loading 'control_question_type_seed2' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:45:44,443][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:45:44,474][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed2' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed2/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:48:35 2025).
[2025-04-29 18:45:44,530][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:45:44,540][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:45:44,541][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:45:44,541][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:45:44,557][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:45:44,581][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:45:44,590][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:45:44,592][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:45:44,592][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:45:44,593][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:45:44,628][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:45:44,660][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:45:44,670][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:45:44,671][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:45:44,672][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:45:44,673][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:45:44,673][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:45:44,673][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:45:44,673][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:45:44,674][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:45:44,674][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:45:44,674][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:45:44,674][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:45:44,674][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 18:45:44,674][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:45:44,674][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:45:44,675][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:45:44,675][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:45:44,675][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:45:44,676][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:45:44,676][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:45:44,676][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:45:44,676][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:45:44,676][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:45:44,676][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:45:44,676][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:45:44,680][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:45:44,680][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:45:48,677][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:45:48,678][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:45:48,679][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:45:48,679][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:45:48,679][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   6%|▋         | 1/16 [00:01<00:17,  1.15s/it]Epoch 1/10:  12%|█▎        | 2/16 [00:01<00:08,  1.63it/s]Epoch 1/10:  19%|█▉        | 3/16 [00:01<00:05,  2.25it/s]Epoch 1/10:  25%|██▌       | 4/16 [00:01<00:04,  2.74it/s]Epoch 1/10:  31%|███▏      | 5/16 [00:02<00:03,  3.12it/s]Epoch 1/10:  38%|███▊      | 6/16 [00:02<00:02,  3.40it/s]Epoch 1/10:  44%|████▍     | 7/16 [00:02<00:02,  3.60it/s]Epoch 1/10:  50%|█████     | 8/16 [00:02<00:02,  3.75it/s]Epoch 1/10:  56%|█████▋    | 9/16 [00:03<00:01,  3.87it/s]Epoch 1/10:  62%|██████▎   | 10/16 [00:03<00:01,  3.95it/s]Epoch 1/10:  69%|██████▉   | 11/16 [00:03<00:01,  4.00it/s]Epoch 1/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.05it/s]Epoch 1/10:  81%|████████▏ | 13/16 [00:04<00:00,  4.07it/s]Epoch 1/10:  88%|████████▊ | 14/16 [00:04<00:00,  4.09it/s]Epoch 1/10:  94%|█████████▍| 15/16 [00:04<00:00,  4.10it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  4.72it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  3.39it/s]
[2025-04-29 18:45:55,326][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7017
[2025-04-29 18:45:55,625][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6892, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   6%|▋         | 1/16 [00:00<00:06,  2.48it/s]Epoch 2/10:  12%|█▎        | 2/16 [00:00<00:04,  3.24it/s]Epoch 2/10:  19%|█▉        | 3/16 [00:00<00:03,  3.59it/s]Epoch 2/10:  25%|██▌       | 4/16 [00:01<00:03,  3.78it/s]Epoch 2/10:  31%|███▏      | 5/16 [00:01<00:02,  3.91it/s]Epoch 2/10:  38%|███▊      | 6/16 [00:01<00:02,  3.98it/s]Epoch 2/10:  44%|████▍     | 7/16 [00:01<00:02,  4.03it/s]Epoch 2/10:  50%|█████     | 8/16 [00:02<00:01,  4.05it/s]Epoch 2/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.07it/s]Epoch 2/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.09it/s]Epoch 2/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.10it/s]Epoch 2/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.11it/s]Epoch 2/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.12it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.02it/s]
[2025-04-29 18:46:00,178][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.7001
[2025-04-29 18:46:00,494][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6891, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   6%|▋         | 1/16 [00:00<00:05,  2.56it/s]Epoch 3/10:  12%|█▎        | 2/16 [00:00<00:04,  3.29it/s]Epoch 3/10:  19%|█▉        | 3/16 [00:00<00:03,  3.64it/s]Epoch 3/10:  25%|██▌       | 4/16 [00:01<00:03,  3.82it/s]Epoch 3/10:  31%|███▏      | 5/16 [00:01<00:02,  3.92it/s]Epoch 3/10:  38%|███▊      | 6/16 [00:01<00:02,  3.99it/s]Epoch 3/10:  44%|████▍     | 7/16 [00:01<00:02,  4.03it/s]Epoch 3/10:  50%|█████     | 8/16 [00:02<00:01,  4.06it/s]Epoch 3/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.08it/s]Epoch 3/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.11it/s]Epoch 3/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.12it/s]Epoch 3/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.13it/s]Epoch 3/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.14it/s]Epoch 3/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.15it/s]Epoch 3/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.15it/s]Epoch 3/10: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]Epoch 3/10: 100%|██████████| 16/16 [00:03<00:00,  4.04it/s]
[2025-04-29 18:46:05,080][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6994
[2025-04-29 18:46:05,426][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   6%|▋         | 1/16 [00:00<00:06,  2.40it/s]Epoch 4/10:  12%|█▎        | 2/16 [00:00<00:04,  3.19it/s]Epoch 4/10:  19%|█▉        | 3/16 [00:00<00:03,  3.57it/s]Epoch 4/10:  25%|██▌       | 4/16 [00:01<00:03,  3.78it/s]Epoch 4/10:  31%|███▏      | 5/16 [00:01<00:02,  3.91it/s]Epoch 4/10:  38%|███▊      | 6/16 [00:01<00:02,  3.99it/s]Epoch 4/10:  44%|████▍     | 7/16 [00:01<00:02,  4.05it/s]Epoch 4/10:  50%|█████     | 8/16 [00:02<00:01,  4.08it/s]Epoch 4/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.11it/s]Epoch 4/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 4/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.14it/s]Epoch 4/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 4/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 4/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.15it/s]Epoch 4/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.15it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.03it/s]
[2025-04-29 18:46:09,938][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6974
[2025-04-29 18:46:10,292][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   6%|▋         | 1/16 [00:00<00:06,  2.49it/s]Epoch 5/10:  12%|█▎        | 2/16 [00:00<00:04,  3.26it/s]Epoch 5/10:  19%|█▉        | 3/16 [00:00<00:03,  3.62it/s]Epoch 5/10:  25%|██▌       | 4/16 [00:01<00:03,  3.81it/s]Epoch 5/10:  31%|███▏      | 5/16 [00:01<00:02,  3.93it/s]Epoch 5/10:  38%|███▊      | 6/16 [00:01<00:02,  4.01it/s]Epoch 5/10:  44%|████▍     | 7/16 [00:01<00:02,  4.07it/s]Epoch 5/10:  50%|█████     | 8/16 [00:02<00:01,  4.09it/s]Epoch 5/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.11it/s]Epoch 5/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.12it/s]Epoch 5/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.13it/s]Epoch 5/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 5/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 5/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 5/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 5/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 5/10: 100%|██████████| 16/16 [00:03<00:00,  4.00it/s]
[2025-04-29 18:46:14,838][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6974
[2025-04-29 18:46:15,187][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 6/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 6/10:   6%|▋         | 1/16 [00:00<00:05,  2.55it/s]Epoch 6/10:  12%|█▎        | 2/16 [00:00<00:04,  3.28it/s]Epoch 6/10:  19%|█▉        | 3/16 [00:00<00:03,  3.61it/s]Epoch 6/10:  25%|██▌       | 4/16 [00:01<00:03,  3.79it/s]Epoch 6/10:  31%|███▏      | 5/16 [00:01<00:02,  3.92it/s]Epoch 6/10:  38%|███▊      | 6/16 [00:01<00:02,  4.00it/s]Epoch 6/10:  44%|████▍     | 7/16 [00:01<00:02,  4.05it/s]Epoch 6/10:  50%|█████     | 8/16 [00:02<00:01,  4.08it/s]Epoch 6/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.11it/s]Epoch 6/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 6/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.15it/s]Epoch 6/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.16it/s]Epoch 6/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 6/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 6/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.05it/s]
[2025-04-29 18:46:19,692][src.training.lm_trainer][INFO] - Epoch 6/10, Train Loss: 0.6992
[2025-04-29 18:46:20,038][src.training.lm_trainer][INFO] - Epoch 6/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 7/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 7/10:   6%|▋         | 1/16 [00:00<00:06,  2.48it/s]Epoch 7/10:  12%|█▎        | 2/16 [00:00<00:04,  3.26it/s]Epoch 7/10:  19%|█▉        | 3/16 [00:00<00:03,  3.62it/s]Epoch 7/10:  25%|██▌       | 4/16 [00:01<00:03,  3.82it/s]Epoch 7/10:  31%|███▏      | 5/16 [00:01<00:02,  3.94it/s]Epoch 7/10:  38%|███▊      | 6/16 [00:01<00:02,  4.01it/s]Epoch 7/10:  44%|████▍     | 7/16 [00:01<00:02,  4.06it/s]Epoch 7/10:  50%|█████     | 8/16 [00:02<00:01,  4.09it/s]Epoch 7/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.12it/s]Epoch 7/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 7/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.14it/s]Epoch 7/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 7/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.79it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.04it/s]
[2025-04-29 18:46:23,996][src.training.lm_trainer][INFO] - Epoch 7/10, Train Loss: 0.6959
[2025-04-29 18:46:24,344][src.training.lm_trainer][INFO] - Epoch 7/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 8/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 8/10:   6%|▋         | 1/16 [00:00<00:05,  2.64it/s]Epoch 8/10:  12%|█▎        | 2/16 [00:00<00:04,  3.38it/s]Epoch 8/10:  19%|█▉        | 3/16 [00:00<00:03,  3.72it/s]Epoch 8/10:  25%|██▌       | 4/16 [00:01<00:03,  3.88it/s]Epoch 8/10:  31%|███▏      | 5/16 [00:01<00:02,  3.98it/s]Epoch 8/10:  38%|███▊      | 6/16 [00:01<00:02,  4.04it/s]Epoch 8/10:  44%|████▍     | 7/16 [00:01<00:02,  4.08it/s]Epoch 8/10:  50%|█████     | 8/16 [00:02<00:01,  4.11it/s]Epoch 8/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.13it/s]Epoch 8/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.14it/s]Epoch 8/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.15it/s]Epoch 8/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.08it/s]
[2025-04-29 18:46:28,271][src.training.lm_trainer][INFO] - Epoch 8/10, Train Loss: 0.6972
[2025-04-29 18:46:28,628][src.training.lm_trainer][INFO] - Epoch 8/10, Val Loss: 0.6891, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:46:28,628][src.training.lm_trainer][INFO] - Early stopping at epoch 8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁
wandb:        best_val_loss █▄▂▁▁
wandb:                epoch ▁▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ███████▁
wandb:           train_loss █▆▅▃▃▅▁▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁
wandb:             val_loss █▄▂▁▁▂▃▃
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68898
wandb:                epoch 8
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69716
wandb:           train_time 38.0293
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68905
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184540-n0ko125z
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184540-n0ko125z/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control2_bs64 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:46:50,644][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs8
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs8
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 8
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 3
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:46:50,644][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:46:50,644][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:46:50,644][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:46:50,648][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:46:50,649][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:46:52,411][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:46:55,205][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:46:55,205][src.data.datasets][INFO] - Loading 'control_question_type_seed3' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:46:55,275][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:46:55,315][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:46:55,500][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:46:55,510][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:46:55,511][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:46:55,522][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:46:55,550][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:46:55,604][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:46:55,626][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:46:55,628][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:46:55,628][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:46:55,629][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:46:55,675][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:46:55,718][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:46:55,739][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:46:55,741][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:46:55,741][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:46:55,742][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:46:55,742][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:46:55,742][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:46:55,742][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:46:55,743][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:46:55,743][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:46:55,743][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:46:55,743][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:46:55,743][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:46:55,743][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:46:55,744][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:46:55,744][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:46:55,744][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:46:55,744][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:46:55,744][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:46:55,744][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:46:55,744][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:46:55,745][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:46:55,745][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:46:55,745][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:46:55,746][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:46:55,746][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:46:55,748][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:46:55,749][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:47:00,232][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:47:00,233][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:47:00,234][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:47:00,234][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:47:00,234][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   1%|          | 1/125 [00:01<02:16,  1.10s/it]Epoch 1/10:   4%|▍         | 5/125 [00:01<00:23,  5.20it/s]Epoch 1/10:   7%|▋         | 9/125 [00:01<00:12,  9.56it/s]Epoch 1/10:  10%|█         | 13/125 [00:01<00:08, 13.71it/s]Epoch 1/10:  14%|█▎        | 17/125 [00:01<00:06, 17.44it/s]Epoch 1/10:  17%|█▋        | 21/125 [00:01<00:05, 20.61it/s]Epoch 1/10:  20%|██        | 25/125 [00:01<00:04, 23.19it/s]Epoch 1/10:  23%|██▎       | 29/125 [00:02<00:03, 25.20it/s]Epoch 1/10:  26%|██▋       | 33/125 [00:02<00:03, 26.73it/s]Epoch 1/10:  30%|██▉       | 37/125 [00:02<00:03, 27.87it/s]Epoch 1/10:  33%|███▎      | 41/125 [00:02<00:02, 28.68it/s]Epoch 1/10:  36%|███▌      | 45/125 [00:02<00:02, 29.28it/s]Epoch 1/10:  39%|███▉      | 49/125 [00:02<00:02, 29.72it/s]Epoch 1/10:  42%|████▏     | 53/125 [00:02<00:02, 30.00it/s]Epoch 1/10:  46%|████▌     | 57/125 [00:02<00:02, 30.23it/s]Epoch 1/10:  49%|████▉     | 61/125 [00:03<00:02, 30.38it/s]Epoch 1/10:  52%|█████▏    | 65/125 [00:03<00:01, 30.50it/s]Epoch 1/10:  55%|█████▌    | 69/125 [00:03<00:01, 30.58it/s]Epoch 1/10:  58%|█████▊    | 73/125 [00:03<00:01, 30.65it/s]Epoch 1/10:  62%|██████▏   | 77/125 [00:03<00:01, 30.69it/s]Epoch 1/10:  65%|██████▍   | 81/125 [00:03<00:01, 30.72it/s]Epoch 1/10:  68%|██████▊   | 85/125 [00:03<00:01, 30.74it/s]Epoch 1/10:  71%|███████   | 89/125 [00:03<00:01, 30.76it/s]Epoch 1/10:  74%|███████▍  | 93/125 [00:04<00:01, 30.77it/s]Epoch 1/10:  78%|███████▊  | 97/125 [00:04<00:00, 30.77it/s]Epoch 1/10:  81%|████████  | 101/125 [00:04<00:00, 30.78it/s]Epoch 1/10:  84%|████████▍ | 105/125 [00:04<00:00, 30.79it/s]Epoch 1/10:  87%|████████▋ | 109/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  90%|█████████ | 113/125 [00:04<00:00, 30.80it/s]Epoch 1/10:  94%|█████████▎| 117/125 [00:04<00:00, 30.79it/s]Epoch 1/10:  97%|█████████▋| 121/125 [00:05<00:00, 30.81it/s]Epoch 1/10: 100%|██████████| 125/125 [00:05<00:00, 32.14it/s]Epoch 1/10: 100%|██████████| 125/125 [00:05<00:00, 24.24it/s]
[2025-04-29 18:47:07,481][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7005
[2025-04-29 18:47:07,803][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6857, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   1%|          | 1/125 [00:00<00:18,  6.74it/s]Epoch 2/10:   4%|▍         | 5/125 [00:00<00:05, 20.03it/s]Epoch 2/10:   7%|▋         | 9/125 [00:00<00:04, 24.78it/s]Epoch 2/10:  10%|█         | 13/125 [00:00<00:04, 27.10it/s]Epoch 2/10:  14%|█▎        | 17/125 [00:00<00:03, 28.42it/s]Epoch 2/10:  17%|█▋        | 21/125 [00:00<00:03, 29.21it/s]Epoch 2/10:  20%|██        | 25/125 [00:00<00:03, 29.72it/s]Epoch 2/10:  23%|██▎       | 29/125 [00:01<00:03, 30.06it/s]Epoch 2/10:  26%|██▋       | 33/125 [00:01<00:03, 30.29it/s]Epoch 2/10:  30%|██▉       | 37/125 [00:01<00:02, 30.45it/s]Epoch 2/10:  33%|███▎      | 41/125 [00:01<00:02, 30.56it/s]Epoch 2/10:  36%|███▌      | 45/125 [00:01<00:02, 30.62it/s]Epoch 2/10:  39%|███▉      | 49/125 [00:01<00:02, 30.67it/s]Epoch 2/10:  42%|████▏     | 53/125 [00:01<00:02, 30.70it/s]Epoch 2/10:  46%|████▌     | 57/125 [00:01<00:02, 30.73it/s]Epoch 2/10:  49%|████▉     | 61/125 [00:02<00:02, 30.74it/s]Epoch 2/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.75it/s]Epoch 2/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.77it/s]Epoch 2/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.79it/s]Epoch 2/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.79it/s]Epoch 2/10:  71%|███████   | 89/125 [00:03<00:01, 30.79it/s]Epoch 2/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.79it/s]Epoch 2/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.79it/s]Epoch 2/10:  81%|████████  | 101/125 [00:03<00:00, 30.79it/s]Epoch 2/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.80it/s]Epoch 2/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.80it/s]Epoch 2/10:  90%|█████████ | 113/125 [00:03<00:00, 30.79it/s]Epoch 2/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.78it/s]Epoch 2/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.79it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 32.14it/s]Epoch 2/10: 100%|██████████| 125/125 [00:04<00:00, 29.73it/s]
[2025-04-29 18:47:12,565][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6981
[2025-04-29 18:47:12,910][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6861, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   1%|          | 1/125 [00:00<00:17,  7.03it/s]Epoch 3/10:   4%|▍         | 5/125 [00:00<00:05, 20.35it/s]Epoch 3/10:   7%|▋         | 9/125 [00:00<00:04, 24.95it/s]Epoch 3/10:  10%|█         | 13/125 [00:00<00:04, 27.17it/s]Epoch 3/10:  14%|█▎        | 17/125 [00:00<00:03, 28.42it/s]Epoch 3/10:  17%|█▋        | 21/125 [00:00<00:03, 29.17it/s]Epoch 3/10:  20%|██        | 25/125 [00:00<00:03, 29.65it/s]Epoch 3/10:  23%|██▎       | 29/125 [00:01<00:03, 29.98it/s]Epoch 3/10:  26%|██▋       | 33/125 [00:01<00:03, 30.19it/s]Epoch 3/10:  30%|██▉       | 37/125 [00:01<00:02, 30.34it/s]Epoch 3/10:  33%|███▎      | 41/125 [00:01<00:02, 30.43it/s]Epoch 3/10:  36%|███▌      | 45/125 [00:01<00:02, 30.50it/s]Epoch 3/10:  39%|███▉      | 49/125 [00:01<00:02, 30.54it/s]Epoch 3/10:  42%|████▏     | 53/125 [00:01<00:02, 30.59it/s]Epoch 3/10:  46%|████▌     | 57/125 [00:01<00:02, 30.61it/s]Epoch 3/10:  49%|████▉     | 61/125 [00:02<00:02, 30.62it/s]Epoch 3/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.63it/s]Epoch 3/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.63it/s]Epoch 3/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.66it/s]Epoch 3/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.60it/s]Epoch 3/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.62it/s]Epoch 3/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.62it/s]Epoch 3/10:  71%|███████   | 89/125 [00:03<00:01, 30.63it/s]Epoch 3/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.64it/s]Epoch 3/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.64it/s]Epoch 3/10:  81%|████████  | 101/125 [00:03<00:00, 30.64it/s]Epoch 3/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.64it/s]Epoch 3/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.65it/s]Epoch 3/10:  90%|█████████ | 113/125 [00:03<00:00, 30.66it/s]Epoch 3/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.64it/s]Epoch 3/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.67it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 32.01it/s]Epoch 3/10: 100%|██████████| 125/125 [00:04<00:00, 29.63it/s]
[2025-04-29 18:47:17,132][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6960
[2025-04-29 18:47:17,462][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6868, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   1%|          | 1/125 [00:00<00:15,  7.85it/s]Epoch 4/10:   4%|▍         | 5/125 [00:00<00:05, 21.24it/s]Epoch 4/10:   7%|▋         | 9/125 [00:00<00:04, 25.53it/s]Epoch 4/10:  10%|█         | 13/125 [00:00<00:04, 27.54it/s]Epoch 4/10:  14%|█▎        | 17/125 [00:00<00:03, 28.66it/s]Epoch 4/10:  17%|█▋        | 21/125 [00:00<00:03, 29.34it/s]Epoch 4/10:  20%|██        | 25/125 [00:00<00:03, 29.76it/s]Epoch 4/10:  23%|██▎       | 29/125 [00:01<00:03, 30.02it/s]Epoch 4/10:  26%|██▋       | 33/125 [00:01<00:03, 30.22it/s]Epoch 4/10:  30%|██▉       | 37/125 [00:01<00:02, 30.35it/s]Epoch 4/10:  33%|███▎      | 41/125 [00:01<00:02, 30.45it/s]Epoch 4/10:  36%|███▌      | 45/125 [00:01<00:02, 30.51it/s]Epoch 4/10:  39%|███▉      | 49/125 [00:01<00:02, 30.55it/s]Epoch 4/10:  42%|████▏     | 53/125 [00:01<00:02, 30.57it/s]Epoch 4/10:  46%|████▌     | 57/125 [00:01<00:02, 30.60it/s]Epoch 4/10:  49%|████▉     | 61/125 [00:02<00:02, 30.61it/s]Epoch 4/10:  52%|█████▏    | 65/125 [00:02<00:01, 30.62it/s]Epoch 4/10:  55%|█████▌    | 69/125 [00:02<00:01, 30.63it/s]Epoch 4/10:  58%|█████▊    | 73/125 [00:02<00:01, 30.64it/s]Epoch 4/10:  62%|██████▏   | 77/125 [00:02<00:01, 30.62it/s]Epoch 4/10:  65%|██████▍   | 81/125 [00:02<00:01, 30.61it/s]Epoch 4/10:  68%|██████▊   | 85/125 [00:02<00:01, 30.62it/s]Epoch 4/10:  71%|███████   | 89/125 [00:03<00:01, 30.62it/s]Epoch 4/10:  74%|███████▍  | 93/125 [00:03<00:01, 30.62it/s]Epoch 4/10:  78%|███████▊  | 97/125 [00:03<00:00, 30.62it/s]Epoch 4/10:  81%|████████  | 101/125 [00:03<00:00, 30.63it/s]Epoch 4/10:  84%|████████▍ | 105/125 [00:03<00:00, 30.64it/s]Epoch 4/10:  87%|████████▋ | 109/125 [00:03<00:00, 30.65it/s]Epoch 4/10:  90%|█████████ | 113/125 [00:03<00:00, 30.65it/s]Epoch 4/10:  94%|█████████▎| 117/125 [00:03<00:00, 30.63it/s]Epoch 4/10:  97%|█████████▋| 121/125 [00:04<00:00, 30.65it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 32.00it/s]Epoch 4/10: 100%|██████████| 125/125 [00:04<00:00, 29.69it/s]
[2025-04-29 18:47:21,675][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6949
[2025-04-29 18:47:22,005][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6874, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:47:22,006][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▅▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68567
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69489
wandb:           train_time 19.68471
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68738
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184650-ny9bx7lo
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184650-ny9bx7lo/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs8 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs16
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:47:41,978][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs16
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs16
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 16
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 3
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:47:41,978][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:47:41,978][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:47:41,979][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:47:41,983][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:47:41,983][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:47:43,361][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:47:46,062][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:47:46,063][src.data.datasets][INFO] - Loading 'control_question_type_seed3' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:47:46,101][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:47:46,130][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:47:46,194][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:47:46,204][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:47:46,204][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:47:46,205][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:47:46,241][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:47:46,301][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:47:46,311][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:47:46,313][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:47:46,313][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:47:46,314][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:47:46,339][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:47:46,387][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:47:46,406][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:47:46,407][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:47:46,408][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:47:46,408][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:47:46,409][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:47:46,409][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:47:46,409][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:47:46,409][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:47:46,409][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:47:46,409][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:47:46,410][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:47:46,410][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:47:46,410][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:47:46,411][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:47:46,411][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:47:46,411][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:47:46,412][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:47:46,412][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:47:46,412][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:47:46,416][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:47:46,416][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:47:50,380][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:47:50,381][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:47:50,382][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:47:50,382][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:47:50,383][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   2%|▏         | 1/63 [00:01<01:08,  1.10s/it]Epoch 1/10:   5%|▍         | 3/63 [00:01<00:19,  3.06it/s]Epoch 1/10:   8%|▊         | 5/63 [00:01<00:10,  5.34it/s]Epoch 1/10:  11%|█         | 7/63 [00:01<00:07,  7.60it/s]Epoch 1/10:  14%|█▍        | 9/63 [00:01<00:05,  9.71it/s]Epoch 1/10:  17%|█▋        | 11/63 [00:01<00:04, 11.58it/s]Epoch 1/10:  21%|██        | 13/63 [00:01<00:03, 13.12it/s]Epoch 1/10:  24%|██▍       | 15/63 [00:01<00:03, 14.38it/s]Epoch 1/10:  27%|██▋       | 17/63 [00:01<00:03, 15.33it/s]Epoch 1/10:  30%|███       | 19/63 [00:02<00:02, 16.08it/s]Epoch 1/10:  33%|███▎      | 21/63 [00:02<00:02, 16.61it/s]Epoch 1/10:  37%|███▋      | 23/63 [00:02<00:02, 17.01it/s]Epoch 1/10:  40%|███▉      | 25/63 [00:02<00:02, 17.26it/s]Epoch 1/10:  43%|████▎     | 27/63 [00:02<00:02, 17.46it/s]Epoch 1/10:  46%|████▌     | 29/63 [00:02<00:01, 17.60it/s]Epoch 1/10:  49%|████▉     | 31/63 [00:02<00:01, 17.71it/s]Epoch 1/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.78it/s]Epoch 1/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.83it/s]Epoch 1/10:  59%|█████▊    | 37/63 [00:03<00:01, 17.86it/s]Epoch 1/10:  62%|██████▏   | 39/63 [00:03<00:01, 17.90it/s]Epoch 1/10:  65%|██████▌   | 41/63 [00:03<00:01, 17.93it/s]Epoch 1/10:  68%|██████▊   | 43/63 [00:03<00:01, 17.93it/s]Epoch 1/10:  71%|███████▏  | 45/63 [00:03<00:01, 17.94it/s]Epoch 1/10:  75%|███████▍  | 47/63 [00:03<00:00, 17.94it/s]Epoch 1/10:  78%|███████▊  | 49/63 [00:03<00:00, 17.96it/s]Epoch 1/10:  81%|████████  | 51/63 [00:03<00:00, 17.95it/s]Epoch 1/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.95it/s]Epoch 1/10:  87%|████████▋ | 55/63 [00:04<00:00, 17.94it/s]Epoch 1/10:  90%|█████████ | 57/63 [00:04<00:00, 17.94it/s]Epoch 1/10:  94%|█████████▎| 59/63 [00:04<00:00, 17.95it/s]Epoch 1/10:  97%|█████████▋| 61/63 [00:04<00:00, 17.96it/s]Epoch 1/10: 100%|██████████| 63/63 [00:04<00:00, 13.81it/s]
[2025-04-29 18:47:57,154][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7011
[2025-04-29 18:47:57,439][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   2%|▏         | 1/63 [00:00<00:09,  6.30it/s]Epoch 2/10:   5%|▍         | 3/63 [00:00<00:04, 12.11it/s]Epoch 2/10:   8%|▊         | 5/63 [00:00<00:03, 14.55it/s]Epoch 2/10:  11%|█         | 7/63 [00:00<00:03, 15.84it/s]Epoch 2/10:  14%|█▍        | 9/63 [00:00<00:03, 16.58it/s]Epoch 2/10:  17%|█▋        | 11/63 [00:00<00:03, 17.05it/s]Epoch 2/10:  21%|██        | 13/63 [00:00<00:02, 17.37it/s]Epoch 2/10:  24%|██▍       | 15/63 [00:00<00:02, 17.56it/s]Epoch 2/10:  27%|██▋       | 17/63 [00:01<00:02, 17.70it/s]Epoch 2/10:  30%|███       | 19/63 [00:01<00:02, 17.78it/s]Epoch 2/10:  33%|███▎      | 21/63 [00:01<00:02, 17.87it/s]Epoch 2/10:  37%|███▋      | 23/63 [00:01<00:02, 17.89it/s]Epoch 2/10:  40%|███▉      | 25/63 [00:01<00:02, 17.93it/s]Epoch 2/10:  43%|████▎     | 27/63 [00:01<00:02, 17.93it/s]Epoch 2/10:  46%|████▌     | 29/63 [00:01<00:01, 17.96it/s]Epoch 2/10:  49%|████▉     | 31/63 [00:01<00:01, 17.96it/s]Epoch 2/10:  52%|█████▏    | 33/63 [00:01<00:01, 17.98it/s]Epoch 2/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.97it/s]Epoch 2/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.96it/s]Epoch 2/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.95it/s]Epoch 2/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.97it/s]Epoch 2/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.96it/s]Epoch 2/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.98it/s]Epoch 2/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.97it/s]Epoch 2/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.99it/s]Epoch 2/10:  81%|████████  | 51/63 [00:02<00:00, 17.97it/s]Epoch 2/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.99it/s]Epoch 2/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.96it/s]Epoch 2/10:  90%|█████████ | 57/63 [00:03<00:00, 17.98it/s]Epoch 2/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.97it/s]Epoch 2/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.99it/s]Epoch 2/10: 100%|██████████| 63/63 [00:03<00:00, 17.36it/s]
[2025-04-29 18:48:01,645][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6983
[2025-04-29 18:48:01,945][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   2%|▏         | 1/63 [00:00<00:14,  4.21it/s]Epoch 3/10:   5%|▍         | 3/63 [00:00<00:06,  9.71it/s]Epoch 3/10:   8%|▊         | 5/63 [00:00<00:04, 12.71it/s]Epoch 3/10:  11%|█         | 7/63 [00:00<00:03, 14.50it/s]Epoch 3/10:  14%|█▍        | 9/63 [00:00<00:03, 15.65it/s]Epoch 3/10:  17%|█▋        | 11/63 [00:00<00:03, 16.39it/s]Epoch 3/10:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 3/10:  24%|██▍       | 15/63 [00:01<00:02, 17.23it/s]Epoch 3/10:  27%|██▋       | 17/63 [00:01<00:02, 17.46it/s]Epoch 3/10:  30%|███       | 19/63 [00:01<00:02, 17.60it/s]Epoch 3/10:  33%|███▎      | 21/63 [00:01<00:02, 17.73it/s]Epoch 3/10:  37%|███▋      | 23/63 [00:01<00:02, 17.80it/s]Epoch 3/10:  40%|███▉      | 25/63 [00:01<00:02, 17.87it/s]Epoch 3/10:  43%|████▎     | 27/63 [00:01<00:02, 17.89it/s]Epoch 3/10:  46%|████▌     | 29/63 [00:01<00:01, 17.94it/s]Epoch 3/10:  49%|████▉     | 31/63 [00:01<00:01, 17.94it/s]Epoch 3/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.96it/s]Epoch 3/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.96it/s]Epoch 3/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.99it/s]Epoch 3/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.98it/s]Epoch 3/10:  65%|██████▌   | 41/63 [00:02<00:01, 18.00it/s]Epoch 3/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.98it/s]Epoch 3/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.99it/s]Epoch 3/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.99it/s]Epoch 3/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.99it/s]Epoch 3/10:  81%|████████  | 51/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  84%|████████▍ | 53/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  87%|████████▋ | 55/63 [00:03<00:00, 18.00it/s]Epoch 3/10:  90%|█████████ | 57/63 [00:03<00:00, 18.01it/s]Epoch 3/10:  94%|█████████▎| 59/63 [00:03<00:00, 18.02it/s]Epoch 3/10:  97%|█████████▋| 61/63 [00:03<00:00, 18.02it/s]Epoch 3/10: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 18:48:06,694][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6989
[2025-04-29 18:48:07,089][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   2%|▏         | 1/63 [00:00<00:13,  4.45it/s]Epoch 4/10:   5%|▍         | 3/63 [00:00<00:05, 10.03it/s]Epoch 4/10:   8%|▊         | 5/63 [00:00<00:04, 12.99it/s]Epoch 4/10:  11%|█         | 7/63 [00:00<00:03, 14.72it/s]Epoch 4/10:  14%|█▍        | 9/63 [00:00<00:03, 15.81it/s]Epoch 4/10:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 4/10:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 4/10:  24%|██▍       | 15/63 [00:01<00:02, 17.30it/s]Epoch 4/10:  27%|██▋       | 17/63 [00:01<00:02, 17.52it/s]Epoch 4/10:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 4/10:  33%|███▎      | 21/63 [00:01<00:02, 17.68it/s]Epoch 4/10:  37%|███▋      | 23/63 [00:01<00:02, 17.78it/s]Epoch 4/10:  40%|███▉      | 25/63 [00:01<00:02, 17.85it/s]Epoch 4/10:  43%|████▎     | 27/63 [00:01<00:02, 17.90it/s]Epoch 4/10:  46%|████▌     | 29/63 [00:01<00:01, 17.91it/s]Epoch 4/10:  49%|████▉     | 31/63 [00:01<00:01, 17.94it/s]Epoch 4/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.94it/s]Epoch 4/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.96it/s]Epoch 4/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.95it/s]Epoch 4/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.96it/s]Epoch 4/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.94it/s]Epoch 4/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.97it/s]Epoch 4/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.96it/s]Epoch 4/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.96it/s]Epoch 4/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.95it/s]Epoch 4/10:  81%|████████  | 51/63 [00:03<00:00, 17.97it/s]Epoch 4/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.97it/s]Epoch 4/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.99it/s]Epoch 4/10:  90%|█████████ | 57/63 [00:03<00:00, 17.97it/s]Epoch 4/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.99it/s]Epoch 4/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.99it/s]Epoch 4/10: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 18:48:10,800][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6980
[2025-04-29 18:48:11,198][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/63 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   2%|▏         | 1/63 [00:00<00:14,  4.22it/s]Epoch 5/10:   5%|▍         | 3/63 [00:00<00:06,  9.71it/s]Epoch 5/10:   8%|▊         | 5/63 [00:00<00:04, 12.68it/s]Epoch 5/10:  11%|█         | 7/63 [00:00<00:03, 14.48it/s]Epoch 5/10:  14%|█▍        | 9/63 [00:00<00:03, 15.62it/s]Epoch 5/10:  17%|█▋        | 11/63 [00:00<00:03, 16.36it/s]Epoch 5/10:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 5/10:  24%|██▍       | 15/63 [00:01<00:02, 17.19it/s]Epoch 5/10:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 5/10:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 5/10:  33%|███▎      | 21/63 [00:01<00:02, 17.68it/s]Epoch 5/10:  37%|███▋      | 23/63 [00:01<00:02, 17.76it/s]Epoch 5/10:  40%|███▉      | 25/63 [00:01<00:02, 17.79it/s]Epoch 5/10:  43%|████▎     | 27/63 [00:01<00:02, 17.83it/s]Epoch 5/10:  46%|████▌     | 29/63 [00:01<00:01, 17.85it/s]Epoch 5/10:  49%|████▉     | 31/63 [00:01<00:01, 17.86it/s]Epoch 5/10:  52%|█████▏    | 33/63 [00:02<00:01, 17.88it/s]Epoch 5/10:  56%|█████▌    | 35/63 [00:02<00:01, 17.88it/s]Epoch 5/10:  59%|█████▊    | 37/63 [00:02<00:01, 17.89it/s]Epoch 5/10:  62%|██████▏   | 39/63 [00:02<00:01, 17.89it/s]Epoch 5/10:  65%|██████▌   | 41/63 [00:02<00:01, 17.89it/s]Epoch 5/10:  68%|██████▊   | 43/63 [00:02<00:01, 17.90it/s]Epoch 5/10:  71%|███████▏  | 45/63 [00:02<00:01, 17.88it/s]Epoch 5/10:  75%|███████▍  | 47/63 [00:02<00:00, 17.90it/s]Epoch 5/10:  78%|███████▊  | 49/63 [00:02<00:00, 17.87it/s]Epoch 5/10:  81%|████████  | 51/63 [00:03<00:00, 17.89it/s]Epoch 5/10:  84%|████████▍ | 53/63 [00:03<00:00, 17.89it/s]Epoch 5/10:  87%|████████▋ | 55/63 [00:03<00:00, 17.87it/s]Epoch 5/10:  90%|█████████ | 57/63 [00:03<00:00, 17.91it/s]Epoch 5/10:  94%|█████████▎| 59/63 [00:03<00:00, 17.90it/s]Epoch 5/10:  97%|█████████▋| 61/63 [00:03<00:00, 17.93it/s]Epoch 5/10: 100%|██████████| 63/63 [00:03<00:00, 16.88it/s]
[2025-04-29 18:48:14,933][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6963
[2025-04-29 18:48:15,309][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6888, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:48:15,310][src.training.lm_trainer][INFO] - Early stopping at epoch 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss █▄▅▃▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▁▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68839
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69629
wandb:           train_time 22.72078
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68877
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184742-lk0bznyg
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184742-lk0bznyg/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs16 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs32
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:48:35,423][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs32
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs32
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 32
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 3
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:48:35,424][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:48:35,424][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:48:35,424][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:48:35,428][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:48:35,428][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:48:37,182][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:48:39,926][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:48:39,926][src.data.datasets][INFO] - Loading 'control_question_type_seed3' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:48:39,976][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:48:40,016][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:48:40,078][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:48:40,088][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:48:40,089][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:48:40,090][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:48:40,102][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:48:40,130][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:48:40,139][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:48:40,140][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:48:40,140][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:48:40,141][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:48:40,164][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:48:40,222][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:48:40,241][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:48:40,243][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:48:40,243][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:48:40,243][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:48:40,244][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:48:40,244][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:48:40,244][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:48:40,244][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:48:40,245][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:48:40,245][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:48:40,245][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:48:40,246][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:48:40,246][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:48:40,246][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:48:40,247][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:48:40,247][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:48:40,247][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:48:40,247][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:48:40,247][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:48:40,247][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:48:40,252][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:48:40,252][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:48:44,591][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:48:44,592][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:48:44,593][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:48:44,593][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:48:44,593][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   3%|▎         | 1/32 [00:01<00:36,  1.16s/it]Epoch 1/10:   6%|▋         | 2/32 [00:01<00:16,  1.84it/s]Epoch 1/10:   9%|▉         | 3/32 [00:01<00:10,  2.90it/s]Epoch 1/10:  12%|█▎        | 4/32 [00:01<00:07,  3.97it/s]Epoch 1/10:  16%|█▌        | 5/32 [00:01<00:05,  4.99it/s]Epoch 1/10:  19%|█▉        | 6/32 [00:01<00:04,  5.90it/s]Epoch 1/10:  22%|██▏       | 7/32 [00:01<00:03,  6.68it/s]Epoch 1/10:  25%|██▌       | 8/32 [00:01<00:03,  7.30it/s]Epoch 1/10:  28%|██▊       | 9/32 [00:02<00:02,  7.80it/s]Epoch 1/10:  31%|███▏      | 10/32 [00:02<00:02,  8.17it/s]Epoch 1/10:  34%|███▍      | 11/32 [00:02<00:02,  8.45it/s]Epoch 1/10:  38%|███▊      | 12/32 [00:02<00:02,  8.66it/s]Epoch 1/10:  41%|████      | 13/32 [00:02<00:02,  8.81it/s]Epoch 1/10:  44%|████▍     | 14/32 [00:02<00:02,  8.91it/s]Epoch 1/10:  47%|████▋     | 15/32 [00:02<00:01,  8.98it/s]Epoch 1/10:  50%|█████     | 16/32 [00:02<00:01,  9.03it/s]Epoch 1/10:  53%|█████▎    | 17/32 [00:02<00:01,  9.06it/s]Epoch 1/10:  56%|█████▋    | 18/32 [00:03<00:01,  9.09it/s]Epoch 1/10:  59%|█████▉    | 19/32 [00:03<00:01,  9.12it/s]Epoch 1/10:  62%|██████▎   | 20/32 [00:03<00:01,  9.13it/s]Epoch 1/10:  66%|██████▌   | 21/32 [00:03<00:01,  9.14it/s]Epoch 1/10:  69%|██████▉   | 22/32 [00:03<00:01,  9.15it/s]Epoch 1/10:  72%|███████▏  | 23/32 [00:03<00:00,  9.16it/s]Epoch 1/10:  75%|███████▌  | 24/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  78%|███████▊  | 25/32 [00:03<00:00,  9.14it/s]Epoch 1/10:  81%|████████▏ | 26/32 [00:03<00:00,  9.15it/s]Epoch 1/10:  84%|████████▍ | 27/32 [00:04<00:00,  9.15it/s]Epoch 1/10:  88%|████████▊ | 28/32 [00:04<00:00,  9.15it/s]Epoch 1/10:  91%|█████████ | 29/32 [00:04<00:00,  9.16it/s]Epoch 1/10:  94%|█████████▍| 30/32 [00:04<00:00,  9.17it/s]Epoch 1/10:  97%|█████████▋| 31/32 [00:04<00:00,  9.17it/s]Epoch 1/10: 100%|██████████| 32/32 [00:04<00:00,  7.09it/s]
[2025-04-29 18:48:51,011][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.7032
[2025-04-29 18:48:51,297][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6866, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   3%|▎         | 1/32 [00:00<00:06,  4.52it/s]Epoch 2/10:   6%|▋         | 2/32 [00:00<00:04,  6.42it/s]Epoch 2/10:   9%|▉         | 3/32 [00:00<00:03,  7.43it/s]Epoch 2/10:  12%|█▎        | 4/32 [00:00<00:03,  8.04it/s]Epoch 2/10:  16%|█▌        | 5/32 [00:00<00:03,  8.40it/s]Epoch 2/10:  19%|█▉        | 6/32 [00:00<00:03,  8.64it/s]Epoch 2/10:  22%|██▏       | 7/32 [00:00<00:02,  8.81it/s]Epoch 2/10:  25%|██▌       | 8/32 [00:00<00:02,  8.92it/s]Epoch 2/10:  28%|██▊       | 9/32 [00:01<00:02,  9.00it/s]Epoch 2/10:  31%|███▏      | 10/32 [00:01<00:02,  9.04it/s]Epoch 2/10:  34%|███▍      | 11/32 [00:01<00:02,  9.08it/s]Epoch 2/10:  38%|███▊      | 12/32 [00:01<00:02,  9.10it/s]Epoch 2/10:  41%|████      | 13/32 [00:01<00:02,  9.12it/s]Epoch 2/10:  44%|████▍     | 14/32 [00:01<00:01,  9.12it/s]Epoch 2/10:  47%|████▋     | 15/32 [00:01<00:01,  9.13it/s]Epoch 2/10:  50%|█████     | 16/32 [00:01<00:01,  9.14it/s]Epoch 2/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.14it/s]Epoch 2/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.16it/s]Epoch 2/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.15it/s]Epoch 2/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.16it/s]Epoch 2/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.16it/s]Epoch 2/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.15it/s]Epoch 2/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.16it/s]Epoch 2/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.16it/s]Epoch 2/10:  91%|█████████ | 29/32 [00:03<00:00,  9.17it/s]Epoch 2/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.16it/s]Epoch 2/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.17it/s]Epoch 2/10: 100%|██████████| 32/32 [00:03<00:00,  8.99it/s]
[2025-04-29 18:48:55,421][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6987
[2025-04-29 18:48:55,721][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6866, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   3%|▎         | 1/32 [00:00<00:07,  4.40it/s]Epoch 3/10:   6%|▋         | 2/32 [00:00<00:04,  6.30it/s]Epoch 3/10:   9%|▉         | 3/32 [00:00<00:03,  7.34it/s]Epoch 3/10:  12%|█▎        | 4/32 [00:00<00:03,  7.95it/s]Epoch 3/10:  16%|█▌        | 5/32 [00:00<00:03,  8.35it/s]Epoch 3/10:  19%|█▉        | 6/32 [00:00<00:03,  8.60it/s]Epoch 3/10:  22%|██▏       | 7/32 [00:00<00:02,  8.77it/s]Epoch 3/10:  25%|██▌       | 8/32 [00:00<00:02,  8.89it/s]Epoch 3/10:  28%|██▊       | 9/32 [00:01<00:02,  8.96it/s]Epoch 3/10:  31%|███▏      | 10/32 [00:01<00:02,  9.02it/s]Epoch 3/10:  34%|███▍      | 11/32 [00:01<00:02,  9.05it/s]Epoch 3/10:  38%|███▊      | 12/32 [00:01<00:02,  9.09it/s]Epoch 3/10:  41%|████      | 13/32 [00:01<00:02,  9.10it/s]Epoch 3/10:  44%|████▍     | 14/32 [00:01<00:01,  9.11it/s]Epoch 3/10:  47%|████▋     | 15/32 [00:01<00:01,  9.12it/s]Epoch 3/10:  50%|█████     | 16/32 [00:01<00:01,  9.12it/s]Epoch 3/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.14it/s]Epoch 3/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.14it/s]Epoch 3/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.13it/s]Epoch 3/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.13it/s]Epoch 3/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.14it/s]Epoch 3/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.14it/s]Epoch 3/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.14it/s]Epoch 3/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.15it/s]Epoch 3/10:  91%|█████████ | 29/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.14it/s]Epoch 3/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.15it/s]Epoch 3/10: 100%|██████████| 32/32 [00:03<00:00,  8.97it/s]
[2025-04-29 18:48:59,293][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6967
[2025-04-29 18:48:59,605][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6868, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/32 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   3%|▎         | 1/32 [00:00<00:06,  4.72it/s]Epoch 4/10:   6%|▋         | 2/32 [00:00<00:04,  6.57it/s]Epoch 4/10:   9%|▉         | 3/32 [00:00<00:03,  7.52it/s]Epoch 4/10:  12%|█▎        | 4/32 [00:00<00:03,  8.09it/s]Epoch 4/10:  16%|█▌        | 5/32 [00:00<00:03,  8.44it/s]Epoch 4/10:  19%|█▉        | 6/32 [00:00<00:03,  8.66it/s]Epoch 4/10:  22%|██▏       | 7/32 [00:00<00:02,  8.81it/s]Epoch 4/10:  25%|██▌       | 8/32 [00:00<00:02,  8.91it/s]Epoch 4/10:  28%|██▊       | 9/32 [00:01<00:02,  8.98it/s]Epoch 4/10:  31%|███▏      | 10/32 [00:01<00:02,  9.03it/s]Epoch 4/10:  34%|███▍      | 11/32 [00:01<00:02,  9.07it/s]Epoch 4/10:  38%|███▊      | 12/32 [00:01<00:02,  9.08it/s]Epoch 4/10:  41%|████      | 13/32 [00:01<00:02,  9.09it/s]Epoch 4/10:  44%|████▍     | 14/32 [00:01<00:01,  9.11it/s]Epoch 4/10:  47%|████▋     | 15/32 [00:01<00:01,  9.11it/s]Epoch 4/10:  50%|█████     | 16/32 [00:01<00:01,  9.12it/s]Epoch 4/10:  53%|█████▎    | 17/32 [00:01<00:01,  9.12it/s]Epoch 4/10:  56%|█████▋    | 18/32 [00:02<00:01,  9.11it/s]Epoch 4/10:  59%|█████▉    | 19/32 [00:02<00:01,  9.11it/s]Epoch 4/10:  62%|██████▎   | 20/32 [00:02<00:01,  9.12it/s]Epoch 4/10:  66%|██████▌   | 21/32 [00:02<00:01,  9.12it/s]Epoch 4/10:  69%|██████▉   | 22/32 [00:02<00:01,  9.11it/s]Epoch 4/10:  72%|███████▏  | 23/32 [00:02<00:00,  9.12it/s]Epoch 4/10:  75%|███████▌  | 24/32 [00:02<00:00,  9.11it/s]Epoch 4/10:  78%|███████▊  | 25/32 [00:02<00:00,  9.12it/s]Epoch 4/10:  81%|████████▏ | 26/32 [00:02<00:00,  9.13it/s]Epoch 4/10:  84%|████████▍ | 27/32 [00:03<00:00,  9.14it/s]Epoch 4/10:  88%|████████▊ | 28/32 [00:03<00:00,  9.14it/s]Epoch 4/10:  91%|█████████ | 29/32 [00:03<00:00,  9.14it/s]Epoch 4/10:  94%|█████████▍| 30/32 [00:03<00:00,  9.14it/s]Epoch 4/10:  97%|█████████▋| 31/32 [00:03<00:00,  9.14it/s]Epoch 4/10: 100%|██████████| 32/32 [00:03<00:00,  8.97it/s]
[2025-04-29 18:49:03,175][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6985
[2025-04-29 18:49:03,481][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6869, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:49:03,481][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▃▁▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68655
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69853
wandb:           train_time 16.9872
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68691
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184835-idhi92mq
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184835-idhi92mq/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs32 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs64
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:49:23,814][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs64
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs64
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 64
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 3
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:49:23,815][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:49:23,815][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:49:23,815][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:49:23,819][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:49:23,820][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:49:25,698][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:49:28,397][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:49:28,398][src.data.datasets][INFO] - Loading 'control_question_type_seed3' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:49:28,434][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:49:28,452][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed3' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed3/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:49:56 2025).
[2025-04-29 18:49:28,513][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:49:28,523][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:49:28,524][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:49:28,524][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:49:28,547][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:49:28,566][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:49:28,575][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:49:28,576][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:49:28,576][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:49:28,577][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:49:28,602][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:49:28,623][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:49:28,632][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:49:28,633][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:49:28,633][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:49:28,634][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:49:28,635][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:49:28,635][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:49:28,635][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:49:28,635][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:49:28,635][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:49:28,635][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:49:28,635][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:49:28,636][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:49:28,636][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:49:28,636][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:49:28,637][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:49:28,637][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:49:28,637][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:49:28,638][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:49:28,638][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:49:28,641][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:49:28,641][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:49:32,688][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:49:32,689][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 18:49:32,690][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:49:32,690][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:49:32,690][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   6%|▋         | 1/16 [00:01<00:18,  1.26s/it]Epoch 1/10:  12%|█▎        | 2/16 [00:01<00:09,  1.51it/s]Epoch 1/10:  19%|█▉        | 3/16 [00:01<00:06,  2.12it/s]Epoch 1/10:  25%|██▌       | 4/16 [00:01<00:04,  2.63it/s]Epoch 1/10:  31%|███▏      | 5/16 [00:02<00:03,  3.02it/s]Epoch 1/10:  38%|███▊      | 6/16 [00:02<00:03,  3.33it/s]Epoch 1/10:  44%|████▍     | 7/16 [00:02<00:02,  3.56it/s]Epoch 1/10:  50%|█████     | 8/16 [00:02<00:02,  3.72it/s]Epoch 1/10:  56%|█████▋    | 9/16 [00:03<00:01,  3.84it/s]Epoch 1/10:  62%|██████▎   | 10/16 [00:03<00:01,  3.92it/s]Epoch 1/10:  69%|██████▉   | 11/16 [00:03<00:01,  3.98it/s]Epoch 1/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.02it/s]Epoch 1/10:  81%|████████▏ | 13/16 [00:04<00:00,  4.06it/s]Epoch 1/10:  88%|████████▊ | 14/16 [00:04<00:00,  4.08it/s]Epoch 1/10:  94%|█████████▍| 15/16 [00:04<00:00,  4.10it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  4.73it/s]Epoch 1/10: 100%|██████████| 16/16 [00:04<00:00,  3.30it/s]
[2025-04-29 18:49:39,307][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6995
[2025-04-29 18:49:39,606][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6892, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   6%|▋         | 1/16 [00:00<00:05,  2.62it/s]Epoch 2/10:  12%|█▎        | 2/16 [00:00<00:04,  3.33it/s]Epoch 2/10:  19%|█▉        | 3/16 [00:00<00:03,  3.65it/s]Epoch 2/10:  25%|██▌       | 4/16 [00:01<00:03,  3.82it/s]Epoch 2/10:  31%|███▏      | 5/16 [00:01<00:02,  3.92it/s]Epoch 2/10:  38%|███▊      | 6/16 [00:01<00:02,  3.99it/s]Epoch 2/10:  44%|████▍     | 7/16 [00:01<00:02,  4.04it/s]Epoch 2/10:  50%|█████     | 8/16 [00:02<00:01,  4.07it/s]Epoch 2/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.09it/s]Epoch 2/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.11it/s]Epoch 2/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.11it/s]Epoch 2/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.12it/s]Epoch 2/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.12it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.74it/s]Epoch 2/10: 100%|██████████| 16/16 [00:03<00:00,  4.03it/s]
[2025-04-29 18:49:44,144][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.7008
[2025-04-29 18:49:44,455][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6891, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   6%|▋         | 1/16 [00:00<00:07,  2.07it/s]Epoch 3/10:  12%|█▎        | 2/16 [00:00<00:04,  2.93it/s]Epoch 3/10:  19%|█▉        | 3/16 [00:00<00:03,  3.38it/s]Epoch 3/10:  25%|██▌       | 4/16 [00:01<00:03,  3.64it/s]Epoch 3/10:  31%|███▏      | 5/16 [00:01<00:02,  3.81it/s]Epoch 3/10:  38%|███▊      | 6/16 [00:01<00:02,  3.92it/s]Epoch 3/10:  44%|████▍     | 7/16 [00:01<00:02,  3.98it/s]Epoch 3/10:  50%|█████     | 8/16 [00:02<00:01,  4.03it/s]Epoch 3/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.05it/s]Epoch 3/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.07it/s]Epoch 3/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.09it/s]Epoch 3/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.11it/s]Epoch 3/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.12it/s]Epoch 3/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.13it/s]Epoch 3/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.14it/s]Epoch 3/10: 100%|██████████| 16/16 [00:04<00:00,  4.76it/s]Epoch 3/10: 100%|██████████| 16/16 [00:04<00:00,  3.90it/s]
[2025-04-29 18:49:49,941][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6975
[2025-04-29 18:49:50,407][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   6%|▋         | 1/16 [00:00<00:06,  2.43it/s]Epoch 4/10:  12%|█▎        | 2/16 [00:00<00:04,  3.20it/s]Epoch 4/10:  19%|█▉        | 3/16 [00:00<00:03,  3.57it/s]Epoch 4/10:  25%|██▌       | 4/16 [00:01<00:03,  3.78it/s]Epoch 4/10:  31%|███▏      | 5/16 [00:01<00:02,  3.90it/s]Epoch 4/10:  38%|███▊      | 6/16 [00:01<00:02,  3.99it/s]Epoch 4/10:  44%|████▍     | 7/16 [00:01<00:02,  4.04it/s]Epoch 4/10:  50%|█████     | 8/16 [00:02<00:01,  4.08it/s]Epoch 4/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.10it/s]Epoch 4/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.12it/s]Epoch 4/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.13it/s]Epoch 4/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.14it/s]Epoch 4/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 4/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.14it/s]Epoch 4/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.14it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.76it/s]Epoch 4/10: 100%|██████████| 16/16 [00:03<00:00,  4.01it/s]
[2025-04-29 18:49:55,017][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6983
[2025-04-29 18:49:55,366][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 5/10:   6%|▋         | 1/16 [00:00<00:07,  2.08it/s]Epoch 5/10:  12%|█▎        | 2/16 [00:00<00:04,  2.94it/s]Epoch 5/10:  19%|█▉        | 3/16 [00:00<00:03,  3.39it/s]Epoch 5/10:  25%|██▌       | 4/16 [00:01<00:03,  3.66it/s]Epoch 5/10:  31%|███▏      | 5/16 [00:01<00:02,  3.83it/s]Epoch 5/10:  38%|███▊      | 6/16 [00:01<00:02,  3.94it/s]Epoch 5/10:  44%|████▍     | 7/16 [00:01<00:02,  4.01it/s]Epoch 5/10:  50%|█████     | 8/16 [00:02<00:01,  4.05it/s]Epoch 5/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.09it/s]Epoch 5/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.11it/s]Epoch 5/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.13it/s]Epoch 5/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.14it/s]Epoch 5/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 5/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.15it/s]Epoch 5/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.15it/s]Epoch 5/10: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]Epoch 5/10: 100%|██████████| 16/16 [00:04<00:00,  3.93it/s]
[2025-04-29 18:50:00,631][src.training.lm_trainer][INFO] - Epoch 5/10, Train Loss: 0.6980
[2025-04-29 18:50:01,073][src.training.lm_trainer][INFO] - Epoch 5/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 6/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 6/10:   6%|▋         | 1/16 [00:00<00:06,  2.45it/s]Epoch 6/10:  12%|█▎        | 2/16 [00:00<00:04,  3.22it/s]Epoch 6/10:  19%|█▉        | 3/16 [00:00<00:03,  3.59it/s]Epoch 6/10:  25%|██▌       | 4/16 [00:01<00:03,  3.80it/s]Epoch 6/10:  31%|███▏      | 5/16 [00:01<00:02,  3.92it/s]Epoch 6/10:  38%|███▊      | 6/16 [00:01<00:02,  4.00it/s]Epoch 6/10:  44%|████▍     | 7/16 [00:01<00:02,  4.06it/s]Epoch 6/10:  50%|█████     | 8/16 [00:02<00:01,  4.09it/s]Epoch 6/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.12it/s]Epoch 6/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 6/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.14it/s]Epoch 6/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 6/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.15it/s]Epoch 6/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 6/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 6/10: 100%|██████████| 16/16 [00:03<00:00,  4.02it/s]
[2025-04-29 18:50:05,689][src.training.lm_trainer][INFO] - Epoch 6/10, Train Loss: 0.6974
[2025-04-29 18:50:06,042][src.training.lm_trainer][INFO] - Epoch 6/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 7/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 7/10:   6%|▋         | 1/16 [00:00<00:05,  2.53it/s]Epoch 7/10:  12%|█▎        | 2/16 [00:00<00:04,  3.29it/s]Epoch 7/10:  19%|█▉        | 3/16 [00:00<00:03,  3.64it/s]Epoch 7/10:  25%|██▌       | 4/16 [00:01<00:03,  3.83it/s]Epoch 7/10:  31%|███▏      | 5/16 [00:01<00:02,  3.94it/s]Epoch 7/10:  38%|███▊      | 6/16 [00:01<00:02,  4.01it/s]Epoch 7/10:  44%|████▍     | 7/16 [00:01<00:02,  4.07it/s]Epoch 7/10:  50%|█████     | 8/16 [00:02<00:01,  4.10it/s]Epoch 7/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.12it/s]Epoch 7/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.13it/s]Epoch 7/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.16it/s]Epoch 7/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 7/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.77it/s]Epoch 7/10: 100%|██████████| 16/16 [00:03<00:00,  4.04it/s]
[2025-04-29 18:50:10,002][src.training.lm_trainer][INFO] - Epoch 7/10, Train Loss: 0.6984
[2025-04-29 18:50:10,373][src.training.lm_trainer][INFO] - Epoch 7/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 8/10:   0%|          | 0/16 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 8/10:   6%|▋         | 1/16 [00:00<00:05,  2.62it/s]Epoch 8/10:  12%|█▎        | 2/16 [00:00<00:04,  3.35it/s]Epoch 8/10:  19%|█▉        | 3/16 [00:00<00:03,  3.68it/s]Epoch 8/10:  25%|██▌       | 4/16 [00:01<00:03,  3.86it/s]Epoch 8/10:  31%|███▏      | 5/16 [00:01<00:02,  3.96it/s]Epoch 8/10:  38%|███▊      | 6/16 [00:01<00:02,  4.03it/s]Epoch 8/10:  44%|████▍     | 7/16 [00:01<00:02,  4.07it/s]Epoch 8/10:  50%|█████     | 8/16 [00:02<00:01,  4.10it/s]Epoch 8/10:  56%|█████▋    | 9/16 [00:02<00:01,  4.13it/s]Epoch 8/10:  62%|██████▎   | 10/16 [00:02<00:01,  4.14it/s]Epoch 8/10:  69%|██████▉   | 11/16 [00:02<00:01,  4.15it/s]Epoch 8/10:  75%|███████▌  | 12/16 [00:03<00:00,  4.15it/s]Epoch 8/10:  81%|████████▏ | 13/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  88%|████████▊ | 14/16 [00:03<00:00,  4.16it/s]Epoch 8/10:  94%|█████████▍| 15/16 [00:03<00:00,  4.16it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.78it/s]Epoch 8/10: 100%|██████████| 16/16 [00:03<00:00,  4.05it/s]
[2025-04-29 18:50:14,330][src.training.lm_trainer][INFO] - Epoch 8/10, Train Loss: 0.6970
[2025-04-29 18:50:14,688][src.training.lm_trainer][INFO] - Epoch 8/10, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:50:14,688][src.training.lm_trainer][INFO] - Early stopping at epoch 8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁
wandb:        best_val_loss █▅▃▁▁
wandb:                epoch ▁▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ██████▁▁
wandb:           train_loss ▆█▂▃▃▂▄▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁
wandb:             val_loss █▅▃▁▁▁▂▂
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68898
wandb:                epoch 8
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69696
wandb:           train_time 40.23099
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68902
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184923-d0ibxrcn
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_184923-d0ibxrcn/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezetrue_control3_bs64 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezefalse_control1_bs8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 18:50:36,890][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/arabic_sweep/sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezefalse_control1_bs8
experiment_name: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezefalse_control1_bs8
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.1
  freeze_model: false
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 64
training:
  task_type: classification
  batch_size: 8
  num_epochs: 10
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: true
  control_index: 1
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 18:50:36,890][__main__][INFO] - Normalized task: question_type
[2025-04-29 18:50:36,891][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 18:50:36,891][__main__][INFO] - Determined Task Type: classification
[2025-04-29 18:50:36,895][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 18:50:36,895][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 18:50:38,593][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 18:50:41,437][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 18:50:41,438][src.data.datasets][INFO] - Loading 'control_question_type_seed1' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:50:41,551][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:50:41,627][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'control_question_type_seed1' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/control_question_type_seed1/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Tue Apr  8 18:47:32 2025).
[2025-04-29 18:50:41,772][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 18:50:41,782][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:50:41,782][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 18:50:41,784][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:50:41,819][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:50:41,862][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:50:41,873][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 18:50:41,874][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:50:41,874][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 18:50:41,875][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 18:50:41,910][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:50:41,936][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 18:50:41,946][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 18:50:41,947][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 18:50:41,947][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 18:50:41,948][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 18:50:41,949][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:50:41,949][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:50:41,949][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:50:41,949][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:50:41,949][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 18:50:41,950][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:50:41,950][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:50:41,950][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 18:50:41,951][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 18:50:41,951][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 18:50:41,951][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 18:50:41,952][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 18:50:41,952][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 18:50:41,952][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 18:50:41,952][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 18:50:41,952][src.data.datasets][INFO] - Creating dataloaders with 4 workers
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-29 18:50:41,964][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 18:50:41,964][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 18:50:47,009][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 18:50:47,009][src.models.model_factory][INFO] - training probe with unfrozen model
[2025-04-29 18:50:47,010][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 18:50:47,011][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 18:50:47,011][__main__][INFO] - Successfully created model for ar
Epoch 1/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/10:   1%|          | 1/125 [00:01<02:40,  1.30s/it]Epoch 1/10:   2%|▏         | 3/125 [00:01<00:49,  2.46it/s]Epoch 1/10:   4%|▍         | 5/125 [00:01<00:29,  4.06it/s]Epoch 1/10:   6%|▌         | 7/125 [00:01<00:21,  5.50it/s]Epoch 1/10:   7%|▋         | 9/125 [00:02<00:17,  6.72it/s]Epoch 1/10:   9%|▉         | 11/125 [00:02<00:14,  7.70it/s]Epoch 1/10:  10%|█         | 13/125 [00:02<00:13,  8.48it/s]Epoch 1/10:  12%|█▏        | 15/125 [00:02<00:12,  9.06it/s]Epoch 1/10:  14%|█▎        | 17/125 [00:02<00:11,  9.49it/s]Epoch 1/10:  15%|█▌        | 19/125 [00:02<00:10,  9.81it/s]Epoch 1/10:  17%|█▋        | 21/125 [00:03<00:10, 10.04it/s]Epoch 1/10:  18%|█▊        | 23/125 [00:03<00:09, 10.20it/s]Epoch 1/10:  20%|██        | 25/125 [00:03<00:09, 10.32it/s]Epoch 1/10:  22%|██▏       | 27/125 [00:03<00:09, 10.40it/s]Epoch 1/10:  23%|██▎       | 29/125 [00:03<00:09, 10.46it/s]Epoch 1/10:  25%|██▍       | 31/125 [00:04<00:08, 10.50it/s]Epoch 1/10:  26%|██▋       | 33/125 [00:04<00:08, 10.53it/s]Epoch 1/10:  28%|██▊       | 35/125 [00:04<00:08, 10.55it/s]Epoch 1/10:  30%|██▉       | 37/125 [00:04<00:08, 10.57it/s]Epoch 1/10:  31%|███       | 39/125 [00:04<00:08, 10.58it/s]Epoch 1/10:  33%|███▎      | 41/125 [00:05<00:07, 10.59it/s]Epoch 1/10:  34%|███▍      | 43/125 [00:05<00:07, 10.59it/s]Epoch 1/10:  36%|███▌      | 45/125 [00:05<00:07, 10.59it/s]Epoch 1/10:  38%|███▊      | 47/125 [00:05<00:07, 10.60it/s]Epoch 1/10:  39%|███▉      | 49/125 [00:05<00:07, 10.60it/s]Epoch 1/10:  41%|████      | 51/125 [00:06<00:06, 10.60it/s]Epoch 1/10:  42%|████▏     | 53/125 [00:06<00:06, 10.60it/s]Epoch 1/10:  44%|████▍     | 55/125 [00:06<00:06, 10.59it/s]Epoch 1/10:  46%|████▌     | 57/125 [00:06<00:06, 10.59it/s]Epoch 1/10:  47%|████▋     | 59/125 [00:06<00:06, 10.59it/s]Epoch 1/10:  49%|████▉     | 61/125 [00:06<00:06, 10.59it/s]Epoch 1/10:  50%|█████     | 63/125 [00:07<00:05, 10.59it/s]Epoch 1/10:  52%|█████▏    | 65/125 [00:07<00:05, 10.59it/s]Epoch 1/10:  54%|█████▎    | 67/125 [00:07<00:05, 10.59it/s]Epoch 1/10:  55%|█████▌    | 69/125 [00:07<00:05, 10.59it/s]Epoch 1/10:  57%|█████▋    | 71/125 [00:07<00:05, 10.59it/s]Epoch 1/10:  58%|█████▊    | 73/125 [00:08<00:04, 10.59it/s]Epoch 1/10:  60%|██████    | 75/125 [00:08<00:04, 10.59it/s]Epoch 1/10:  62%|██████▏   | 77/125 [00:08<00:04, 10.59it/s]Epoch 1/10:  63%|██████▎   | 79/125 [00:08<00:04, 10.59it/s]Epoch 1/10:  65%|██████▍   | 81/125 [00:08<00:04, 10.59it/s]Epoch 1/10:  66%|██████▋   | 83/125 [00:09<00:03, 10.59it/s]Epoch 1/10:  68%|██████▊   | 85/125 [00:09<00:03, 10.59it/s]Epoch 1/10:  70%|██████▉   | 87/125 [00:09<00:03, 10.59it/s]Epoch 1/10:  71%|███████   | 89/125 [00:09<00:03, 10.59it/s]Epoch 1/10:  73%|███████▎  | 91/125 [00:09<00:03, 10.59it/s]Epoch 1/10:  74%|███████▍  | 93/125 [00:09<00:03, 10.58it/s]Epoch 1/10:  76%|███████▌  | 95/125 [00:10<00:02, 10.58it/s]Epoch 1/10:  78%|███████▊  | 97/125 [00:10<00:02, 10.59it/s]Epoch 1/10:  79%|███████▉  | 99/125 [00:10<00:02, 10.59it/s]Epoch 1/10:  81%|████████  | 101/125 [00:10<00:02, 10.59it/s]Epoch 1/10:  82%|████████▏ | 103/125 [00:10<00:02, 10.58it/s]Epoch 1/10:  84%|████████▍ | 105/125 [00:11<00:01, 10.58it/s]Epoch 1/10:  86%|████████▌ | 107/125 [00:11<00:01, 10.58it/s]Epoch 1/10:  87%|████████▋ | 109/125 [00:11<00:01, 10.58it/s]Epoch 1/10:  89%|████████▉ | 111/125 [00:11<00:01, 10.58it/s]Epoch 1/10:  90%|█████████ | 113/125 [00:11<00:01, 10.58it/s]Epoch 1/10:  92%|█████████▏| 115/125 [00:12<00:00, 10.58it/s]Epoch 1/10:  94%|█████████▎| 117/125 [00:12<00:00, 10.58it/s]Epoch 1/10:  95%|█████████▌| 119/125 [00:12<00:00, 10.59it/s]Epoch 1/10:  97%|█████████▋| 121/125 [00:12<00:00, 10.59it/s]Epoch 1/10:  98%|█████████▊| 123/125 [00:12<00:00, 10.59it/s]Epoch 1/10: 100%|██████████| 125/125 [00:12<00:00, 10.99it/s]Epoch 1/10: 100%|██████████| 125/125 [00:13<00:00,  9.59it/s]
[2025-04-29 18:51:02,254][src.training.lm_trainer][INFO] - Epoch 1/10, Train Loss: 0.6963
[2025-04-29 18:51:02,575][src.training.lm_trainer][INFO] - Epoch 1/10, Val Loss: 0.6861, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 2/10:   1%|          | 1/125 [00:00<00:28,  4.41it/s]Epoch 2/10:   2%|▏         | 3/125 [00:00<00:15,  7.74it/s]Epoch 2/10:   4%|▍         | 5/125 [00:00<00:13,  8.98it/s]Epoch 2/10:   6%|▌         | 7/125 [00:00<00:12,  9.60it/s]Epoch 2/10:   7%|▋         | 9/125 [00:00<00:11,  9.95it/s]Epoch 2/10:   9%|▉         | 11/125 [00:01<00:11, 10.16it/s]Epoch 2/10:  10%|█         | 13/125 [00:01<00:10, 10.30it/s]Epoch 2/10:  12%|█▏        | 15/125 [00:01<00:10, 10.39it/s]Epoch 2/10:  14%|█▎        | 17/125 [00:01<00:10, 10.45it/s]Epoch 2/10:  15%|█▌        | 19/125 [00:01<00:10, 10.49it/s]Epoch 2/10:  17%|█▋        | 21/125 [00:02<00:09, 10.52it/s]Epoch 2/10:  18%|█▊        | 23/125 [00:02<00:09, 10.54it/s]Epoch 2/10:  20%|██        | 25/125 [00:02<00:09, 10.55it/s]Epoch 2/10:  22%|██▏       | 27/125 [00:02<00:09, 10.56it/s]Epoch 2/10:  23%|██▎       | 29/125 [00:02<00:09, 10.57it/s]Epoch 2/10:  25%|██▍       | 31/125 [00:03<00:08, 10.57it/s]Epoch 2/10:  26%|██▋       | 33/125 [00:03<00:08, 10.58it/s]Epoch 2/10:  28%|██▊       | 35/125 [00:03<00:08, 10.58it/s]Epoch 2/10:  30%|██▉       | 37/125 [00:03<00:08, 10.58it/s]Epoch 2/10:  31%|███       | 39/125 [00:03<00:08, 10.58it/s]Epoch 2/10:  33%|███▎      | 41/125 [00:04<00:07, 10.58it/s]Epoch 2/10:  34%|███▍      | 43/125 [00:04<00:07, 10.58it/s]Epoch 2/10:  36%|███▌      | 45/125 [00:04<00:07, 10.58it/s]Epoch 2/10:  38%|███▊      | 47/125 [00:04<00:07, 10.58it/s]Epoch 2/10:  39%|███▉      | 49/125 [00:04<00:07, 10.58it/s]Epoch 2/10:  41%|████      | 51/125 [00:04<00:06, 10.58it/s]Epoch 2/10:  42%|████▏     | 53/125 [00:05<00:06, 10.59it/s]Epoch 2/10:  44%|████▍     | 55/125 [00:05<00:06, 10.59it/s]Epoch 2/10:  46%|████▌     | 57/125 [00:05<00:06, 10.59it/s]Epoch 2/10:  47%|████▋     | 59/125 [00:05<00:06, 10.59it/s]Epoch 2/10:  49%|████▉     | 61/125 [00:05<00:06, 10.58it/s]Epoch 2/10:  50%|█████     | 63/125 [00:06<00:05, 10.58it/s]Epoch 2/10:  52%|█████▏    | 65/125 [00:06<00:05, 10.58it/s]Epoch 2/10:  54%|█████▎    | 67/125 [00:06<00:05, 10.58it/s]Epoch 2/10:  55%|█████▌    | 69/125 [00:06<00:05, 10.58it/s]Epoch 2/10:  57%|█████▋    | 71/125 [00:06<00:05, 10.59it/s]Epoch 2/10:  58%|█████▊    | 73/125 [00:07<00:04, 10.58it/s]Epoch 2/10:  60%|██████    | 75/125 [00:07<00:04, 10.58it/s]Epoch 2/10:  62%|██████▏   | 77/125 [00:07<00:04, 10.57it/s]Epoch 2/10:  63%|██████▎   | 79/125 [00:07<00:04, 10.58it/s]Epoch 2/10:  65%|██████▍   | 81/125 [00:07<00:04, 10.58it/s]Epoch 2/10:  66%|██████▋   | 83/125 [00:07<00:03, 10.58it/s]Epoch 2/10:  68%|██████▊   | 85/125 [00:08<00:03, 10.58it/s]Epoch 2/10:  70%|██████▉   | 87/125 [00:08<00:03, 10.58it/s]Epoch 2/10:  71%|███████   | 89/125 [00:08<00:03, 10.58it/s]Epoch 2/10:  73%|███████▎  | 91/125 [00:08<00:03, 10.59it/s]Epoch 2/10:  74%|███████▍  | 93/125 [00:08<00:03, 10.59it/s]Epoch 2/10:  76%|███████▌  | 95/125 [00:09<00:02, 10.59it/s]Epoch 2/10:  78%|███████▊  | 97/125 [00:09<00:02, 10.59it/s]Epoch 2/10:  79%|███████▉  | 99/125 [00:09<00:02, 10.59it/s]Epoch 2/10:  81%|████████  | 101/125 [00:09<00:02, 10.59it/s]Epoch 2/10:  82%|████████▏ | 103/125 [00:09<00:02, 10.58it/s]Epoch 2/10:  84%|████████▍ | 105/125 [00:10<00:01, 10.58it/s]Epoch 2/10:  86%|████████▌ | 107/125 [00:10<00:01, 10.59it/s]Epoch 2/10:  87%|████████▋ | 109/125 [00:10<00:01, 10.59it/s]Epoch 2/10:  89%|████████▉ | 111/125 [00:10<00:01, 10.58it/s]Epoch 2/10:  90%|█████████ | 113/125 [00:10<00:01, 10.59it/s]Epoch 2/10:  92%|█████████▏| 115/125 [00:10<00:00, 10.59it/s]Epoch 2/10:  94%|█████████▎| 117/125 [00:11<00:00, 10.59it/s]Epoch 2/10:  95%|█████████▌| 119/125 [00:11<00:00, 10.59it/s]Epoch 2/10:  97%|█████████▋| 121/125 [00:11<00:00, 10.59it/s]Epoch 2/10:  98%|█████████▊| 123/125 [00:11<00:00, 10.59it/s]Epoch 2/10: 100%|██████████| 125/125 [00:11<00:00, 11.00it/s]Epoch 2/10: 100%|██████████| 125/125 [00:12<00:00, 10.40it/s]
[2025-04-29 18:51:15,164][src.training.lm_trainer][INFO] - Epoch 2/10, Train Loss: 0.6951
[2025-04-29 18:51:15,503][src.training.lm_trainer][INFO] - Epoch 2/10, Val Loss: 0.6874, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 3/10:   1%|          | 1/125 [00:00<00:24,  5.15it/s]Epoch 3/10:   2%|▏         | 3/125 [00:00<00:14,  8.30it/s]Epoch 3/10:   4%|▍         | 5/125 [00:00<00:12,  9.34it/s]Epoch 3/10:   6%|▌         | 7/125 [00:00<00:12,  9.83it/s]Epoch 3/10:   7%|▋         | 9/125 [00:00<00:11, 10.11it/s]Epoch 3/10:   9%|▉         | 11/125 [00:01<00:11, 10.27it/s]Epoch 3/10:  10%|█         | 13/125 [00:01<00:10, 10.38it/s]Epoch 3/10:  12%|█▏        | 15/125 [00:01<00:10, 10.45it/s]Epoch 3/10:  14%|█▎        | 17/125 [00:01<00:10, 10.50it/s]Epoch 3/10:  15%|█▌        | 19/125 [00:01<00:10, 10.53it/s]Epoch 3/10:  17%|█▋        | 21/125 [00:02<00:09, 10.55it/s]Epoch 3/10:  18%|█▊        | 23/125 [00:02<00:09, 10.57it/s]Epoch 3/10:  20%|██        | 25/125 [00:02<00:09, 10.58it/s]Epoch 3/10:  22%|██▏       | 27/125 [00:02<00:09, 10.58it/s]Epoch 3/10:  23%|██▎       | 29/125 [00:02<00:09, 10.59it/s]Epoch 3/10:  25%|██▍       | 31/125 [00:03<00:08, 10.59it/s]Epoch 3/10:  26%|██▋       | 33/125 [00:03<00:08, 10.59it/s]Epoch 3/10:  28%|██▊       | 35/125 [00:03<00:08, 10.60it/s]Epoch 3/10:  30%|██▉       | 37/125 [00:03<00:08, 10.60it/s]Epoch 3/10:  31%|███       | 39/125 [00:03<00:08, 10.60it/s]Epoch 3/10:  33%|███▎      | 41/125 [00:03<00:07, 10.60it/s]Epoch 3/10:  34%|███▍      | 43/125 [00:04<00:07, 10.60it/s]Epoch 3/10:  36%|███▌      | 45/125 [00:04<00:07, 10.60it/s]Epoch 3/10:  38%|███▊      | 47/125 [00:04<00:07, 10.60it/s]Epoch 3/10:  39%|███▉      | 49/125 [00:04<00:07, 10.60it/s]Epoch 3/10:  41%|████      | 51/125 [00:04<00:06, 10.59it/s]Epoch 3/10:  42%|████▏     | 53/125 [00:05<00:06, 10.59it/s]Epoch 3/10:  44%|████▍     | 55/125 [00:05<00:06, 10.59it/s]Epoch 3/10:  46%|████▌     | 57/125 [00:05<00:06, 10.59it/s]Epoch 3/10:  47%|████▋     | 59/125 [00:05<00:06, 10.60it/s]Epoch 3/10:  49%|████▉     | 61/125 [00:05<00:06, 10.60it/s]Epoch 3/10:  50%|█████     | 63/125 [00:06<00:05, 10.60it/s]Epoch 3/10:  52%|█████▏    | 65/125 [00:06<00:05, 10.60it/s]Epoch 3/10:  54%|█████▎    | 67/125 [00:06<00:05, 10.60it/s]Epoch 3/10:  55%|█████▌    | 69/125 [00:06<00:05, 10.60it/s]Epoch 3/10:  57%|█████▋    | 71/125 [00:06<00:05, 10.60it/s]Epoch 3/10:  58%|█████▊    | 73/125 [00:06<00:04, 10.60it/s]Epoch 3/10:  60%|██████    | 75/125 [00:07<00:04, 10.60it/s]Epoch 3/10:  62%|██████▏   | 77/125 [00:07<00:04, 10.60it/s]Epoch 3/10:  63%|██████▎   | 79/125 [00:07<00:04, 10.60it/s]Epoch 3/10:  65%|██████▍   | 81/125 [00:07<00:04, 10.60it/s]Epoch 3/10:  66%|██████▋   | 83/125 [00:07<00:03, 10.60it/s]Epoch 3/10:  68%|██████▊   | 85/125 [00:08<00:03, 10.60it/s]Epoch 3/10:  70%|██████▉   | 87/125 [00:08<00:03, 10.60it/s]Epoch 3/10:  71%|███████   | 89/125 [00:08<00:03, 10.59it/s]Epoch 3/10:  73%|███████▎  | 91/125 [00:08<00:03, 10.60it/s]Epoch 3/10:  74%|███████▍  | 93/125 [00:08<00:03, 10.60it/s]Epoch 3/10:  76%|███████▌  | 95/125 [00:09<00:02, 10.60it/s]Epoch 3/10:  78%|███████▊  | 97/125 [00:09<00:02, 10.60it/s]Epoch 3/10:  79%|███████▉  | 99/125 [00:09<00:02, 10.60it/s]Epoch 3/10:  81%|████████  | 101/125 [00:09<00:02, 10.60it/s]Epoch 3/10:  82%|████████▏ | 103/125 [00:09<00:02, 10.60it/s]Epoch 3/10:  84%|████████▍ | 105/125 [00:10<00:01, 10.60it/s]Epoch 3/10:  86%|████████▌ | 107/125 [00:10<00:01, 10.60it/s]Epoch 3/10:  87%|████████▋ | 109/125 [00:10<00:01, 10.59it/s]Epoch 3/10:  89%|████████▉ | 111/125 [00:10<00:01, 10.59it/s]Epoch 3/10:  90%|█████████ | 113/125 [00:10<00:01, 10.59it/s]Epoch 3/10:  92%|█████████▏| 115/125 [00:10<00:00, 10.59it/s]Epoch 3/10:  94%|█████████▎| 117/125 [00:11<00:00, 10.58it/s]Epoch 3/10:  95%|█████████▌| 119/125 [00:11<00:00, 10.59it/s]Epoch 3/10:  97%|█████████▋| 121/125 [00:11<00:00, 10.59it/s]Epoch 3/10:  98%|█████████▊| 123/125 [00:11<00:00, 10.59it/s]Epoch 3/10: 100%|██████████| 125/125 [00:11<00:00, 10.99it/s]Epoch 3/10: 100%|██████████| 125/125 [00:11<00:00, 10.48it/s]
[2025-04-29 18:51:27,434][src.training.lm_trainer][INFO] - Epoch 3/10, Train Loss: 0.6941
[2025-04-29 18:51:27,761][src.training.lm_trainer][INFO] - Epoch 3/10, Val Loss: 0.6889, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/10:   0%|          | 0/125 [00:00<?, ?it/s]/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 4/10:   1%|          | 1/125 [00:00<00:26,  4.61it/s]Epoch 4/10:   2%|▏         | 3/125 [00:00<00:15,  7.91it/s]Epoch 4/10:   4%|▍         | 5/125 [00:00<00:13,  9.09it/s]Epoch 4/10:   6%|▌         | 7/125 [00:00<00:12,  9.67it/s]Epoch 4/10:   7%|▋         | 9/125 [00:00<00:11, 10.00it/s]Epoch 4/10:   9%|▉         | 11/125 [00:01<00:11, 10.20it/s]Epoch 4/10:  10%|█         | 13/125 [00:01<00:10, 10.33it/s]Epoch 4/10:  12%|█▏        | 15/125 [00:01<00:10, 10.42it/s]Epoch 4/10:  14%|█▎        | 17/125 [00:01<00:10, 10.48it/s]Epoch 4/10:  15%|█▌        | 19/125 [00:01<00:10, 10.51it/s]Epoch 4/10:  17%|█▋        | 21/125 [00:02<00:09, 10.54it/s]Epoch 4/10:  18%|█▊        | 23/125 [00:02<00:09, 10.56it/s]Epoch 4/10:  20%|██        | 25/125 [00:02<00:09, 10.56it/s]Epoch 4/10:  22%|██▏       | 27/125 [00:02<00:09, 10.57it/s]Epoch 4/10:  23%|██▎       | 29/125 [00:02<00:09, 10.58it/s]Epoch 4/10:  25%|██▍       | 31/125 [00:03<00:08, 10.58it/s]Epoch 4/10:  26%|██▋       | 33/125 [00:03<00:08, 10.59it/s]Epoch 4/10:  28%|██▊       | 35/125 [00:03<00:08, 10.59it/s]Epoch 4/10:  30%|██▉       | 37/125 [00:03<00:08, 10.59it/s]Epoch 4/10:  31%|███       | 39/125 [00:03<00:08, 10.60it/s]Epoch 4/10:  33%|███▎      | 41/125 [00:03<00:07, 10.60it/s]Epoch 4/10:  34%|███▍      | 43/125 [00:04<00:07, 10.60it/s]Epoch 4/10:  36%|███▌      | 45/125 [00:04<00:07, 10.60it/s]Epoch 4/10:  38%|███▊      | 47/125 [00:04<00:07, 10.60it/s]Epoch 4/10:  39%|███▉      | 49/125 [00:04<00:07, 10.60it/s]Epoch 4/10:  41%|████      | 51/125 [00:04<00:06, 10.60it/s]Epoch 4/10:  42%|████▏     | 53/125 [00:05<00:06, 10.60it/s]Epoch 4/10:  44%|████▍     | 55/125 [00:05<00:06, 10.60it/s]Epoch 4/10:  46%|████▌     | 57/125 [00:05<00:06, 10.60it/s]Epoch 4/10:  47%|████▋     | 59/125 [00:05<00:06, 10.60it/s]Epoch 4/10:  49%|████▉     | 61/125 [00:05<00:06, 10.60it/s]Epoch 4/10:  50%|█████     | 63/125 [00:06<00:05, 10.60it/s]Epoch 4/10:  52%|█████▏    | 65/125 [00:06<00:05, 10.60it/s]Epoch 4/10:  54%|█████▎    | 67/125 [00:06<00:05, 10.60it/s]Epoch 4/10:  55%|█████▌    | 69/125 [00:06<00:05, 10.60it/s]Epoch 4/10:  57%|█████▋    | 71/125 [00:06<00:05, 10.60it/s]Epoch 4/10:  58%|█████▊    | 73/125 [00:07<00:04, 10.60it/s]Epoch 4/10:  60%|██████    | 75/125 [00:07<00:04, 10.60it/s]Epoch 4/10:  62%|██████▏   | 77/125 [00:07<00:04, 10.60it/s]Epoch 4/10:  63%|██████▎   | 79/125 [00:07<00:04, 10.60it/s]Epoch 4/10:  65%|██████▍   | 81/125 [00:07<00:04, 10.60it/s]Epoch 4/10:  66%|██████▋   | 83/125 [00:07<00:03, 10.60it/s]Epoch 4/10:  68%|██████▊   | 85/125 [00:08<00:03, 10.60it/s]Epoch 4/10:  70%|██████▉   | 87/125 [00:08<00:03, 10.60it/s]Epoch 4/10:  71%|███████   | 89/125 [00:08<00:03, 10.60it/s]Epoch 4/10:  73%|███████▎  | 91/125 [00:08<00:03, 10.60it/s]Epoch 4/10:  74%|███████▍  | 93/125 [00:08<00:03, 10.60it/s]Epoch 4/10:  76%|███████▌  | 95/125 [00:09<00:02, 10.60it/s]Epoch 4/10:  78%|███████▊  | 97/125 [00:09<00:02, 10.60it/s]Epoch 4/10:  79%|███████▉  | 99/125 [00:09<00:02, 10.60it/s]Epoch 4/10:  81%|████████  | 101/125 [00:09<00:02, 10.60it/s]Epoch 4/10:  82%|████████▏ | 103/125 [00:09<00:02, 10.60it/s]Epoch 4/10:  84%|████████▍ | 105/125 [00:10<00:01, 10.60it/s]Epoch 4/10:  86%|████████▌ | 107/125 [00:10<00:01, 10.60it/s]Epoch 4/10:  87%|████████▋ | 109/125 [00:10<00:01, 10.60it/s]Epoch 4/10:  89%|████████▉ | 111/125 [00:10<00:01, 10.60it/s]Epoch 4/10:  90%|█████████ | 113/125 [00:10<00:01, 10.60it/s]Epoch 4/10:  92%|█████████▏| 115/125 [00:10<00:00, 10.60it/s]Epoch 4/10:  94%|█████████▎| 117/125 [00:11<00:00, 10.60it/s]Epoch 4/10:  95%|█████████▌| 119/125 [00:11<00:00, 10.60it/s]Epoch 4/10:  97%|█████████▋| 121/125 [00:11<00:00, 10.60it/s]Epoch 4/10:  98%|█████████▊| 123/125 [00:11<00:00, 10.61it/s]Epoch 4/10: 100%|██████████| 125/125 [00:11<00:00, 11.02it/s]Epoch 4/10: 100%|██████████| 125/125 [00:11<00:00, 10.47it/s]
[2025-04-29 18:51:39,705][src.training.lm_trainer][INFO] - Epoch 4/10, Train Loss: 0.6919
[2025-04-29 18:51:40,045][src.training.lm_trainer][INFO] - Epoch 4/10, Val Loss: 0.6899, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 18:51:40,046][src.training.lm_trainer][INFO] - Early stopping at epoch 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▆▄▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68607
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69188
wandb:           train_time 50.82123
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68994
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_185036-4y0xqxop
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_185036-4y0xqxop/logs
Experiment sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezefalse_control1_bs8 completed successfully
Running experiment: sweep_question_type_layer2_dropout0.1_lr1e-5_probe64_freezefalse_control1_bs16
slurmstepd: error: *** JOB 58113934 ON r24g37 CANCELLED AT 2025-04-29T18:51:54 ***
