{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Normalize total complexity scores\n",
    "def normalize_complexity_scores(df):    # normalize total scores, per language\n",
    "  df['lang_norm_complexity_score'] = 0.0\n",
    "  for language, group in df.groupby('language'):\n",
    "    min_score = group['complexity_score'].min()\n",
    "    max_score = group['complexity_score'].max()\n",
    "    if min_score == max_score:\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = 0.5\n",
    "    else:\n",
    "      normalized_scores = (group['complexity_score'] - min_score) / (max_score - min_score)\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = normalized_scores.values\n",
    "  return df\n",
    "\n",
    "train_df = normalize_complexity_scores(train_df)\n",
    "dev_df = normalize_complexity_scores(dev_df)\n",
    "\n",
    "print(\"Original vs Language-Normalized scores (sample from different languages):\")\n",
    "sample_df = train_df.groupby('language').head(2).reset_index(drop=True)\n",
    "\n",
    "display(sample_df[['language', 'complexity_score', 'lang_norm_complexity_score']])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
