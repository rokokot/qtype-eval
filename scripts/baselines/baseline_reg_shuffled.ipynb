{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Score Prediction Baselines: (S)TF-IDF Baseline Experiments\n",
    "#### Multilingual Question Type Classification and Complexity Prediction\n",
    "\n",
    "In this notebook we will be developing a set of baselines for complexity score prediction using subword TF-IDF vectors generated with the text2text toolkit. \n",
    "\n",
    "##### Author: Robin Kokot\n",
    "##### Date: March 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ==================== Set up displays\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# ==================== Set up seed constant\n",
    "\n",
    "SEED = 69\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Wandb config\n",
    "run = wandb.init(project=\"MAIthesis\", name=\"xgboost-reg-baseline\", tags=[\"baseline\", \"xgboost\", \"question-complexity\", \"regression\", \"tfidf\"],     job_type=\"model-training\")\n",
    "\n",
    "config = wandb.config\n",
    "config.max_depth = 6\n",
    "config.learning_rate = 0.1\n",
    "config.n_estimators = 200\n",
    "config.objective = 'reg:squarederror'\n",
    "config.random_state = 69\n",
    "config.subsample = 0.8\n",
    "config.colsample_bytree = 0.8\n",
    "config.early_stopping_rounds = 20\n",
    "\n",
    "wandb.run.notes = \"Baseline experiments for question complexity prediction using XGBoost regressor on subword TF-IDF vectors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Dataset loading and label config\n",
    "dataset = load_dataset(\"rokokot/question-type-and-complexity-v2\")\n",
    "train = dataset['train']['complexity_score']\n",
    "test = dataset['test']['complexity_score']\n",
    "dev = dataset['dev']['complexity_score']\n",
    "\n",
    "# ==================== Normalize total complexity scores\n",
    "def normalize_complexity_scores(df):    # normalize total scores, per language\n",
    "  df['lang_norm_complexity_score'] = 0.0\n",
    "  for language, group in df.groupby('language'):\n",
    "    min_score = group['complexity_score'].min()\n",
    "    max_score = group['complexity_score'].max()\n",
    "    if min_score == max_score:\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = 0.5\n",
    "    else:\n",
    "      normalized_scores = (group['complexity_score'] - min_score) / (max_score - min_score)\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = normalized_scores.values\n",
    "  return df\n",
    "\n",
    "train_df = normalize_complexity_scores(train)\n",
    "test_df = normalize_complexity_scores(test)\n",
    "dev_df = normalize_complexity_scores(dev)\n",
    "\n",
    "print(\"Original vs Language-Normalized scores (sample from different languages):\")\n",
    "sample_df = train_df.groupby('language').head(2).reset_index(drop=True)\n",
    "\n",
    "display(sample_df[['language', 'complexity_score', 'lang_norm_complexity_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(dataset['train']['lang_norm_complexity_score'])\n",
    "y_dev = np.array(dataset['validation']['lang_norm_complexity_score'])\n",
    "y_test = np.array(dataset['test']['lang_norm_complexity_score'])\n",
    "\n",
    "\n",
    "print(f\"Train target distribution: mean={y_train.mean():.4f}, std={y_train.std():.4f}, min={y_train.min():.4f}, max={y_train.max():.4f}\")\n",
    "print(f\"Test target distribution: mean={y_test.mean():.4f}, std={y_test.std():.4f}, min={y_test.min():.4f}, max={y_test.max():.4f}\")\n",
    "print(f\"Validation target distribution: mean={y_dev.mean():.4f}, std={y_dev.std():.4f}, min={y_dev.min():.4f}, max={y_dev.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== TFIDF vectors loading\n",
    "print(\"\\nLoading TF-IDF vectors...\")\n",
    "train_vectors = \"/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_train.pkl\"\n",
    "dev_vectors = \"/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_dev.pkl\"\n",
    "test_vectors = \"/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_test.pkl\"\n",
    "\n",
    "with open(train_vectors, 'rb') as v:\n",
    "    X_train = pickle.load(v)\n",
    "with open(dev_vectors, 'rb') as v:\n",
    "    X_dev = pickle.load(v)\n",
    "with open(test_vectors, 'rb') as v:\n",
    "    X_test = pickle.load(v)\n",
    "\n",
    "print(\"\\nChecking shapes of features and targets:\")\n",
    "print(f\"Train - Features: {X_train.shape[0]}, Targets: {y_train.shape[0]}\")\n",
    "print(f\"Test - Features: {X_test.shape[0]}, Targets: {y_test.shape[0]}\")\n",
    "print(f\"Validation - Features: {X_dev.shape[0]}, Targets: {y_dev.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Visualization of complexity score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_train, bins=30, alpha=0.7, label='Train')\n",
    "plt.hist(y_dev, bins=30, alpha=0.7, label='Dev')\n",
    "plt.hist(y_test, bins=30, alpha=0.7, label='Test')\n",
    "plt.xlabel('Complexity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Complexity Scores')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "wandb.log({\"complexity_distribution\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== XGBoost Training and Evaluation\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    max_depth=config.max_depth,\n",
    "    learning_rate=config.learning_rate,\n",
    "    n_estimators=config.n_estimators,\n",
    "    objective=config.objective,\n",
    "    random_state=config.random_state,\n",
    "    subsample=config.subsample,\n",
    "    colsample_bytree=config.colsample_bytree\n",
    ")\n",
    "\n",
    "wandb.config.update({\n",
    "    \"model_type\": \"XGBoost\",\n",
    "    \"feature_type\": \"TF-IDF\",\n",
    "    \"train_samples\": X_train.shape[0],\n",
    "    \"test_samples\": X_test.shape[0],\n",
    "    \"dev_samples\": X_dev.shape[0],\n",
    "    \"feature_dim\": X_train.shape[1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "xgb_reg.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_dev, y_dev)],   eval_metric=['rmse', 'mae'],verbose=100,early_stopping_rounds=config.early_stopping_rounds)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"training took {training_time:.2f} seconds\")\n",
    "wandb.log({\"training_time\": training_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Model Evaluation\n",
    "print(\"\\nEvaluating model on development set...\")\n",
    "y_pred_dev = xgb_reg.predict(X_dev)\n",
    "\n",
    "rmse_dev = np.sqrt(mean_squared_error(y_dev, y_pred_dev))\n",
    "mae_dev = mean_absolute_error(y_dev, y_pred_dev)\n",
    "r2_dev = r2_score(y_dev, y_pred_dev)\n",
    "\n",
    "print(f\"Dev Set: RMSE = {rmse_dev:.4f}, MAE = {mae_dev:.4f}, R² = {r2_dev:.4f}\")\n",
    "wandb.log({\"dev_rmse\": rmse_dev, \"dev_mae\": mae_dev, \"dev_r2\": r2_dev})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_dev, y_pred_dev, alpha=0.5)\n",
    "plt.plot([y_dev.min(), y_dev.max()], [y_dev.min(), y_dev.max()], 'r--')\n",
    "plt.xlabel('Actual Complexity')\n",
    "plt.ylabel('Predicted Complexity')\n",
    "plt.title('Predicted vs Actual Complexity (Dev Set)')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"dev_predictions_scatter\": wandb.Image(plt)})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "residuals = y_pred_dev - y_dev\n",
    "plt.scatter(y_pred_dev, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Complexity')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot (Dev Set)')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"dev_residuals\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Evaluating on test set\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "y_pred_test = xgb_reg.predict(X_test)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Test Set: RMSE = {rmse_test:.4f}, MAE = {mae_test:.4f}, R² = {r2_test:.4f}\")\n",
    "wandb.log({\"test_rmse\": rmse_test, \"test_mae\": mae_test, \"test_r2\": r2_test})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Complexity')\n",
    "plt.ylabel('Predicted Complexity')\n",
    "plt.title('Predicted vs Actual Complexity (Test Set)')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"test_predictions_scatter\": wandb.Image(plt)})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "residuals = y_pred_test - y_test\n",
    "plt.scatter(y_pred_test, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Complexity')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot (Test Set)')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"test_residuals\": wandb.Image(plt)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Feature Importance Analysis\n",
    "print(\"\\nAnalyzing feature importance...\")\n",
    "importance = xgb_reg.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature_index': range(len(importance)),\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance_df.head(20)\n",
    "print(\"Top 20 important features:\")\n",
    "print(top_features)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(20), top_features['importance'])\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 20 Important Features')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"feature_importance\": wandb.Image(plt)})\n",
    "wandb.log({\"feature_importance_table\": wandb.Table(\n",
    "    data=[[int(idx), float(imp)] for idx, imp in zip(top_features['feature_index'], top_features['importance'])],\n",
    "    columns=[\"feature_index\", \"importance\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Save Model\n",
    "model_path = 'xgboost_regression_baseline_model.json'\n",
    "xgb_reg.save_model(model_path)\n",
    "wandb.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add analysis by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc and learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
