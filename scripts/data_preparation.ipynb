{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Generating TF-IDF Vectors\n",
    "##### Prepare datasets, normalize features, create destroyed (sub)sets and extract Text2Text TF-IDF features for our questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q text2text -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import text2text as t2t\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "SEED = 69\n",
    "np.random.seed(SEED)\n",
    "\n",
    "LANGUAGES = ['en', 'fi', 'id', 'ko', 'ja', 'ru', 'ar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/robin/Research/qtype-eval/scripts/wandb/run-20250324_214907-zf3q78w5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/zf3q78w5' target=\"_blank\">data-preparation</a></strong> to <a href='https://wandb.ai/rokii-ku-leuven/MAIthesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rokii-ku-leuven/MAIthesis' target=\"_blank\">https://wandb.ai/rokii-ku-leuven/MAIthesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/zf3q78w5' target=\"_blank\">https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/zf3q78w5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/zf3q78w5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a11f837cf50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"MAIthesis\",\n",
    "  name=\"data-preparation\",\n",
    "  tags=[\"data-prep\", \"tfidf\", \"normalization\", \"data-randomization\"],\n",
    "  job_type=\"data-processing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('rokokot/question-type-and-complexity-v2')\n",
    "train_data = dataset['train']\n",
    "train = train_data.to_pandas()\n",
    "dev_data = dataset['validation']\n",
    "dev = dev_data.to_pandas()\n",
    "test_data = dataset['test']\n",
    "test = test_data.to_pandas()\n",
    "\n",
    "wandb.log({\"train_data_rows\": len(train), \"dev_data_rows\": len(dev), \"test_data_rows\": len(test), \"data_columns\": len(train.columns)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"questions:\")\n",
    "for i in range(3):\n",
    "    print(f\"{train['text'][i][:100]}... (lang id: {train['language'][i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vs normalized scores (sample from different languages):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>complexity_score</th>\n",
       "      <th>lang_norm_complexity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>3.421</td>\n",
       "      <td>0.840525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru</td>\n",
       "      <td>1.728</td>\n",
       "      <td>0.478899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fi</td>\n",
       "      <td>3.071</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ja</td>\n",
       "      <td>2.087</td>\n",
       "      <td>0.587973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.199342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fi</td>\n",
       "      <td>1.419</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en</td>\n",
       "      <td>2.379</td>\n",
       "      <td>0.514697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.090959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id</td>\n",
       "      <td>3.309</td>\n",
       "      <td>0.838166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ar</td>\n",
       "      <td>2.527</td>\n",
       "      <td>0.602913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ja</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.137457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ko</td>\n",
       "      <td>2.149</td>\n",
       "      <td>0.500163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ko</td>\n",
       "      <td>2.469</td>\n",
       "      <td>0.604500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  complexity_score  lang_norm_complexity_score\n",
       "0        en             3.421                    0.840525\n",
       "1        ru             1.728                    0.478899\n",
       "2        fi             3.071                    1.000000\n",
       "3        ja             2.087                    0.587973\n",
       "4        ru             0.794                    0.199342\n",
       "5        id             0.129                    0.000000\n",
       "6        fi             1.419                    0.397959\n",
       "7        en             2.379                    0.514697\n",
       "8        ar             0.664                    0.090959\n",
       "9        id             3.309                    0.838166\n",
       "10       ar             2.527                    0.602913\n",
       "11       ja             0.776                    0.137457\n",
       "12       ko             2.149                    0.500163\n",
       "13       ko             2.469                    0.604500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================== Normalize total complexity scores and log distribution\n",
    "\n",
    "def normalize_complexity_scores(df):    # normalize total scores, per language\n",
    "  df['lang_norm_complexity_score'] = 0.0\n",
    "  for language, group in df.groupby('language'):\n",
    "    min_score = group['complexity_score'].min()\n",
    "    max_score = group['complexity_score'].max()\n",
    "    if min_score == max_score:\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = 0.5\n",
    "    else:\n",
    "      normalized_scores = (group['complexity_score'] - min_score) / (max_score - min_score)\n",
    "      df.loc[df['language'] == language, 'lang_norm_complexity_score'] = normalized_scores.values\n",
    "  return df\n",
    "\n",
    "train_df = normalize_complexity_scores(train)\n",
    "test_df = normalize_complexity_scores(test)\n",
    "dev_df = normalize_complexity_scores(dev)\n",
    "\n",
    "print(\"original vs normalized scores (sample from different languages):\")\n",
    "sample_df = dev_df.groupby('language').head(2).reset_index(drop=True)\n",
    "\n",
    "display(sample_df[['language', 'complexity_score', 'lang_norm_complexity_score']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Complexity Score Distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=train_df, x='lang_norm_complexity_score', label='Train', fill=True, alpha=0.3)\n",
    "sns.kdeplot(data=test_df, x='lang_norm_complexity_score', label='Test', fill=True, alpha=0.3)\n",
    "sns.kdeplot(data=dev_df, x='lang_norm_complexity_score', label='Dev', fill=True, alpha=0.3)\n",
    "plt.title('Normalized Complexity Score Distribution Across Splits')\n",
    "plt.xlabel('Normalized Complexity Score')\n",
    "plt.legend()\n",
    "wandb.log({\"complexity_distribution/all_splits\": wandb.Image(plt)})\n",
    "plt.close()\n",
    "\n",
    "complexity_stats = {\n",
    "    \"complexity_stats/train_mean\": train_df['lang_norm_complexity_score'].mean(),\n",
    "    \"complexity_stats/train_median\": train_df['lang_norm_complexity_score'].median(),\n",
    "    \"complexity_stats/test_mean\": test_df['lang_norm_complexity_score'].mean(),\n",
    "    \"complexity_stats/test_median\": test_df['lang_norm_complexity_score'].median(),\n",
    "    \"complexity_stats/dev_mean\": dev_df['lang_norm_complexity_score'].mean(),\n",
    "    \"complexity_stats/dev_median\": dev_df['lang_norm_complexity_score'].median(),\n",
    "}\n",
    "wandb.log(complexity_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================== Question type distributions \n",
    "def plot_type_dist(train_df, test_df, dev_df):\n",
    "  train_types = train_df['question_type'].value_counts().reset_index()\n",
    "  train_types.columns = ['question_type', 'count']\n",
    "  train_types['split'] = 'Train'\n",
    "\n",
    "  test_types = test_df['question_type'].value_counts().reset_index()\n",
    "  test_types.columns = ['question_type', 'count']\n",
    "  test_types['split'] = 'Test'\n",
    "\n",
    "  dev_types = dev_df['question_type'].value_counts().reset_index()\n",
    "  dev_types.columns = ['question_type', 'count']\n",
    "  dev_types['split'] = 'Dev'\n",
    "\n",
    "  all_types = pd.concat([train_types, test_types, dev_types])\n",
    "\n",
    "  for split, group in all_types.groupby('split'):\n",
    "      total = group['count'].sum()\n",
    "      all_types.loc[all_types['split'] == split, 'percentage'] = all_types.loc[all_types['split'] == split, 'count'] / total * 100\n",
    "\n",
    "  plt.figure(figsize=(15, 8))\n",
    "  chart = sns.barplot(data=all_types, x='question_type', y='count', hue='split')\n",
    "  plt.title('Question Type Distribution Across Splits')\n",
    "  plt.xlabel('Question Type')\n",
    "  plt.ylabel('Count')\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "  plt.tight_layout()\n",
    "  wandb.log({\"question_type_distribution/counts\": wandb.Image(plt)})\n",
    "  plt.close()\n",
    "\n",
    "  plt.figure(figsize=(15, 8))\n",
    "  chart = sns.barplot(data=all_types, x='question_type', y='percentage', hue='split')\n",
    "  plt.title('Question Type Percentage Distribution Across Splits')\n",
    "  plt.xlabel('Question Type')\n",
    "  plt.ylabel('Percentage (%)')\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "  plt.tight_layout()\n",
    "  wandb.log({\"question_type_distribution/percentages\": wandb.Image(plt)})\n",
    "  plt.close()\n",
    "\n",
    "  return all_types\n",
    "\n",
    "question_type_stats = plot_type_dist(train_df, dev_df, test_df)\n",
    "\n",
    "wandb.log({\"question_type_stats\": wandb.Table(dataframe=question_type_stats)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_language_dist(train_df, dev_df, test_df):\n",
    "    train_langs = train_df['language'].value_counts().reset_index()\n",
    "    train_langs.columns = ['language', 'count']\n",
    "    train_langs['split'] = 'Train'\n",
    "    dev_langs = dev_df['language'].value_counts().reset_index()\n",
    "    dev_langs.columns = ['language', 'count']\n",
    "    dev_langs['split'] = 'Dev'\n",
    "    test_langs = test_df['language'].value_counts().reset_index()\n",
    "    test_langs.columns = ['language', 'count']\n",
    "    test_langs['split'] = 'Test'\n",
    "    all_langs = pd.concat([train_langs, dev_langs, test_langs])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=all_langs, x='language', y='count', hue='split')\n",
    "    plt.title('Language Distribution Across Splits')\n",
    "    plt.xlabel('Language')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    wandb.log({\"language_distribution\": wandb.Image(plt)})\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return all_langs\n",
    "\n",
    "language_stats = plot_language_dist(train_df, dev_df, test_df)\n",
    "\n",
    "wandb.log({\"language_stats\": wandb.Table(dataframe=language_stats)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4f718448884aa8ae69987eca16fdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106be4c1a3924ff78d1c4d545c3d733d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15528dc08efe4aaf8166f0980e55f767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF matrix shape: (7460, 1)\n",
      "Dev TF-IDF matrix shape: (441, 1)\n",
      "Test TF-IDF matrix shape: (719, 1)\n"
     ]
    }
   ],
   "source": [
    "tfidfer = t2t.Tfidfer()\n",
    "indexer = t2t.Indexer()\n",
    "\n",
    "\n",
    "def extract_tfidf_vectors(questions, languages):\n",
    "    vectors = []\n",
    "    for i, (question, lang) in enumerate(tqdm(zip(questions, languages), total=len(questions))):\n",
    "        vector = tfidfer.transform([question], src_lang=lang, output='matrix')[0]\n",
    "        vectors.append(vector)\n",
    "    return np.vstack(vectors)\n",
    "\n",
    "X_train = extract_tfidf_vectors(train_df['text'].tolist(), train_df['language'].tolist())\n",
    "X_dev = extract_tfidf_vectors(dev_df['text'].tolist(), dev_df['language'].tolist())\n",
    "X_test = extract_tfidf_vectors(test_df['text'].tolist(), test_df['language'].tolist())\n",
    "\n",
    "print(f\"Training TF-IDF matrix shape: {X_train.shape}\")\n",
    "print(f\"Dev TF-IDF matrix shape: {X_dev.shape}\")\n",
    "print(f\"Test TF-IDF matrix shape: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_train.pkl', 'wb') as v: \n",
    "    pickle.dump(X_train, v)\n",
    "with open('/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_dev.pkl', 'wb') as v:\n",
    "    pickle.dump(X_dev, v)\n",
    "with open('/home/robin/Research/qtype-eval/scripts/baselines/vectors/tfidf_vectors_test.pkl', 'wb') as v:\n",
    "    pickle.dump(X_test, v)\n",
    "with open('/home/robin/Research/qtype-eval/scripts/baselines/vectors/idf_values.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidfer.idf, f)\n",
    "    \n",
    "tokenizer = t2t.Tokenizer()\n",
    "vocab = tokenizer.__class__.tokenizer.get_vocab()\n",
    "token_to_index = {token: idx for token, idx in vocab.items()}\n",
    "    \n",
    "with open('/home/robin/Research/qtype-eval/scripts/baselines/vectors/token_to_index_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(token_to_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating destroyed sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 destroyed label sets\n",
      "Generated 3 destroyed complexity sets\n"
     ]
    }
   ],
   "source": [
    "# ==================== Destroyed set generation\n",
    "\n",
    "destroyed_sets = {\n",
    "  'types': {},\n",
    "  'complexity': {}\n",
    "}\n",
    "\n",
    "def generate_destroyed_sets(train_df, n_seeds=3):\n",
    "    destroyed_sets = {\n",
    "        'types': {},   \n",
    "        'complexity': {} \n",
    "    }\n",
    "    \n",
    "    for seed in range(1, n_seeds+1):\n",
    "        types_df = train_df.copy()\n",
    "        complexity_df = train_df.copy()\n",
    "        \n",
    "        types_df['question_type_destroyed'] = types_df['question_type']\n",
    "        complexity_df['complexity_score_destroyed'] = complexity_df['lang_norm_complexity_score']\n",
    "        \n",
    "        for lang in LANGUAGES:\n",
    "            lang_mask = types_df['language'] == lang\n",
    "            \n",
    "            if lang_mask.sum() > 0:\n",
    "                lang_indices = types_df[lang_mask].index\n",
    "                \n",
    "                np.random.seed(seed)\n",
    "                shuffled_types = np.random.permutation(types_df.loc[lang_indices, 'question_type'].values)\n",
    "                types_df.loc[lang_indices, 'question_type_destroyed'] = shuffled_types\n",
    "                np.random.seed(seed)\n",
    "                shuffled_scores = np.random.permutation(complexity_df.loc[lang_indices, 'lang_norm_complexity_score'].values)\n",
    "                complexity_df.loc[lang_indices, 'complexity_score_destroyed'] = shuffled_scores\n",
    "        \n",
    "        destroyed_sets['types'][f'within_lang_shuffle_{seed}'] = types_df\n",
    "        destroyed_sets['complexity'][f'within_lang_shuffle_{seed}'] = complexity_df\n",
    "    \n",
    "    return destroyed_sets\n",
    "\n",
    "destroyed_sets = generate_destroyed_sets(train_df, n_seeds=3)\n",
    "\n",
    "print(f\"Generated {len(destroyed_sets['types'])} destroyed label sets\")\n",
    "print(f\"Generated {len(destroyed_sets['complexity'])} destroyed complexity sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined destroyed datasets (all languages per seed) as CSV files\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('/home/robin/Research/qtype-eval/data/destroyed/destroyed_types', exist_ok=True)\n",
    "os.makedirs('/home/robin/Research/qtype-eval/data/destroyed/destroyed_complexity', exist_ok=True)\n",
    "\n",
    "for seed in range(1, 4):\n",
    "    seed_key = f'within_lang_shuffle_{seed}'\n",
    "    \n",
    "    destroyed_sets['types'][seed_key].to_csv(f'/home/robin/Research/qtype-eval/data/destroyed/destroyed_types/{seed_key}.csv', index=False)\n",
    "    destroyed_sets['complexity'][seed_key].to_csv(f'/home/robin/Research/qtype-eval/data/destroyed/destroyed_complexity/{seed_key}.csv', index=False)\n",
    "\n",
    "print(\"Saved combined destroyed datasets (all languages per seed) as CSV files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Comparison of destroyed and original scores\n",
    "\n",
    "for seed in range(1, 4):\n",
    "    seed_key = f'within_lang_shuffle_{seed}'\n",
    "    destroyed_df = destroyed_sets['complexity'][seed_key]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        data=train_df, \n",
    "        x='lang_norm_complexity_score',\n",
    "        label='Original', \n",
    "        fill=True, \n",
    "        alpha=0.4,\n",
    "        color='blue'\n",
    "    )\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        data=destroyed_df, \n",
    "        x='complexity_score_destroyed',\n",
    "        label=f'Destroyed (Seed {seed})', \n",
    "        fill=True, \n",
    "        alpha=0.4,\n",
    "        color='red'\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Original vs. Destroyed Complexity Score Distribution (Seed {seed})')\n",
    "    plt.xlabel('Normalized Complexity Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    wandb.log({f\"destroyed_complexity_comparison/seed_{seed}\": wandb.Image(plt)})\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>complexity_stats/dev_mean</td><td>▁</td></tr><tr><td>complexity_stats/dev_median</td><td>▁</td></tr><tr><td>complexity_stats/test_mean</td><td>▁</td></tr><tr><td>complexity_stats/test_median</td><td>▁</td></tr><tr><td>complexity_stats/train_mean</td><td>▁</td></tr><tr><td>complexity_stats/train_median</td><td>▁</td></tr><tr><td>data_columns</td><td>▁</td></tr><tr><td>dev_data_rows</td><td>▁</td></tr><tr><td>test_data_rows</td><td>▁</td></tr><tr><td>train_data_rows</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>complexity_stats/dev_mean</td><td>0.44659</td></tr><tr><td>complexity_stats/dev_median</td><td>0.43849</td></tr><tr><td>complexity_stats/test_mean</td><td>0.42937</td></tr><tr><td>complexity_stats/test_median</td><td>0.40675</td></tr><tr><td>complexity_stats/train_mean</td><td>0.38545</td></tr><tr><td>complexity_stats/train_median</td><td>0.37212</td></tr><tr><td>data_columns</td><td>11</td></tr><tr><td>dev_data_rows</td><td>441</td></tr><tr><td>test_data_rows</td><td>719</td></tr><tr><td>train_data_rows</td><td>7460</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">data-preparation</strong> at: <a href='https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/qy9f2eiq' target=\"_blank\">https://wandb.ai/rokii-ku-leuven/MAIthesis/runs/qy9f2eiq</a><br> View project at: <a href='https://wandb.ai/rokii-ku-leuven/MAIthesis' target=\"_blank\">https://wandb.ai/rokii-ku-leuven/MAIthesis</a><br>Synced 5 W&B file(s), 6 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250324_192518-qy9f2eiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtype-eval-pAepV5Z2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
