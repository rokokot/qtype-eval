# configs/experiment/finetune_submetric.yaml
type: "lm_finetune"
tasks:
  - "single_submetric"
submetric: "avg_links_len"
available_submetrics:
  - "avg_links_len"
  - "avg_max_depth"
  - "avg_subordinate_chain_len"
  - "avg_verb_edges"
  - "lexical_density"
  - "n_tokens"
use_controls: false
control_index: null
num_controls: 3
eval_on_orig_test: true
cross_lingual: false
finetune: true

training:
  patience: 5
  scheduler_patience: 4
  scheduler_factor: 0.8
  dropout: 0.1
  lr: 2.0e-05
  batch_size: 8