\begin{table}[H]
    \centering
    \label{tab:submetric_probing}
    \makebox[\textwidth][c]{\resizebox{1.2\textwidth}{!}{
    \setlength{\tabcolsep}{7pt}
    \begin{tabular}{crcccccccccccc}
        & & \multicolumn{2}{c}{\textsc{dependency length}} & \multicolumn{2}{c}{\textsc{max. tree depth}} & \multicolumn{2}{c}{\textsc{sub.chain length}} & \multicolumn{2}{c}{\textsc{verbal edges}} & \multicolumn{2}{c}{\textsc{lexical density}} & \multicolumn{2}{c}{\textsc{n tokens}} \\[6pt]
        & & $MSE$ & $\widehat{S}$ & $MSE$ & $\widehat{S}$ & $MSE$ & $\widehat{S}$ & $MSE$ & $\widehat{S}$ & $MSE$ & $\widehat{S}$ & $MSE$ & $\widehat{S}$ \\\hhline{*{14}{-}}
        %  DEPENDENCY_LENGTH,MAX_TREE_DEPTH,SUB_CHAIN_LENGTH,VERBAL_EDGES,LEXICAL_DENSITY,N_TOKENS
        % mse   |   norm selectivity
        \rotmultirow{7}{*}{\small Dummy baseline} 
        & ar & 0.064 & 0 & 0.052 & 0 & 0.066 & 0 & 0.098 & 0 & 0.073 & 0 & 0.078 & 0 \\
        & en & 0.012 & 0 & 0.029 & 0 & 0.025 & 0 & 0.060 & 0 & 0.035 & 0 & 0.023 & 0 \\
        & fi & 0.020 & 0 & 0.035 & 0 & 0.047 & 0 & 0.075 & 0 & 0.049 & 0 & 0.022 & 0 \\
        & id & 0.034 & 0 & 0.033 & 0 & 0.071 & 0 & 0.081 & 0 & 0.053 & 0 & 0.030 & 0 \\
        & ja & 0.096 & 0 & 0.094 & 0 & 0.131 & 0 & 0.102 & 0 & 0.063 & 0 & 0.074 & 0 \\
        & ko & 0.027 & 0 & 0.035 & 0 & 0.078 & 0 & 0.035 & 0 & 0.040 & 0 & 0.047 & 0 \\
        & ru & 0.022 & 0 & 0.025 & 0 & 0.044 & 0 & 0.053 & 0 & 0.045 & 0 & 0.017 & 0 \\\hhline{*{14}{-}}
        
        \rotmultirow{7}{*}{\small Linear predictors} 
        & ar & 0.040 & 0.39 & 0.028 & 0.48 & 0.049 & 0.38 & 0.091 & 0.28 & 0.068 & 0.04 & 0.038 & 0.53 \\
        & en & 0.006 & 0.45 & 0.013 & 0.60 & 0.015 & 0.48 & 0.045 & 0.32 & 0.024 & 0.18 & 0.027 & 0.11 \\
        & fi & 0.018 &0.25&0.030 &0.15&0.037& 0.30&0.066& 0.25&0.058 &-0.04&0.015& 0.21 \\
        & id & 0.026 &0.27&0.018&0.47&0.035 &0.53&0.070 &0.07&0.038 &0.43&0.022 &0.37 \\
        & ja & 0.076 &0.29&0.053 &0.37&0.070 &0.37&0.094 &0.12&0.077 &-0.21&0.035 &0.43 \\
        & ko & 0.020 &0.26&0.022& 0.45&0.045 &0.34&0.038 &0.09&0.059 &0.27&0.046 &0.35 \\
        & ru &0.019 &0.11&0.014 &0.48&0.032 &0.43&0.042 &0.18&0.043 &0.33&0.012 &0.26 \\\hhline{*{14}{-}}
        
        \rotmultirow{7}{*}{\small Gradient boosting \ } 
        & ar & 0.045&0.22&0.028&0.44&0.057&0.16&0.107&0.13&0.067&0.01&0.038 &0.49\\
        & en & 0.009&0.21&0.012&0.61&0.016&0.43&0.050&0.21&0.028 &0.12&0.018 &0.29 \\
        & fi & 0.022&0.03&0.017&0.52&0.039&0.27&0.066 &0.22&0.058 &-0.05&0.011 &0.37 \\
        & id & 0.024&0.32&0.029&0.07&0.044&0.39&0.077&-0.06&0.040 &0.39&0.035 &-0.13 \\
        & ja & 0.099&0.06&0.063&0.29&0.072&0.36&0.097&0.11&0.078&-0.19&0.028 &0.56 \\
        & ko & 0.018&0.36&0.018&0.53&0.055&0.18&0.037&0.04&0.063&0.22&0.033& 0.51 \\
        & ru & 0.023&-0.07&0.015&0.41&0.041&0.25&0.045&0.06&0.052&0.14&0.009 &0.39 \\\hhline{*{14}{-}}
        %   DEP_LENGTH,TREE_DEPTH,SUB_CHAIN,VERBAL_EDGES,LEXICAL_DENSITY,N_TOKENS

        \rotmultirow{7}{*}{\small Optimal Probe} 
        & ar & 0.045 \footnotesize(6) & 0.42 & 0.028 \footnotesize(6) & 0.48 & 0.069 \footnotesize(6) & 0.12 & 0.103 \footnotesize(1) & 0.23 & 0.054 \footnotesize(3) & 0.10 & 0.037 \footnotesize(4) & 0.59 \\
        & en & 0.090 \footnotesize(6) & 0.23 & 0.016 \footnotesize(8) & 0.46 & 0.022 \footnotesize(6) & 0.25 & 0.043 \footnotesize(1) & 0.35 & 0.025 \footnotesize(6) & 0.11 & 0.010 \footnotesize(3) & 0.63 \\
        & fi & 0.025 \footnotesize(8) & 0.18 & 0.016 \footnotesize(7) & 0.52 & 0.047 \footnotesize(12) & -0.01 & 0.080 \footnotesize(12) & -0.01 & 0.039 \footnotesize(2) & 0.14 & 0.006 \footnotesize(1) & 0.59 \\
        & id & 0.030 \footnotesize(12) & 0 & 0.024 \footnotesize(1) & 0.34 & 0.049 \footnotesize(1) & 0.46 & 0.046 \footnotesize(9) & 0.35 & 0.036 \footnotesize(3) & 0.21 & 0.025 \footnotesize(3) & 0.32 \\
        & ja & 0.087 \footnotesize(1) & 0.10 & 0.072 \footnotesize(9) & 0.10 & 0.053 \footnotesize(6) & 0.47 & 0.007 \footnotesize(6) & 0.40 & 0.071 \footnotesize(7) & 0 & 0.023 \footnotesize(5) & 0.66 \\
        & ko & 0.023 \footnotesize(8) & 0.18 & 0.020 \footnotesize(2) & 0.57 & 0.047 \footnotesize(5) & 0.26 & 0.034 \footnotesize(12) & 0 & 0.062 \footnotesize(8) & 0.13 & 0.073 \footnotesize(9) & 0.18 \\
        & ru & 0.013 \footnotesize(4) & 0.29 & 0.016 \footnotesize(6) & 0.41 & 0.049 \footnotesize(5) & 0.14 & 0.041 \footnotesize(9) & 0.18 & 0.037 \footnotesize(7) & 0.14 & 0.004 \footnotesize(5) & 0.68 \\\hhline{*{14}{-}}
        
        \rotmultirow{7}{*}{\small Weakest Probe} 
        & ar & 0.073 \footnotesize(12) & -0.13 & 0.053 \footnotesize(12) & 0.05 & 0.080 \footnotesize(12) & -0.04 & 0.140 \footnotesize(7) & 0 & 0.065 \footnotesize(5) & -0.02 & 0.079 \footnotesize(12) & 0 \\
        & en & 0.015 \footnotesize(10) & -0.29 & 0.029 \footnotesize(12) & 0.06 & 0.031 \footnotesize(3) & 0.06 & 0.076 \footnotesize(8) & 0.04 & 0.030 \footnotesize(12) & 0.02 & 0.023 \footnotesize(12) & 0.17 \\
        & fi & 0.030 \footnotesize(2) & 0.07 & 0.037 \footnotesize(12) & -0.05 & 0.073 \footnotesize(10) & 0.08 & 0.112 \footnotesize(5) & -0.13 & 0.051 \footnotesize(12) & -0.03 & 0.016 \footnotesize(12) & -0.03 \\
        & id & 0.049 \footnotesize(11) & 0.16 & 0.033 \footnotesize(12) & 0.05 & 0.081 \footnotesize(11) & 0.06 & 0.062 \footnotesize(12) & 0.04 & 0.046 \footnotesize(12) & 0.04 & 0.034 \footnotesize(7) & 0.08 \\
        & ja & 0.122 \footnotesize(3) & 0.06 & 0.103 \footnotesize(10) & -0.10 & 0.094 \footnotesize(12) & -0.03 & 0.094 \footnotesize(12) & 0.06 & 0.093 \footnotesize(10) & -0.14 & 0.063 \footnotesize(12) & 0.03 \\
        & ko & 0.042 \footnotesize(3) & 0.18 & 0.037 \footnotesize(12) & 0.02 & 0.070 \footnotesize(7) & -0.05 & 0.036 \footnotesize(11) & -0.04 & 0.074 \footnotesize(6) & -0.07 & 0.104 \footnotesize(3) & 0.12 \\
        & ru & 0.020 \footnotesize(11) & 0.07 & 0.028 \footnotesize(12) & 0 & 0.058 \footnotesize(6) & 0.03 & 0.057 \footnotesize(8) & -0.08 & 0.051 \footnotesize(12) & -0.07 & 0.016 \footnotesize(12) & -0.09 \\\hhline{*{14}{-}}

        %  DEPENDENCY_LENGTH,MAX_TREE_DEPTH,SUB_CHAIN_LENGTH,VERBAL_EDGES,LEXICAL_DENSITY,N_TOKENS
        % mse   |   norm selectivity
        \rotmultirow{7}{*}{\small Fine-tuned Glot500 \ } 
        & ar & 0.056 & - & 0.038 & - & 0.069 & - & 0.030 & - & 0.055 & - & 0.056 & - \\
        & en & 0.008 & - & 0.022 & - & 0.019 & - & 0.039 & - & 0.023 & - & 0.020 & - \\
        & fi & 0.002 & - & 0.023 & - & 0.045 & - & 0.079& - & 0.044 & - & 0.011 & - \\
        & id & 0.031 & - & 0.028 & - & 0.043 & - & 0.045 & - & 0.038 & - & 0.027 & - \\
        & ja & 0.105 & - & 0.068 & - & 0.061 & - & 0.078 & - & 0.071 & - & 0.035 & - \\
        & ko & 0.025 & - & 0.029 & - & 0.046 & - & 0.034 & - & 0.074 & - & 0.070 & - \\
        & ru & 0.015 & - & 0.017 & - & 0.046 & - & 0.038 & - & 0.043 & - & 0.006 & - \\\hhline{*{14}{-}}
    \end{tabular}
    }}
\caption{Performance metrics for linguistic complexity submetric regression tasks across 7 languages.}
\end{table}