seed: 42
<<<<<<< HEAD
output_dir: /scratch/leuven/371/vsc37132/probe_output/complexity/layer3/ja
experiment_name: probe_layer3_complexity_ja
=======
output_dir: /scratch/leuven/371/vsc37132/probe_output/submetrics/n_tokens/control3/layer12/ru
experiment_name: probe_layer12_n_tokens_control3_ru
>>>>>>> 69f886f3030b7aff0301a7fd3596c248c0142992
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
<<<<<<< HEAD
  - ja
=======
  - ru
>>>>>>> 69f886f3030b7aff0301a7fd3596c248c0142992
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.2
  freeze_model: true
  layer_wise: true
<<<<<<< HEAD
  layer_index: 3
=======
  layer_index: 12
>>>>>>> 69f886f3030b7aff0301a7fd3596c248c0142992
  num_outputs: 1
  probe_hidden_size: 128
  probe_depth: 3
  activation: silu
  normalization: layer
  weight_init: xavier
  output_standardization: true
  use_linear_probe: false
  use_mean_pooling: true
  use_class_weights: false
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 0.0001
  weight_decay: 0.01
  patience: 4
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
  gradient_accumulation_steps: 2
experiment:
  type: lm_probe
<<<<<<< HEAD
  tasks: complexity
  use_controls: false
  control_index: null
=======
  tasks: single_submetric
  submetric: n_tokens
  available_submetrics:
  - avg_links_len
  - avg_max_depth
  - avg_subordinate_chain_len
  - avg_verb_edges
  - lexical_density
  - n_tokens
  use_controls: true
  control_index: 3
>>>>>>> 69f886f3030b7aff0301a7fd3596c248c0142992
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
<<<<<<< HEAD
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1
=======
>>>>>>> 69f886f3030b7aff0301a7fd3596c248c0142992
