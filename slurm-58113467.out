SLURM_JOB_ID: 58113467
SLURM_JOB_USER: vsc37132
SLURM_JOB_ACCOUNT: intro_vsc37132
SLURM_JOB_NAME: layerwise_probing
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: gpu_p100
SLURM_NNODES: 1
SLURM_NODELIST: r22g41
SLURM_JOB_CPUS_PER_NODE: 4
SLURM_JOB_GPUS: 2
Date: Tue Apr 29 16:48:16 CEST 2025
Walltime: 01-12:00:00
========================================================================
Environment variables:
PYTHONPATH=:/data/leuven/371/vsc37132/qtype-eval:/vsc-hard-mounts/leuven-user/371/vsc37132:/vsc-hard-mounts/leuven-user/371/vsc37132:/vsc-hard-mounts/leuven-data/371/vsc37132/qtype-eval
HF_HOME=/data/leuven/371/vsc37132/qtype-eval/data/cache
GPU information:
Tue Apr 29 16:48:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-SXM2-16GB           Off |   00000000:89:00.0 Off |                    0 |
| N/A   46C    P0             36W /  300W |       0MiB /  16384MiB |      0%   E. Process |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Python executable: /data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/bin/python
PyTorch CUDA available: True
Starting standard experiments...
Running question_type experiment for language ar, layer 1
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:49:02,911][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_1/question_type
experiment_name: layer_1_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 1
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 16:49:02,911][__main__][INFO] - Normalized task: question_type
[2025-04-29 16:49:02,911][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 16:49:02,911][__main__][INFO] - Determined Task Type: classification
[2025-04-29 16:49:02,916][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 16:49:02,916][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:49:06,574][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:49:09,985][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:49:09,986][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:49:10,124][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,181][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,558][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:49:10,573][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:49:10,574][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:49:10,574][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:49:10,588][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,619][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,632][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:49:10,634][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:49:10,634][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:49:10,635][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:49:10,650][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,681][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:49:10,704][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:49:10,705][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:49:10,706][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:49:10,706][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:49:10,722][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:49:10,723][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:49:10,723][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:49:10,723][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:49:10,754][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 16:49:10,754][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 16:49:10,755][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:49:10,755][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 16:49:10,755][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:49:10,755][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:49:10,755][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:49:10,756][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:49:10,756][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 16:49:10,756][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 16:49:10,756][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:49:10,756][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:49:10,757][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:49:10,757][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:49:10,757][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:49:10,757][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:49:10,757][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 16:49:10,757][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 16:49:10,758][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:49:10,758][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:49:10,758][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:49:10,758][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:49:10,758][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:49:10,759][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:49:27,178][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:49:27,179][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:49:27,180][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 16:49:27,181][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 1
[2025-04-29 16:49:27,181][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:03<03:36,  3.50s/it]Epoch 1/15:   5%|▍         | 3/63 [00:03<00:56,  1.05it/s]Epoch 1/15:   8%|▊         | 5/63 [00:03<00:28,  2.04it/s]Epoch 1/15:  11%|█         | 7/63 [00:03<00:17,  3.27it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:03<00:11,  4.72it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:04<00:08,  6.37it/s]Epoch 1/15:  21%|██        | 13/63 [00:04<00:06,  8.10it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:04<00:04,  9.83it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:04<00:04, 11.47it/s]Epoch 1/15:  30%|███       | 19/63 [00:04<00:03, 12.89it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:04<00:02, 14.09it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:04<00:02, 15.06it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:04<00:02, 15.79it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:04<00:02, 16.39it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:05<00:02, 16.79it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:05<00:01, 17.07it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:05<00:01, 17.28it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:05<00:01, 17.44it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:05<00:01, 17.55it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:05<00:01, 17.66it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:05<00:01, 17.69it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:05<00:01, 17.74it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:05<00:01, 17.78it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:06<00:00, 17.79it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:06<00:00, 17.85it/s]Epoch 1/15:  81%|████████  | 51/63 [00:06<00:00, 17.84it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:06<00:00, 17.85it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:06<00:00, 17.84it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:06<00:00, 17.86it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:06<00:00, 17.87it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:06<00:00, 17.89it/s]Epoch 1/15: 100%|██████████| 63/63 [00:06<00:00,  9.03it/s]
[2025-04-29 16:49:40,573][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.7014
[2025-04-29 16:49:40,892][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  6.20it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:04, 12.02it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.45it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.73it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.46it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.94it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.22it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.44it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.55it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.64it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.78it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.79it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.80it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.81it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.81it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.83it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.84it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.83it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.84it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.84it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.84it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.84it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.84it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.85it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.27it/s]
[2025-04-29 16:49:45,144][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.7021
[2025-04-29 16:49:45,460][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6883, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.29it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.01it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.72it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.20it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.09it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.58it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.65it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.80it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.82it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.84it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.83it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.84it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.84it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.83it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.84it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.84it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.83it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.83it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.84it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.85it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:49:49,761][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6988
[2025-04-29 16:49:50,092][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.60it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.36it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.95it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.37it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.22it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.74it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.09it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.31it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.47it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.74it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.77it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.82it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.81it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.82it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.82it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.82it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.83it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.84it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.82it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.84it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.82it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.83it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.85it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.84it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.22it/s]
[2025-04-29 16:49:53,754][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6974
[2025-04-29 16:49:54,076][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6888, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.57it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.33it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.95it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.36it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.20it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.06it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.30it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.20it/s]
[2025-04-29 16:49:57,742][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6954
[2025-04-29 16:49:58,060][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 16:49:58,061][src.training.lm_trainer][INFO] - Early stopping at epoch 5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss ▇█▅▃▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▁▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68831
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69545
wandb:           train_time 24.46953
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68903
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_164902-i26cjel5
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_164902-i26cjel5/logs
Standard experiment completed successfully: layer_1_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_1/question_type/results.json
Running complexity experiment for language ar, layer 1
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:50:17,025][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_1/complexity
experiment_name: layer_1_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 1
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 16:50:17,025][__main__][INFO] - Normalized task: complexity
[2025-04-29 16:50:17,025][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 16:50:17,025][__main__][INFO] - Determined Task Type: regression
[2025-04-29 16:50:17,030][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 16:50:17,030][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:50:18,438][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:50:21,584][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:50:21,585][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:50:21,652][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,681][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,780][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:50:21,792][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:50:21,792][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:50:21,794][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:50:21,830][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,873][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,894][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:50:21,896][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:50:21,896][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:50:21,897][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:50:21,933][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,972][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:50:21,985][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:50:21,987][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:50:21,987][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:50:21,988][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:50:21,989][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:50:21,989][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:50:21,989][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:50:21,989][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:50:21,989][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:50:21,990][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 16:50:21,990][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:50:21,990][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 16:50:21,990][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:50:21,990][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:50:21,990][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:50:21,991][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:50:21,991][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:50:21,991][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 16:50:21,991][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:50:21,991][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 16:50:21,991][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:50:21,991][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:50:21,992][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:50:21,992][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:50:21,992][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:50:21,992][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 16:50:21,992][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:50:21,992][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 16:50:21,993][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:50:21,993][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:50:21,993][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:50:21,994][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:50:27,100][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:50:27,101][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:50:27,102][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 16:50:27,103][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 1
[2025-04-29 16:50:27,103][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:01<01:14,  1.21s/it]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:21,  2.82it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:11,  4.97it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:07,  7.16it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05,  9.25it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 11.13it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 12.73it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.03it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:02<00:03, 15.04it/s]Epoch 1/15:  30%|███       | 19/63 [00:02<00:02, 15.80it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.37it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 16.77it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.08it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.29it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.44it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.56it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:03<00:01, 17.63it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:03<00:01, 17.70it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:03<00:01, 17.73it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.82it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.84it/s]Epoch 1/15:  81%|████████  | 51/63 [00:04<00:00, 17.83it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:04<00:00, 17.73it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:04<00:00, 17.74it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.77it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 13.39it/s]
[2025-04-29 16:50:34,219][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.4146
[2025-04-29 16:50:34,528][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3343, Metrics: {'mse': 0.337262362241745, 'rmse': 0.5807429398983212, 'r2': -4.198334693908691}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.44it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.19it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.83it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.26it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:50:38,802][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.2857
[2025-04-29 16:50:39,108][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.2328, Metrics: {'mse': 0.23511242866516113, 'rmse': 0.4848839331893367, 'r2': -2.6238644123077393}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.54it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.28it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.90it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.33it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.29it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.66it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.83it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.82it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.81it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.82it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.82it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.82it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.83it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.17it/s]
[2025-04-29 16:50:43,398][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2031
[2025-04-29 16:50:43,725][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1643, Metrics: {'mse': 0.16606895625591278, 'rmse': 0.4075155901998263, 'r2': -1.5596749782562256}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:10,  6.01it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.78it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 14.28it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.60it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.35it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.84it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.13it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.34it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.49it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.59it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.74it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.81it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.20it/s]
[2025-04-29 16:50:47,959][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1292
[2025-04-29 16:50:48,283][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1221, Metrics: {'mse': 0.12337356060743332, 'rmse': 0.35124572681732846, 'r2': -0.9015969038009644}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.47it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.20it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.85it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.28it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.14it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.81it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.11it/s]
[2025-04-29 16:50:52,522][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1001
[2025-04-29 16:50:52,856][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0940, Metrics: {'mse': 0.09484241157770157, 'rmse': 0.3079649518657952, 'r2': -0.4618370532989502}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.41it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.15it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.81it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.26it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 16:50:57,127][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0723
[2025-04-29 16:50:57,456][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0785, Metrics: {'mse': 0.07903600484132767, 'rmse': 0.2811334288933418, 'r2': -0.2182077169418335}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.33it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.05it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.73it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.20it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.60it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.11it/s]
[2025-04-29 16:51:01,729][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0598
[2025-04-29 16:51:02,057][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0705, Metrics: {'mse': 0.07077775150537491, 'rmse': 0.26604088314650987, 'r2': -0.09092056751251221}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.29it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.06it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.03it/s]
[2025-04-29 16:51:06,335][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0501
[2025-04-29 16:51:06,667][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0669, Metrics: {'mse': 0.06702199578285217, 'rmse': 0.2588860671856486, 'r2': -0.03303182125091553}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:11,  5.19it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.89it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.10it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.58it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.73it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 16:51:10,990][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0475
[2025-04-29 16:51:11,306][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0653, Metrics: {'mse': 0.06521410495042801, 'rmse': 0.2553705248270207, 'r2': -0.005166172981262207}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:11,  5.23it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.91it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.60it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.65it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.67it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.66it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.66it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 16:51:15,622][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0474
[2025-04-29 16:51:15,958][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0649, Metrics: {'mse': 0.06477636843919754, 'rmse': 0.25451202022536684, 'r2': 0.0015807747840881348}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:10,  5.78it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 11.53it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 14.07it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 11/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 16:51:20,285][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0418
[2025-04-29 16:51:20,625][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0651, Metrics: {'mse': 0.06482711434364319, 'rmse': 0.25461169325787686, 'r2': 0.0007985234260559082}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.74it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.44it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.96it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.87it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.44it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.09it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 16:51:24,354][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0430
[2025-04-29 16:51:24,690][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0652, Metrics: {'mse': 0.06496038287878036, 'rmse': 0.2548732682702923, 'r2': -0.0012555122375488281}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.10it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.78it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.01it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.92it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 16:51:28,418][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0402
[2025-04-29 16:51:28,760][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0654, Metrics: {'mse': 0.06514676660299301, 'rmse': 0.25523864637431576, 'r2': -0.0041283369064331055}
[2025-04-29 16:51:28,761][src.training.lm_trainer][INFO] - Early stopping at epoch 13
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▅▄▂▂▁▁▁▁▁
wandb:     best_val_mse █▅▄▃▂▁▁▁▁▁
wandb:      best_val_r2 ▁▄▅▆▇█████
wandb:    best_val_rmse █▆▄▃▂▂▁▁▁▁
wandb:            epoch ▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▄▃▂▂▁▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▅▄▂▂▁▁▁▁▁▁▁▁
wandb:          val_mse █▅▄▃▂▁▁▁▁▁▁▁▁
wandb:           val_r2 ▁▄▅▆▇████████
wandb:         val_rmse █▆▄▃▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06493
wandb:     best_val_mse 0.06478
wandb:      best_val_r2 0.00158
wandb:    best_val_rmse 0.25451
wandb:            epoch 13
wandb:   final_test_mse 0.05928
wandb:    final_test_r2 -0.02194
wandb:  final_test_rmse 0.24347
wandb:  final_train_mse 0.03239
wandb:   final_train_r2 -0.05505
wandb: final_train_rmse 0.17996
wandb:    final_val_mse 0.06478
wandb:     final_val_r2 0.00158
wandb:   final_val_rmse 0.25451
wandb:    learning_rate 1e-05
wandb:       train_loss 0.04019
wandb:       train_time 59.24863
wandb:         val_loss 0.06545
wandb:          val_mse 0.06515
wandb:           val_r2 -0.00413
wandb:         val_rmse 0.25524
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165017-eqlovfy5
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165017-eqlovfy5/logs
Standard experiment completed successfully: layer_1_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_1/complexity/results.json
Running question_type experiment for language ar, layer 2
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:51:50,729][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_2/question_type
experiment_name: layer_2_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 16:51:50,730][__main__][INFO] - Normalized task: question_type
[2025-04-29 16:51:50,730][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 16:51:50,730][__main__][INFO] - Determined Task Type: classification
[2025-04-29 16:51:50,734][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 16:51:50,734][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:51:52,424][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:51:55,577][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:51:55,578][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:51:55,640][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,662][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,774][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:51:55,785][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:51:55,786][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:51:55,787][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:51:55,816][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,842][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,855][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:51:55,857][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:51:55,857][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:51:55,858][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:51:55,879][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,934][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:51:55,947][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:51:55,949][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:51:55,949][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:51:55,950][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:51:55,950][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:51:55,951][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:51:55,951][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:51:55,951][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:51:55,951][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 16:51:55,951][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:51:55,952][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:51:55,953][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 16:51:55,953][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 16:51:55,953][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:51:55,953][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:51:55,953][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:51:55,953][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:51:55,953][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:51:55,954][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:51:55,954][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 16:51:55,954][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 16:51:55,954][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:51:55,954][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:51:55,954][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:51:55,954][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:51:55,955][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:51:55,956][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:52:00,484][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:52:00,485][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:52:00,486][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 16:52:00,487][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 16:52:00,487][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:52,  1.19it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.84it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.43it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.81it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.88it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.57it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.93it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.97it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.76it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.36it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.77it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.06it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.29it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.44it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.55it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.81it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.52it/s]
[2025-04-29 16:52:06,769][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.7026
[2025-04-29 16:52:07,049][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:09,  6.40it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:04, 12.14it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:03, 14.51it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.75it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.46it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.92it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.20it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.39it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.52it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.61it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.22it/s]
[2025-04-29 16:52:11,278][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.7017
[2025-04-29 16:52:11,587][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:10,  5.76it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.51it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.08it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.45it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.27it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.77it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.08it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.30it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.17it/s]
[2025-04-29 16:52:15,868][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.7001
[2025-04-29 16:52:16,188][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.45it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.18it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.82it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.25it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.11it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 16:52:19,883][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6976
[2025-04-29 16:52:20,208][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6886, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.59it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.33it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.94it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.33it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 16:52:23,897][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6968
[2025-04-29 16:52:24,198][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6886, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 16:52:24,199][src.training.lm_trainer][INFO] - Early stopping at epoch 5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss █▇▅▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▂▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68838
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69683
wandb:           train_time 21.77296
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68865
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165150-mfifummx
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165150-mfifummx/logs
Standard experiment completed successfully: layer_2_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_2/question_type/results.json
Running complexity experiment for language ar, layer 2
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:52:43,884][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_2/complexity
experiment_name: layer_2_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 16:52:43,884][__main__][INFO] - Normalized task: complexity
[2025-04-29 16:52:43,884][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 16:52:43,884][__main__][INFO] - Determined Task Type: regression
[2025-04-29 16:52:43,889][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 16:52:43,889][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:52:45,417][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:52:48,484][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:52:48,484][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:52:48,517][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,540][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,652][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:52:48,662][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:52:48,663][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:52:48,663][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:52:48,680][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,733][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,745][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:52:48,747][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:52:48,747][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:52:48,748][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:52:48,796][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,834][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:52:48,856][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:52:48,858][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:52:48,858][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:52:48,859][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:52:48,859][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:52:48,860][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:52:48,860][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:52:48,860][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:52:48,860][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:52:48,860][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:52:48,861][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:52:48,861][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:52:48,862][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:52:48,862][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:52:48,863][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:52:48,863][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 16:52:48,863][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:52:48,863][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 16:52:48,863][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:52:48,863][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:52:48,864][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:52:48,864][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:52:53,484][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:52:53,485][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:52:53,486][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 16:52:53,486][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 16:52:53,486][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:55,  1.11it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.64it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.16it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.52it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.60it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.33it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.73it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.82it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.64it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.67it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 16.99it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.22it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.37it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.49it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.57it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.73it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.76it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.27it/s]
[2025-04-29 16:52:59,843][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.4393
[2025-04-29 16:53:00,137][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3662, Metrics: {'mse': 0.3693718910217285, 'rmse': 0.6077597313262277, 'r2': -4.693249225616455}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  5.74it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.49it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.05it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.38it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.83it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.84it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.13it/s]
[2025-04-29 16:53:04,398][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3545
[2025-04-29 16:53:04,703][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.3007, Metrics: {'mse': 0.3035370111465454, 'rmse': 0.5509419308298701, 'r2': -3.6785149574279785}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.54it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.26it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.87it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.30it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.14it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 16:53:09,010][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2960
[2025-04-29 16:53:09,333][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.2471, Metrics: {'mse': 0.24952645599842072, 'rmse': 0.4995262315418688, 'r2': -2.8460326194763184}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.48it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.22it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.86it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.30it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.16it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:53:13,576][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.2309
[2025-04-29 16:53:13,893][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.2049, Metrics: {'mse': 0.20702581107616425, 'rmse': 0.4550008912916152, 'r2': -2.1909563541412354}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.35it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.08it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.75it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.22it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.09it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.65it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:53:18,152][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1962
[2025-04-29 16:53:18,476][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1702, Metrics: {'mse': 0.17202313244342804, 'rmse': 0.41475671476593123, 'r2': -1.6514487266540527}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.46it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.19it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.83it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.27it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 6/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.03it/s]
[2025-04-29 16:53:22,740][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1584
[2025-04-29 16:53:23,067][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1427, Metrics: {'mse': 0.1442827433347702, 'rmse': 0.37984568358054327, 'r2': -1.223876953125}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.31it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.03it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.70it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.18it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.72it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 16:53:27,353][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.1325
[2025-04-29 16:53:27,690][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1215, Metrics: {'mse': 0.12281827628612518, 'rmse': 0.3504543854571165, 'r2': -0.8930380344390869}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.44it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 11.15it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.80it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.24it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.09it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.64it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.97it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.74it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 16:53:31,969][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.1065
[2025-04-29 16:53:32,294][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.1057, Metrics: {'mse': 0.10679033398628235, 'rmse': 0.32678790367191124, 'r2': -0.6459943056106567}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:10,  5.81it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.56it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 14.09it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.44it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.22it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 16:53:36,614][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0936
[2025-04-29 16:53:36,941][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0933, Metrics: {'mse': 0.094143345952034, 'rmse': 0.30682787675182643, 'r2': -0.45106208324432373}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:10,  5.81it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 11.56it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 14.08it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 10/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 16:53:41,220][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0820
[2025-04-29 16:53:41,528][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0842, Metrics: {'mse': 0.08492428809404373, 'rmse': 0.29141772096776086, 'r2': -0.30896568298339844}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:10,  5.69it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 11.41it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.94it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.30it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 16.10it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.62it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.62it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.63it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.66it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 16:53:45,870][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0674
[2025-04-29 16:53:46,194][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0776, Metrics: {'mse': 0.07815495878458023, 'rmse': 0.2795620839537798, 'r2': -0.2046278715133667}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.94it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.67it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 16:53:50,468][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0607
[2025-04-29 16:53:50,802][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0733, Metrics: {'mse': 0.07365380972623825, 'rmse': 0.27139235384630545, 'r2': -0.13525021076202393}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:11,  5.29it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.98it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.63it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.67it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.72it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.97it/s]
[2025-04-29 16:53:55,142][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0539
[2025-04-29 16:53:55,480][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0701, Metrics: {'mse': 0.07037684321403503, 'rmse': 0.2652863419289335, 'r2': -0.08474123477935791}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.94it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.09it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 16:53:59,809][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0538
[2025-04-29 16:54:00,144][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0680, Metrics: {'mse': 0.06817679107189178, 'rmse': 0.2611068575734689, 'r2': -0.05083107948303223}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.07it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.74it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.43it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.94it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.87it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.09it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.34it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.44it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.49it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.65it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.63it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.63it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 16:54:04,523][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0507
[2025-04-29 16:54:04,847][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0667, Metrics: {'mse': 0.06676586717367172, 'rmse': 0.2583909192941418, 'r2': -0.029084086418151855}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:     best_val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:      best_val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:    best_val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▄▃▂▂▂▂▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:          val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:           val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:         val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.0667
wandb:     best_val_mse 0.06677
wandb:      best_val_r2 -0.02908
wandb:    best_val_rmse 0.25839
wandb:            epoch 15
wandb:   final_test_mse 0.06344
wandb:    final_test_r2 -0.09369
wandb:  final_test_rmse 0.25187
wandb:  final_train_mse 0.0369
wandb:   final_train_r2 -0.2022
wandb: final_train_rmse 0.19211
wandb:    final_val_mse 0.06677
wandb:     final_val_r2 -0.02908
wandb:   final_val_rmse 0.25839
wandb:    learning_rate 1e-05
wandb:       train_loss 0.05066
wandb:       train_time 70.01299
wandb:         val_loss 0.0667
wandb:          val_mse 0.06677
wandb:           val_r2 -0.02908
wandb:         val_rmse 0.25839
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165243-j7h6zafi
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165243-j7h6zafi/logs
Standard experiment completed successfully: layer_2_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_2/complexity/results.json
Running question_type experiment for language ar, layer 3
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:54:25,844][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_3/question_type
experiment_name: layer_3_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 3
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 16:54:25,844][__main__][INFO] - Normalized task: question_type
[2025-04-29 16:54:25,844][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 16:54:25,844][__main__][INFO] - Determined Task Type: classification
[2025-04-29 16:54:25,849][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 16:54:25,849][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:54:27,493][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:54:30,673][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:54:30,674][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:54:30,729][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:30,759][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:30,846][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:54:30,857][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:54:30,858][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:54:30,859][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:54:30,889][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:30,922][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:30,933][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:54:30,935][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:54:30,935][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:54:30,936][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:54:30,963][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:31,018][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:54:31,031][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:54:31,033][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:54:31,033][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:54:31,034][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:54:31,034][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:54:31,035][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:54:31,035][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:54:31,035][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:54:31,035][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 16:54:31,035][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 16:54:31,035][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:54:31,036][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 16:54:31,036][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:54:31,036][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:54:31,036][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:54:31,036][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:54:31,036][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 16:54:31,036][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:54:31,037][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:54:31,037][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 16:54:31,038][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 16:54:31,038][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:54:31,038][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:54:31,038][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:54:31,038][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:54:31,039][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:54:31,039][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:54:35,641][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:54:35,642][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:54:35,644][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 16:54:35,644][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 3
[2025-04-29 16:54:35,644][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:56,  1.09it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.58it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.07it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.43it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.50it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.27it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.70it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.79it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.64it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.24it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.70it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.01it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.24it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.40it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.52it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.61it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.83it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.84it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.29it/s]
[2025-04-29 16:54:42,231][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.7011
[2025-04-29 16:54:42,526][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.51it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.25it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.88it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.29it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.15it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 16:54:46,783][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.7003
[2025-04-29 16:54:47,094][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:10,  6.10it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.86it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.30it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.61it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.36it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.82it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.13it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.34it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.46it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.19it/s]
[2025-04-29 16:54:50,762][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6989
[2025-04-29 16:54:51,066][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6886, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:09,  6.28it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:04, 12.00it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 14.40it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.64it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.38it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.82it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.11it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.30it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.15it/s]
[2025-04-29 16:54:54,744][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6969
[2025-04-29 16:54:55,045][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6888, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 16:54:55,046][src.training.lm_trainer][INFO] - Early stopping at epoch 4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▇▄▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▂▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.6884
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69695
wandb:           train_time 17.22577
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68876
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165425-e5v31oxq
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165425-e5v31oxq/logs
Standard experiment completed successfully: layer_3_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_3/question_type/results.json
Running complexity experiment for language ar, layer 3
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:55:13,569][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_3/complexity
experiment_name: layer_3_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 3
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 16:55:13,570][__main__][INFO] - Normalized task: complexity
[2025-04-29 16:55:13,570][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 16:55:13,570][__main__][INFO] - Determined Task Type: regression
[2025-04-29 16:55:13,574][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 16:55:13,575][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:55:14,890][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:55:18,097][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:55:18,097][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:55:18,125][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,166][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,245][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:55:18,254][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:55:18,255][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:55:18,256][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:55:18,283][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,316][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,341][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:55:18,342][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:55:18,342][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:55:18,343][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:55:18,370][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,393][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:55:18,404][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:55:18,405][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:55:18,406][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:55:18,407][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:55:18,407][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:55:18,407][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:55:18,407][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:55:18,407][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:55:18,408][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:55:18,408][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 16:55:18,408][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:55:18,408][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 16:55:18,408][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:55:18,409][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:55:18,409][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:55:18,409][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:55:18,409][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:55:18,409][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 16:55:18,409][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:55:18,410][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 16:55:18,410][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:55:18,410][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:55:18,410][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:55:18,410][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:55:18,410][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:55:18,411][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 16:55:18,411][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:55:18,411][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 16:55:18,411][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:55:18,411][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:55:18,412][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:55:18,412][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:55:22,554][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:55:22,555][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:55:22,556][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 16:55:22,556][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 3
[2025-04-29 16:55:22,556][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:52,  1.17it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.81it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.39it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.78it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.86it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.59it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.95it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.02it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.80it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.38it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.79it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.09it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.30it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.44it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.55it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.83it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.83it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.51it/s]
[2025-04-29 16:55:29,486][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.4055
[2025-04-29 16:55:29,777][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3405, Metrics: {'mse': 0.34353047609329224, 'rmse': 0.5861147294628349, 'r2': -4.294947147369385}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  5.90it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.66it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.19it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.52it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.32it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.81it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.11it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.34it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.48it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.59it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.64it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.18it/s]
[2025-04-29 16:55:34,035][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3273
[2025-04-29 16:55:34,341][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.2808, Metrics: {'mse': 0.2835036516189575, 'rmse': 0.5324506095582552, 'r2': -3.3697338104248047}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.56it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.29it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.90it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.28it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.71it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:55:38,654][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2755
[2025-04-29 16:55:38,962][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.2330, Metrics: {'mse': 0.23532533645629883, 'rmse': 0.4851034286173401, 'r2': -2.627146005630493}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:10,  6.06it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.81it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 14.28it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.57it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.33it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.81it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.12it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.32it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.47it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.22it/s]
[2025-04-29 16:55:43,174][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.2159
[2025-04-29 16:55:43,497][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1944, Metrics: {'mse': 0.1964675784111023, 'rmse': 0.4432466338406895, 'r2': -2.0282187461853027}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.42it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.14it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.78it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.24it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.11it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 16:55:47,747][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1843
[2025-04-29 16:55:48,075][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1625, Metrics: {'mse': 0.16424411535263062, 'rmse': 0.40527042249913897, 'r2': -1.531548261642456}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.28it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.99it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.67it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.15it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.04it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 16:55:52,343][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1485
[2025-04-29 16:55:52,675][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1372, Metrics: {'mse': 0.1387103945016861, 'rmse': 0.37243844390944136, 'r2': -1.1379883289337158}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.39it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.09it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.74it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.62it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.63it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.64it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 16:55:56,970][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.1252
[2025-04-29 16:55:57,298][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1184, Metrics: {'mse': 0.11968279629945755, 'rmse': 0.34595201444630663, 'r2': -0.8447099924087524}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:10,  5.85it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 11.57it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 14.08it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.43it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:56:01,559][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.1023
[2025-04-29 16:56:01,889][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.1043, Metrics: {'mse': 0.10533244907855988, 'rmse': 0.32454960958004536, 'r2': -0.6235233545303345}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:11,  5.42it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.12it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.75it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.18it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.58it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.93it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.01it/s]
[2025-04-29 16:56:06,212][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0908
[2025-04-29 16:56:06,547][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0930, Metrics: {'mse': 0.09382659941911697, 'rmse': 0.3063112786351769, 'r2': -0.4461798667907715}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.95it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.65it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.58it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 16:56:10,843][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0804
[2025-04-29 16:56:11,174][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0844, Metrics: {'mse': 0.08510065823793411, 'rmse': 0.29172017111940357, 'r2': -0.31168413162231445}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:10,  5.85it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 11.58it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 14.08it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 16.20it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  81%|████████  | 51/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 16:56:15,484][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0666
[2025-04-29 16:56:15,828][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0780, Metrics: {'mse': 0.07850963622331619, 'rmse': 0.280195710572657, 'r2': -0.21009469032287598}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:10,  5.86it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 11.59it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 14.09it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  81%|████████  | 51/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 16:56:20,100][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0599
[2025-04-29 16:56:20,433][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0736, Metrics: {'mse': 0.07401866465806961, 'rmse': 0.27206371433557547, 'r2': -0.14087378978729248}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.13it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.81it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.51it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.01it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.92it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.49it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.10it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.28it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.66it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.65it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 16:56:24,779][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0537
[2025-04-29 16:56:25,087][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0706, Metrics: {'mse': 0.07082974165678024, 'rmse': 0.26613857604034075, 'r2': -0.09172189235687256}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:11,  5.23it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.91it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.53it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.62it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 16:56:29,393][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0536
[2025-04-29 16:56:29,727][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0686, Metrics: {'mse': 0.06874185055494308, 'rmse': 0.26218667120001177, 'r2': -0.059540629386901855}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.82it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.52it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 16:56:34,073][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0499
[2025-04-29 16:56:34,389][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0673, Metrics: {'mse': 0.06738436967134476, 'rmse': 0.2595849950812734, 'r2': -0.03861725330352783}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:     best_val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:      best_val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:    best_val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▄▃▂▂▂▂▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:          val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:           val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:         val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06732
wandb:     best_val_mse 0.06738
wandb:      best_val_r2 -0.03862
wandb:    best_val_rmse 0.25958
wandb:            epoch 15
wandb:   final_test_mse 0.06418
wandb:    final_test_r2 -0.10636
wandb:  final_test_rmse 0.25333
wandb:  final_train_mse 0.03692
wandb:   final_train_r2 -0.20265
wandb: final_train_rmse 0.19214
wandb:    final_val_mse 0.06738
wandb:     final_val_r2 -0.03862
wandb:   final_val_rmse 0.25958
wandb:    learning_rate 1e-05
wandb:       train_loss 0.04988
wandb:       train_time 69.83005
wandb:         val_loss 0.06732
wandb:          val_mse 0.06738
wandb:           val_r2 -0.03862
wandb:         val_rmse 0.25958
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165513-b3vg8j36
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165513-b3vg8j36/logs
Standard experiment completed successfully: layer_3_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_3/complexity/results.json
Running question_type experiment for language ar, layer 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:56:57,075][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_4/question_type
experiment_name: layer_4_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 4
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 16:56:57,075][__main__][INFO] - Normalized task: question_type
[2025-04-29 16:56:57,076][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 16:56:57,076][__main__][INFO] - Determined Task Type: classification
[2025-04-29 16:56:57,080][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 16:56:57,081][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:56:58,959][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:57:02,137][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:57:02,138][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:02,230][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,282][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,391][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:57:02,402][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:02,403][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:57:02,404][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:02,422][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,475][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,497][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:57:02,498][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:02,499][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:57:02,500][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:02,525][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,597][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:02,620][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:57:02,622][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:02,622][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:57:02,623][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:57:02,623][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:57:02,624][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:57:02,624][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:57:02,624][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:57:02,624][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 16:57:02,624][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 16:57:02,624][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:57:02,625][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 16:57:02,625][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:57:02,625][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:57:02,625][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:57:02,625][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:57:02,625][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 16:57:02,625][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:57:02,626][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:57:02,626][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 16:57:02,627][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 16:57:02,627][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:57:02,627][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:57:02,627][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:57:02,627][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:57:02,627][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:57:02,628][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:57:07,636][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:57:07,637][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:57:07,638][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 16:57:07,638][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 4
[2025-04-29 16:57:07,638][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:56,  1.10it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.61it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.12it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.48it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.57it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.33it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.74it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.83it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.66it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.28it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.71it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.03it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.26it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.42it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.52it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.59it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.76it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.81it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.33it/s]
[2025-04-29 16:57:14,249][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.7029
[2025-04-29 16:57:14,544][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  5.70it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.47it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.04it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.23it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.76it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.09it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.31it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.47it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.58it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.15it/s]
[2025-04-29 16:57:18,780][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.7022
[2025-04-29 16:57:19,092][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.59it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.33it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.92it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.35it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.09it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.30it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.13it/s]
[2025-04-29 16:57:23,388][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.7002
[2025-04-29 16:57:23,713][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.22it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.93it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.64it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.13it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.04it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 16:57:27,417][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6981
[2025-04-29 16:57:27,750][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6886, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:10,  6.07it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.82it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 14.26it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.55it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.32it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.79it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.10it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.31it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.17it/s]
[2025-04-29 16:57:31,421][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6972
[2025-04-29 16:57:31,739][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 16:57:31,740][src.training.lm_trainer][INFO] - Early stopping at epoch 5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁
wandb:          best_val_f1 ▁▁
wandb:        best_val_loss █▁
wandb:                epoch ▁▁▃▃▅▅▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ████▁
wandb:           train_loss █▇▅▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁
wandb:             val_loss ▃▁▂▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68842
wandb:                epoch 5
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69718
wandb:           train_time 21.88921
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68866
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165657-rmzy1ib2
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165657-rmzy1ib2/logs
Standard experiment completed successfully: layer_4_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_4/question_type/results.json
Running complexity experiment for language ar, layer 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:57:49,872][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_4/complexity
experiment_name: layer_4_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 4
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 16:57:49,873][__main__][INFO] - Normalized task: complexity
[2025-04-29 16:57:49,873][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 16:57:49,873][__main__][INFO] - Determined Task Type: regression
[2025-04-29 16:57:49,880][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 16:57:49,881][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:57:51,097][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:57:54,234][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:57:54,235][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:54,263][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,315][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,386][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:57:54,397][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:54,398][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:57:54,399][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:54,435][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,467][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,479][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:57:54,480][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:54,480][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:57:54,481][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:57:54,518][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,560][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:57:54,581][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:57:54,584][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:57:54,584][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:57:54,585][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:57:54,586][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:57:54,586][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:57:54,586][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:57:54,586][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:57:54,586][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:57:54,587][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 16:57:54,587][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:57:54,587][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 16:57:54,587][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:57:54,587][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:57:54,587][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:57:54,588][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:57:54,588][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:57:54,588][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 16:57:54,588][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:57:54,588][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 16:57:54,588][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 16:57:54,589][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 16:57:54,589][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 16:57:54,589][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 16:57:54,589][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 16:57:54,589][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 16:57:54,589][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:57:54,589][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 16:57:54,590][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:57:54,590][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:57:54,590][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:57:54,591][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:57:59,166][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:57:59,167][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:57:59,168][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 16:57:59,168][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 4
[2025-04-29 16:57:59,169][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:46,  1.35it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:14,  4.27it/s]Epoch 1/15:   8%|▊         | 5/63 [00:00<00:08,  7.01it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:05,  9.44it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 11.48it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:03, 13.12it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 14.38it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.35it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 16.05it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.57it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.93it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:01<00:02, 17.18it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.37it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.49it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.59it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.89it/s]
[2025-04-29 16:58:06,017][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.4462
[2025-04-29 16:58:06,306][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3712, Metrics: {'mse': 0.37438899278640747, 'rmse': 0.6118733470142391, 'r2': -4.770579814910889}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.49it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.22it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.83it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.22it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.09it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.65it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 16:58:10,569][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3578
[2025-04-29 16:58:10,883][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.3037, Metrics: {'mse': 0.3065677583217621, 'rmse': 0.5536856132515654, 'r2': -3.725228786468506}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.55it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.30it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.92it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.33it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 16:58:15,184][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2984
[2025-04-29 16:58:15,502][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.2498, Metrics: {'mse': 0.25228965282440186, 'rmse': 0.5022844341848569, 'r2': -2.888622760772705}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:10,  6.02it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.75it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 14.22it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.51it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.28it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.76it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.08it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.72it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.73it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 16:58:19,760][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.2319
[2025-04-29 16:58:20,086][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.2057, Metrics: {'mse': 0.20786428451538086, 'rmse': 0.45592135781884674, 'r2': -2.2038798332214355}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:10,  5.96it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.72it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 14.21it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.51it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.29it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.79it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.11it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.32it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.46it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 16:58:24,324][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1954
[2025-04-29 16:58:24,657][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1691, Metrics: {'mse': 0.1708924025297165, 'rmse': 0.41339134307544045, 'r2': -1.6340203285217285}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.28it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.98it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.67it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.04it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 16:58:28,957][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1549
[2025-04-29 16:58:29,283][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1404, Metrics: {'mse': 0.14193356037139893, 'rmse': 0.3767407070803458, 'r2': -1.1876683235168457}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:10,  5.90it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.63it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 14.13it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.46it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.24it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.03it/s]
[2025-04-29 16:58:33,569][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.1279
[2025-04-29 16:58:33,903][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1190, Metrics: {'mse': 0.12025464326143265, 'rmse': 0.34677751262363116, 'r2': -0.8535240888595581}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.94it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.64it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.95it/s]
[2025-04-29 16:58:38,200][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.1031
[2025-04-29 16:58:38,531][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.1034, Metrics: {'mse': 0.10439328849315643, 'rmse': 0.32309950246504004, 'r2': -0.6090477705001831}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:11,  5.17it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.85it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 16:58:42,877][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0910
[2025-04-29 16:58:43,222][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0913, Metrics: {'mse': 0.09215283393859863, 'rmse': 0.3035668525030337, 'r2': -0.42038166522979736}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:10,  5.86it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 11.59it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 14.10it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.45it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.24it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.73it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 17.06it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  81%|████████  | 51/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:58:47,493][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0805
[2025-04-29 16:58:47,822][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0830, Metrics: {'mse': 0.08359270542860031, 'rmse': 0.2891240312194756, 'r2': -0.28844165802001953}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:11,  5.36it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 11.07it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.71it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 16.03it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 16:58:52,154][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0667
[2025-04-29 16:58:52,488][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0769, Metrics: {'mse': 0.07734373956918716, 'rmse': 0.27810742451287984, 'r2': -0.19212424755096436}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:11,  5.40it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 11.09it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.73it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.93it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.97it/s]
[2025-04-29 16:58:56,783][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0610
[2025-04-29 16:58:57,119][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0727, Metrics: {'mse': 0.07309066504240036, 'rmse': 0.2703528528467942, 'r2': -0.1265702247619629}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:10,  5.75it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 11.46it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 14.00it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.34it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 16.15it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.65it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 16:59:01,464][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0545
[2025-04-29 16:59:01,785][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0699, Metrics: {'mse': 0.07016691565513611, 'rmse': 0.2648903842255058, 'r2': -0.08150553703308105}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:12,  5.13it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.80it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.51it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.00it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.92it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.49it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.12it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.67it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 16:59:06,082][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0555
[2025-04-29 16:59:06,405][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0681, Metrics: {'mse': 0.06821140646934509, 'rmse': 0.26117313504521306, 'r2': -0.05136454105377197}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.82it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.51it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.00it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.90it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.08it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.37it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.45it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.55it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.58it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.59it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.61it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.62it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.62it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.65it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.66it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 16:59:10,731][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0523
[2025-04-29 16:59:11,069][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0669, Metrics: {'mse': 0.06696311384439468, 'rmse': 0.2587723204757315, 'r2': -0.03212428092956543}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:     best_val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:      best_val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:    best_val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▄▃▂▂▂▂▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:          val_mse █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:           val_r2 ▁▃▄▅▆▆▇▇▇██████
wandb:         val_rmse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06693
wandb:     best_val_mse 0.06696
wandb:      best_val_r2 -0.03212
wandb:    best_val_rmse 0.25877
wandb:            epoch 15
wandb:   final_test_mse 0.06359
wandb:    final_test_r2 -0.09619
wandb:  final_test_rmse 0.25216
wandb:  final_train_mse 0.03634
wandb:   final_train_r2 -0.18376
wandb: final_train_rmse 0.19063
wandb:    final_val_mse 0.06696
wandb:     final_val_r2 -0.03212
wandb:   final_val_rmse 0.25877
wandb:    learning_rate 1e-05
wandb:       train_loss 0.05234
wandb:       train_time 69.87578
wandb:         val_loss 0.06693
wandb:          val_mse 0.06696
wandb:           val_r2 -0.03212
wandb:         val_rmse 0.25877
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165749-jg0agzkz
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165749-jg0agzkz/logs
Standard experiment completed successfully: layer_4_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_4/complexity/results.json
Running question_type experiment for language ar, layer 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 16:59:33,129][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_5/question_type
experiment_name: layer_5_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 5
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 16:59:33,130][__main__][INFO] - Normalized task: question_type
[2025-04-29 16:59:33,130][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 16:59:33,130][__main__][INFO] - Determined Task Type: classification
[2025-04-29 16:59:33,134][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 16:59:33,135][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 16:59:34,860][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 16:59:38,125][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 16:59:38,126][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:59:38,186][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,208][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,316][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 16:59:38,328][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:59:38,329][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 16:59:38,330][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:59:38,346][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,401][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,412][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 16:59:38,414][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:59:38,414][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 16:59:38,415][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 16:59:38,442][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,473][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 16:59:38,484][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 16:59:38,486][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 16:59:38,487][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 16:59:38,488][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 16:59:38,488][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:59:38,489][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:59:38,489][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:59:38,489][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:59:38,489][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 16:59:38,489][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 16:59:38,489][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 16:59:38,490][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 16:59:38,490][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:59:38,490][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:59:38,490][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:59:38,490][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:59:38,490][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 16:59:38,490][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 16:59:38,491][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 16:59:38,491][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 16:59:38,492][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 16:59:38,492][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 16:59:38,492][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 16:59:38,492][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 16:59:38,492][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 16:59:38,493][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 16:59:38,493][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 16:59:43,506][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 16:59:43,507][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 16:59:43,508][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 16:59:43,508][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 5
[2025-04-29 16:59:43,508][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:57,  1.07it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.53it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.00it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.35it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.45it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.22it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.64it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.76it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.60it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.23it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.69it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.00it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.24it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.42it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.53it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.61it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.78it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.81it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.25it/s]
[2025-04-29 16:59:50,223][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.7002
[2025-04-29 16:59:50,527][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6884, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  6.00it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.77it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.26it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.58it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.35it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.82it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.14it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.34it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.48it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.58it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.15it/s]
[2025-04-29 16:59:54,793][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6997
[2025-04-29 16:59:55,102][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:09,  6.32it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:04, 12.08it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.46it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.71it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.45it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.90it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.20it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.38it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.50it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.59it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.22it/s]
[2025-04-29 16:59:58,763][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6982
[2025-04-29 16:59:59,070][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:09,  6.34it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:04, 12.09it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 14.46it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.70it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.42it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.87it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.17it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.36it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.48it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:00:02,767][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6961
[2025-04-29 17:00:03,079][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6889, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 17:00:03,080][src.training.lm_trainer][INFO] - Early stopping at epoch 4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss █▇▅▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▅█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68843
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69614
wandb:           train_time 17.28079
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68891
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165933-75kgztl5
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_165933-75kgztl5/logs
Standard experiment completed successfully: layer_5_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_5/question_type/results.json
Running complexity experiment for language ar, layer 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:00:21,772][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_5/complexity
experiment_name: layer_5_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 5
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:00:21,773][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:00:21,773][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:00:21,773][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:00:21,777][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:00:21,778][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:00:22,975][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:00:26,207][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:00:26,207][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:00:26,247][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,337][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,401][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:00:26,411][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:00:26,411][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:00:26,412][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:00:26,442][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,471][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,484][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:00:26,486][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:00:26,486][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:00:26,487][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:00:26,525][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,560][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:00:26,572][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:00:26,574][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:00:26,574][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:00:26,575][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:00:26,576][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:00:26,576][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:00:26,576][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:00:26,576][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:00:26,576][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:00:26,577][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:00:26,577][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:00:26,578][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:00:26,578][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:00:26,578][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:00:26,578][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:00:26,578][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:00:26,578][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:00:26,579][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:00:26,579][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:00:26,579][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:00:26,579][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:00:26,579][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:00:26,579][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:00:26,580][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:00:26,580][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:00:26,580][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:00:26,581][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:00:30,929][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:00:30,930][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:00:30,931][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:00:30,931][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 5
[2025-04-29 17:00:30,931][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:49,  1.24it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  4.00it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.65it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  9.06it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 11.12it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.81it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 14.13it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.15it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.91it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.46it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.85it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.14it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.32it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.47it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.58it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.65it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.82it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.78it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.64it/s]
[2025-04-29 17:00:37,855][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3950
[2025-04-29 17:00:38,148][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3286, Metrics: {'mse': 0.33159369230270386, 'rmse': 0.5758417250449154, 'r2': -4.110961437225342}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  5.70it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.44it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.01it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.37it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.84it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:00:42,424][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3118
[2025-04-29 17:00:42,734][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.2649, Metrics: {'mse': 0.2675125002861023, 'rmse': 0.5172161059809548, 'r2': -3.1232571601867676}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:10,  6.07it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.84it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.29it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.60it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.35it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.82it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.15it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.35it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.50it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.11it/s]
[2025-04-29 17:00:47,030][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2565
[2025-04-29 17:00:47,347][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.2138, Metrics: {'mse': 0.21602223813533783, 'rmse': 0.46478192535353374, 'r2': -2.3296210765838623}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.61it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.36it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.96it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.36it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.18it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.68it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.03it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.11it/s]
[2025-04-29 17:00:51,598][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1954
[2025-04-29 17:00:51,914][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1747, Metrics: {'mse': 0.1765202134847641, 'rmse': 0.4201430869177358, 'r2': -1.7207636833190918}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.43it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.16it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.81it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.26it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.13it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.03it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.75it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:00:56,169][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1630
[2025-04-29 17:00:56,500][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1437, Metrics: {'mse': 0.14525312185287476, 'rmse': 0.3811208756456077, 'r2': -1.2388336658477783}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.52it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.24it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.86it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.29it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.14it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:01:00,769][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1304
[2025-04-29 17:01:01,098][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1210, Metrics: {'mse': 0.12228705734014511, 'rmse': 0.3496956638852491, 'r2': -0.884850263595581}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.21it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.91it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:01:05,389][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.1087
[2025-04-29 17:01:05,723][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1038, Metrics: {'mse': 0.10484945774078369, 'rmse': 0.3238046598503235, 'r2': -0.6160788536071777}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:10,  5.88it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 11.63it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 14.15it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.48it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.26it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.73it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 17.06it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 8/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 17:01:09,979][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0872
[2025-04-29 17:01:10,315][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0911, Metrics: {'mse': 0.09196298569440842, 'rmse': 0.3032539953478081, 'r2': -0.41745543479919434}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:10,  5.78it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.52it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 14.06it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.40it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:01:14,609][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0768
[2025-04-29 17:01:14,937][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0819, Metrics: {'mse': 0.08250540494918823, 'rmse': 0.2872375409816555, 'r2': -0.2716827392578125}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:11,  5.46it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 11.17it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.81it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.24it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.11it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.64it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.66it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:01:19,227][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0691
[2025-04-29 17:01:19,560][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0757, Metrics: {'mse': 0.07612497359514236, 'rmse': 0.2759075453755159, 'r2': -0.17333900928497314}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:11,  5.22it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.90it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.58it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.53it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.66it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.67it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:01:23,908][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0573
[2025-04-29 17:01:24,232][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0714, Metrics: {'mse': 0.07171240448951721, 'rmse': 0.26779171848568656, 'r2': -0.10532665252685547}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:11,  5.26it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.97it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.64it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.00it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:01:28,521][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0528
[2025-04-29 17:01:28,860][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0688, Metrics: {'mse': 0.0689239650964737, 'rmse': 0.2625337408724328, 'r2': -0.06234753131866455}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:11,  5.30it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.66it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.62it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:01:33,181][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0478
[2025-04-29 17:01:33,522][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0672, Metrics: {'mse': 0.06721597909927368, 'rmse': 0.2592604464612249, 'r2': -0.03602182865142822}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:10,  5.69it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 11.40it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.94it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.30it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 16.10it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.60it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.61it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.62it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.62it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.62it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:01:37,824][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0491
[2025-04-29 17:01:38,164][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0664, Metrics: {'mse': 0.0663347989320755, 'rmse': 0.2575554288538207, 'r2': -0.02243983745574951}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:11,  5.23it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.90it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.05it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.49it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.56it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.61it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:01:42,539][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0467
[2025-04-29 17:01:42,864][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0660, Metrics: {'mse': 0.06592392176389694, 'rmse': 0.2567565418132456, 'r2': -0.01610696315765381}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▅▄▃▂▂▂▁▁▁▁▁▁▁
wandb:     best_val_mse █▆▅▄▃▂▂▂▁▁▁▁▁▁▁
wandb:      best_val_r2 ▁▃▄▅▆▇▇▇███████
wandb:    best_val_rmse █▇▆▅▄▃▂▂▂▁▁▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▅▄▃▂▂▂▁▁▁▁▁▁▁
wandb:          val_mse █▆▅▄▃▂▂▂▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▄▅▆▇▇▇███████
wandb:         val_rmse █▇▆▅▄▃▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06604
wandb:     best_val_mse 0.06592
wandb:      best_val_r2 -0.01611
wandb:    best_val_rmse 0.25676
wandb:            epoch 15
wandb:   final_test_mse 0.06112
wandb:    final_test_r2 -0.05361
wandb:  final_test_rmse 0.24722
wandb:  final_train_mse 0.03338
wandb:   final_train_r2 -0.08728
wandb: final_train_rmse 0.18269
wandb:    final_val_mse 0.06592
wandb:     final_val_r2 -0.01611
wandb:   final_val_rmse 0.25676
wandb:    learning_rate 1e-05
wandb:       train_loss 0.0467
wandb:       train_time 69.91339
wandb:         val_loss 0.06604
wandb:          val_mse 0.06592
wandb:           val_r2 -0.01611
wandb:         val_rmse 0.25676
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170021-orpa6rum
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170021-orpa6rum/logs
Standard experiment completed successfully: layer_5_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_5/complexity/results.json
Running question_type experiment for language ar, layer 6
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:02:08,215][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_6/question_type
experiment_name: layer_6_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 6
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:02:08,215][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:02:08,216][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:02:08,216][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:02:08,220][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:02:08,220][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:02:09,760][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:02:12,951][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:02:12,952][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:02:13,009][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,044][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,161][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:02:13,174][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:02:13,174][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:02:13,175][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:02:13,211][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,283][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,297][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:02:13,299][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:02:13,299][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:02:13,300][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:02:13,337][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,369][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:02:13,391][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:02:13,393][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:02:13,393][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:02:13,404][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:02:13,404][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:02:13,404][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:02:13,405][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:02:13,405][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:02:13,405][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:02:13,405][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:02:13,405][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:02:13,405][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:02:13,406][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:02:13,406][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:02:13,406][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:02:13,406][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:02:13,406][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:02:13,406][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:02:13,406][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:02:13,407][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:02:13,407][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:02:13,407][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:02:13,407][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:02:13,407][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:02:13,407][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:02:13,408][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:02:13,408][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:02:13,408][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:02:13,408][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:02:13,408][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:02:13,409][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:02:13,409][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:02:18,325][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:02:18,326][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:02:18,328][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:02:18,328][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 6
[2025-04-29 17:02:18,328][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:52,  1.18it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.83it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.42it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.81it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.88it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.61it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.96it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.02it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.79it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.37it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.78it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.08it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.28it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.43it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.54it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.52it/s]
[2025-04-29 17:02:24,914][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6990
[2025-04-29 17:02:25,216][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6885, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:10,  5.79it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.56it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.11it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.47it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.27it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.77it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.10it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.33it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.13it/s]
[2025-04-29 17:02:29,469][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6988
[2025-04-29 17:02:29,769][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6887, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:09,  6.29it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:04, 12.02it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.43it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.68it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.41it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.86it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.17it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.36it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.50it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.58it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.19it/s]
[2025-04-29 17:02:33,436][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6978
[2025-04-29 17:02:33,754][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6889, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.61it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.31it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.90it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.29it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.10it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 17:02:37,445][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6960
[2025-04-29 17:02:37,737][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6890, Metrics: {'accuracy': 0.5454545454545454, 'f1': 0.0}
[2025-04-29 17:02:37,738][src.training.lm_trainer][INFO] - Early stopping at epoch 4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁
wandb:          best_val_f1 ▁
wandb:        best_val_loss ▁
wandb:                epoch ▁▁▃▃▆▆██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁
wandb:           train_loss ██▅▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁
wandb:               val_f1 ▁▁▁▁
wandb:             val_loss ▁▃▆█
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.54545
wandb:          best_val_f1 0
wandb:        best_val_loss 0.68855
wandb:                epoch 4
wandb:  final_test_accuracy 0.71429
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5005
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.54545
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69599
wandb:           train_time 17.16485
wandb:         val_accuracy 0.54545
wandb:               val_f1 0
wandb:             val_loss 0.68904
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170208-hx2hkgd6
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170208-hx2hkgd6/logs
Standard experiment completed successfully: layer_6_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_6/question_type/results.json
Running complexity experiment for language ar, layer 6
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:02:57,926][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_6/complexity
experiment_name: layer_6_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 6
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:02:57,927][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:02:57,927][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:02:57,927][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:02:57,932][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:02:57,932][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:02:59,442][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:03:02,586][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:03:02,587][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:03:02,615][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,635][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,723][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:03:02,735][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:03:02,736][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:03:02,737][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:03:02,751][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,793][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,814][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:03:02,816][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:03:02,816][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:03:02,817][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:03:02,842][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,918][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:03:02,940][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:03:02,942][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:03:02,942][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:03:02,943][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:03:02,944][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:03:02,944][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:03:02,944][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:03:02,944][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:03:02,944][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:03:02,945][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:03:02,945][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:03:02,945][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:03:02,945][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:03:02,945][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:03:02,945][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:03:02,946][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:03:02,946][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:03:02,946][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:03:02,946][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:03:02,946][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:03:02,946][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:03:02,947][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:03:02,947][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:03:02,947][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:03:02,947][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:03:02,947][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:03:02,947][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:03:02,948][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:03:02,948][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:03:02,948][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:03:02,948][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:03:02,949][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:03:07,266][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:03:07,267][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:03:07,268][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:03:07,268][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 6
[2025-04-29 17:03:07,268][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:51,  1.20it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.88it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.49it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.88it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.95it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.67it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 14.01it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.06it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.83it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.40it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.81it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.12it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.32it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.49it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.58it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.66it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.78it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.84it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.52it/s]
[2025-04-29 17:03:14,379][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3694
[2025-04-29 17:03:14,691][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.3159, Metrics: {'mse': 0.31882408261299133, 'rmse': 0.564645094384952, 'r2': -3.914139747619629}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.59it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.35it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.96it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.36it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.73it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.82it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.13it/s]
[2025-04-29 17:03:18,971][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3049
[2025-04-29 17:03:19,283][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.2662, Metrics: {'mse': 0.26884034276008606, 'rmse': 0.51849816080685, 'r2': -3.143723487854004}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:10,  6.00it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.76it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 14.25it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.56it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.33it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.81it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.13it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.34it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.47it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.57it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.64it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.17it/s]
[2025-04-29 17:03:23,549][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2618
[2025-04-29 17:03:23,879][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.2256, Metrics: {'mse': 0.2279445230960846, 'rmse': 0.47743536012332033, 'r2': -2.513383150100708}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.29it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.01it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:03:28,151][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.2099
[2025-04-29 17:03:28,474][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1917, Metrics: {'mse': 0.19367805123329163, 'rmse': 0.4400886856456226, 'r2': -1.9852230548858643}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.20it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.90it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.93it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:03:32,740][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1811
[2025-04-29 17:03:33,074][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1627, Metrics: {'mse': 0.16448740661144257, 'rmse': 0.40557047058611473, 'r2': -1.5352978706359863}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.94it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.62it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.10it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 17:03:37,347][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1500
[2025-04-29 17:03:37,679][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1397, Metrics: {'mse': 0.1412610411643982, 'rmse': 0.3758470981189002, 'r2': -1.177302360534668}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:10,  5.82it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.54it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 14.06it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.40it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.70it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 17.03it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.64it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.65it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 7/15:  81%|████████  | 51/63 [00:02<00:00, 17.70it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 17:03:42,014][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.1280
[2025-04-29 17:03:42,346][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1218, Metrics: {'mse': 0.12313566356897354, 'rmse': 0.35090691581810346, 'r2': -0.8979301452636719}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.28it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.99it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.66it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.14it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.03it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.60it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 17:03:46,619][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.1059
[2025-04-29 17:03:46,931][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.1074, Metrics: {'mse': 0.10853547602891922, 'rmse': 0.32944722798791193, 'r2': -0.6728925704956055}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:10,  5.89it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.63it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 14.12it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.43it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.22it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 9/15:  81%|████████  | 51/63 [00:02<00:00, 17.73it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 17:03:51,209][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0941
[2025-04-29 17:03:51,518][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0960, Metrics: {'mse': 0.09695107489824295, 'rmse': 0.311369675624077, 'r2': -0.4943385124206543}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:10,  5.80it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 11.54it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 14.07it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.43it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.23it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 10/15:  81%|████████  | 51/63 [00:02<00:00, 17.72it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:03:55,782][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0836
[2025-04-29 17:03:56,113][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0873, Metrics: {'mse': 0.08808428049087524, 'rmse': 0.29678996022587295, 'r2': -0.35767173767089844}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.92it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.60it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.09it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.97it/s]
[2025-04-29 17:04:00,437][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0697
[2025-04-29 17:04:00,772][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0805, Metrics: {'mse': 0.08113499730825424, 'rmse': 0.28484205677577573, 'r2': -0.2505601644515991}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:10,  5.80it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 11.54it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 14.06it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.42it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.23it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.73it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 17.06it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  81%|████████  | 51/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:04:05,068][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0624
[2025-04-29 17:04:05,404][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0756, Metrics: {'mse': 0.07604464888572693, 'rmse': 0.2757619424172359, 'r2': -0.17210102081298828}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:11,  5.37it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 11.08it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.71it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 16.03it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:04:09,754][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0555
[2025-04-29 17:04:10,097][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0719, Metrics: {'mse': 0.07222602516412735, 'rmse': 0.26874900030349386, 'r2': -0.1132432222366333}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:10,  5.86it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 11.59it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 14.09it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.40it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.97it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.56it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.59it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.61it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.62it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.62it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.61it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.62it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.62it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 17:04:14,376][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0543
[2025-04-29 17:04:14,700][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0693, Metrics: {'mse': 0.06954418867826462, 'rmse': 0.26371232181728754, 'r2': -0.0719071626663208}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:11,  5.23it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.91it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.06it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:04:19,057][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0501
[2025-04-29 17:04:19,390][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0675, Metrics: {'mse': 0.06767361611127853, 'rmse': 0.2601415309236081, 'r2': -0.04307544231414795}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▇▅▄▄▃▃▂▂▂▁▁▁▁▁
wandb:     best_val_mse █▇▅▅▄▃▃▂▂▂▁▁▁▁▁
wandb:      best_val_r2 ▁▂▄▄▅▆▆▇▇▇█████
wandb:    best_val_rmse █▇▆▅▄▄▃▃▂▂▂▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▇▅▄▄▃▃▂▂▂▁▁▁▁▁
wandb:          val_mse █▇▅▅▄▃▃▂▂▂▁▁▁▁▁
wandb:           val_r2 ▁▂▄▄▅▆▆▇▇▇█████
wandb:         val_rmse █▇▆▅▄▄▃▃▂▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06753
wandb:     best_val_mse 0.06767
wandb:      best_val_r2 -0.04308
wandb:    best_val_rmse 0.26014
wandb:            epoch 15
wandb:   final_test_mse 0.06504
wandb:    final_test_r2 -0.12133
wandb:  final_test_rmse 0.25504
wandb:  final_train_mse 0.03884
wandb:   final_train_r2 -0.26525
wandb: final_train_rmse 0.19708
wandb:    final_val_mse 0.06767
wandb:     final_val_r2 -0.04308
wandb:   final_val_rmse 0.26014
wandb:    learning_rate 1e-05
wandb:       train_loss 0.05013
wandb:       train_time 69.93716
wandb:         val_loss 0.06753
wandb:          val_mse 0.06767
wandb:           val_r2 -0.04308
wandb:         val_rmse 0.26014
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170257-6uovkgud
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170257-6uovkgud/logs
Standard experiment completed successfully: layer_6_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_6/complexity/results.json
Running question_type experiment for language ar, layer 7
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:04:41,492][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_7/question_type
experiment_name: layer_7_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 7
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:04:41,492][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:04:41,492][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:04:41,493][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:04:41,497][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:04:41,497][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:04:43,381][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:04:46,580][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:04:46,581][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:04:46,656][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,695][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,797][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:04:46,808][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:04:46,809][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:04:46,810][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:04:46,833][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,874][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,895][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:04:46,897][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:04:46,897][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:04:46,898][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:04:46,922][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,953][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:04:46,965][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:04:46,967][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:04:46,967][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:04:46,968][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:04:46,968][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:04:46,968][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:04:46,969][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:04:46,969][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:04:46,969][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:04:46,969][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:04:46,969][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:04:46,969][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:04:46,970][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:04:46,970][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:04:46,970][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:04:46,970][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:04:46,970][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:04:46,970][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:04:46,970][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:04:46,971][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:04:46,971][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:04:46,971][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:04:46,971][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:04:46,971][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:04:46,971][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:04:46,972][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:04:46,972][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:04:46,972][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:04:46,972][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:04:46,972][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:04:46,973][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:04:46,973][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:04:51,943][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:04:51,944][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:04:51,945][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:04:51,946][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 7
[2025-04-29 17:04:51,946][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:56,  1.10it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.61it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.11it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.47it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.55it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.31it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.71it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.80it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.62it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.23it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.67it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 16.97it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.20it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.36it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.48it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.57it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.71it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.72it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.74it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.74it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.74it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.74it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.75it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.77it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.28it/s]
[2025-04-29 17:04:58,451][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6944
[2025-04-29 17:04:58,751][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6986, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:09,  6.36it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:04, 12.12it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.48it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.73it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.46it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.91it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.20it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.39it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.51it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.60it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:03<00:02,  6.92it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:03<00:02,  8.47it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:03<00:01, 10.05it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:03<00:01, 11.56it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 12.93it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 14.08it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 15.01it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 15.76it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:04<00:00, 16.33it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:04<00:00, 16.76it/s]Epoch 2/15: 100%|██████████| 63/63 [00:04<00:00, 14.87it/s]
[2025-04-29 17:05:03,552][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6940
[2025-04-29 17:05:03,853][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6985, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.60it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.35it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.94it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.35it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.19it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.74it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.08it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.32it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.46it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.56it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.75it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:05:08,128][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6944
[2025-04-29 17:05:08,453][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6983, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.28it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.68it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:05:12,700][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6941
[2025-04-29 17:05:13,025][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6982, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.50it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.24it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.86it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.28it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.14it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.68it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.75it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 17:05:17,252][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6942
[2025-04-29 17:05:17,561][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6980, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:10,  5.99it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.74it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 14.22it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.53it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.31it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.79it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 17.10it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.31it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.10it/s]
[2025-04-29 17:05:21,801][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6939
[2025-04-29 17:05:22,111][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6979, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:10,  5.90it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 11.64it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 14.13it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.47it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.26it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.76it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 17.07it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.29it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  81%|████████  | 51/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 17:05:26,357][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6942
[2025-04-29 17:05:26,693][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6977, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.30it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 11.01it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.70it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.06it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 17:05:30,985][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6935
[2025-04-29 17:05:31,319][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6976, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:10,  5.83it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.58it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 14.10it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.45it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.24it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.74it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 17.06it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.67it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 17:05:35,603][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6942
[2025-04-29 17:05:35,941][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6976, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:10,  5.81it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 11.51it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 14.02it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.36it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 16.13it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.62it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.62it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.65it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:05:39,658][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6938
[2025-04-29 17:05:39,988][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6974, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:11,  5.43it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 11.15it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.76it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.20it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:05:44,270][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6938
[2025-04-29 17:05:44,585][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6973, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:10,  5.80it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 11.52it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 14.04it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.39it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.18it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.60it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.63it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.60it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.65it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:05:48,889][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6938
[2025-04-29 17:05:49,223][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6972, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.92it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:05:53,540][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6938
[2025-04-29 17:05:53,877][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6971, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:11,  5.33it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 11.01it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.64it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.09it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.49it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.10it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.44it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.62it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.93it/s]
[2025-04-29 17:05:58,210][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6934
[2025-04-29 17:05:58,544][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6969, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:10,  5.75it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 11.48it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 14.02it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.37it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 17.03it/s]
[2025-04-29 17:06:02,835][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6938
[2025-04-29 17:06:03,172][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6969, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▇▇▆▆▅▄▄▃▃▂▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss █▅█▆▇▄▆▂▇▄▄▄▄▁▄
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▇▇▆▆▅▄▄▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.45455
wandb:          best_val_f1 0.625
wandb:        best_val_loss 0.69686
wandb:                epoch 15
wandb:  final_test_accuracy 0.28571
wandb:        final_test_f1 0.44444
wandb: final_train_accuracy 0.4995
wandb:       final_train_f1 0.66622
wandb:   final_val_accuracy 0.45455
wandb:         final_val_f1 0.625
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69377
wandb:           train_time 69.73551
wandb:         val_accuracy 0.45455
wandb:               val_f1 0.625
wandb:             val_loss 0.69686
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170441-biit05pj
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170441-biit05pj/logs
Standard experiment completed successfully: layer_7_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_7/question_type/results.json
Running complexity experiment for language ar, layer 7
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:06:25,980][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_7/complexity
experiment_name: layer_7_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 7
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:06:25,980][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:06:25,980][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:06:25,981][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:06:25,985][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:06:25,986][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:06:27,520][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:06:30,676][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:06:30,677][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:06:30,789][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:30,888][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:31,050][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:06:31,060][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:06:31,061][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:06:31,064][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:06:31,107][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:31,148][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:31,179][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:06:31,181][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:06:31,181][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:06:31,182][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:06:31,207][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:31,229][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:06:31,250][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:06:31,252][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:06:31,252][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:06:31,253][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:06:31,254][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:06:31,254][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:06:31,254][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:06:31,254][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:06:31,254][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:06:31,255][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:06:31,255][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:06:31,256][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:06:31,256][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:06:31,256][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:06:31,256][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:06:31,256][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:06:31,256][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:06:31,256][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:06:31,257][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:06:31,257][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:06:31,257][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:06:31,257][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:06:31,257][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:06:31,257][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:06:31,258][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:06:31,258][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:06:31,259][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:06:36,144][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:06:36,145][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:06:36,146][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:06:36,146][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 7
[2025-04-29 17:06:36,146][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:53,  1.15it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.75it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.32it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.70it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.78it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.52it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.89it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.97it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.76it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.36it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.78it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.08it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.30it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.43it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.54it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.46it/s]
[2025-04-29 17:06:42,588][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1331
[2025-04-29 17:06:42,890][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.1379, Metrics: {'mse': 0.1393844485282898, 'rmse': 0.3733422672673023, 'r2': -1.1483778953552246}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.37it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.11it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.78it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.25it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.68it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 17:06:47,173][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.1214
[2025-04-29 17:06:47,480][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1290, Metrics: {'mse': 0.13035209476947784, 'rmse': 0.3610430649790657, 'r2': -1.0091593265533447}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.45it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.19it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.83it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.29it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.13it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.68it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.13it/s]
[2025-04-29 17:06:51,767][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.1123
[2025-04-29 17:06:52,087][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1209, Metrics: {'mse': 0.12216928601264954, 'rmse': 0.34952723214743875, 'r2': -0.8830350637435913}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.51it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.24it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.86it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.30it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.15it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.67it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.03it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 17:06:56,340][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1026
[2025-04-29 17:06:56,668][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1126, Metrics: {'mse': 0.11381823569536209, 'rmse': 0.33736958323974925, 'r2': -0.7543175220489502}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.30it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.67it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.14it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.73it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:07:00,948][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0925
[2025-04-29 17:07:01,278][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1050, Metrics: {'mse': 0.10610383003950119, 'rmse': 0.32573582860886086, 'r2': -0.6354129314422607}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:10,  5.84it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.60it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 14.13it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.46it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.25it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.76it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 17.07it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  81%|████████  | 51/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 17:07:05,538][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0850
[2025-04-29 17:07:05,847][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0983, Metrics: {'mse': 0.09928562492132187, 'rmse': 0.3150962153395719, 'r2': -0.5303217172622681}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.21it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.89it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.06it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.67it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.93it/s]
[2025-04-29 17:07:10,173][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0784
[2025-04-29 17:07:10,503][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0921, Metrics: {'mse': 0.09294486045837402, 'rmse': 0.3048685953954163, 'r2': -0.43258941173553467}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.28it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.99it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.66it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.14it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 16.03it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.97it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:07:14,792][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0707
[2025-04-29 17:07:15,106][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0866, Metrics: {'mse': 0.08731845021247864, 'rmse': 0.2954969546585525, 'r2': -0.34586775302886963}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.94it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.63it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.03it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:07:19,439][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0641
[2025-04-29 17:07:19,774][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0817, Metrics: {'mse': 0.08229071646928787, 'rmse': 0.28686358512241994, 'r2': -0.26837360858917236}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.77it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.51it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.03it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.95it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.68it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.68it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:07:24,082][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0595
[2025-04-29 17:07:24,410][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0776, Metrics: {'mse': 0.07808560878038406, 'rmse': 0.2794380231471445, 'r2': -0.20355892181396484}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  5.14it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.82it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.54it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.05it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.93it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.67it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.67it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.67it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:07:28,781][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0545
[2025-04-29 17:07:29,117][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0741, Metrics: {'mse': 0.07455863058567047, 'rmse': 0.2730542630791002, 'r2': -0.14919650554656982}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:11,  5.62it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 11.35it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.94it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.34it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 16.15it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:07:33,423][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0496
[2025-04-29 17:07:33,761][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0716, Metrics: {'mse': 0.07192198187112808, 'rmse': 0.2681827396965138, 'r2': -0.10855698585510254}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:10,  5.71it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 11.44it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.96it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.31it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 16.12it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.62it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:07:38,093][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0465
[2025-04-29 17:07:38,439][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0697, Metrics: {'mse': 0.06994183361530304, 'rmse': 0.2644651841269528, 'r2': -0.07803630828857422}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:11,  5.42it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 11.13it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.76it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.19it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.58it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.67it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.67it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:07:42,753][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0448
[2025-04-29 17:07:43,091][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0682, Metrics: {'mse': 0.0684245228767395, 'rmse': 0.26158081519243626, 'r2': -0.0546494722366333}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.93it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.09it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:07:47,434][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0416
[2025-04-29 17:07:47,773][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0671, Metrics: {'mse': 0.06726483255624771, 'rmse': 0.2593546462977822, 'r2': -0.03677475452423096}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▇▆▆▅▄▃▃▂▂▂▁▁▁▁
wandb:     best_val_mse █▇▆▆▅▄▃▃▂▂▂▁▁▁▁
wandb:      best_val_r2 ▁▂▃▃▄▅▆▆▇▇▇████
wandb:    best_val_rmse █▇▇▆▅▄▄▃▃▂▂▂▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▇▆▆▅▄▄▃▃▂▂▂▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▇▆▆▅▄▃▃▂▂▂▁▁▁▁
wandb:          val_mse █▇▆▆▅▄▃▃▂▂▂▁▁▁▁
wandb:           val_r2 ▁▂▃▃▄▅▆▆▇▇▇████
wandb:         val_rmse █▇▇▆▅▄▄▃▃▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06714
wandb:     best_val_mse 0.06726
wandb:      best_val_r2 -0.03677
wandb:    best_val_rmse 0.25935
wandb:            epoch 15
wandb:   final_test_mse 0.06434
wandb:    final_test_r2 -0.10917
wandb:  final_test_rmse 0.25365
wandb:  final_train_mse 0.03825
wandb:   final_train_r2 -0.24598
wandb: final_train_rmse 0.19557
wandb:    final_val_mse 0.06726
wandb:     final_val_r2 -0.03677
wandb:   final_val_rmse 0.25935
wandb:    learning_rate 1e-05
wandb:       train_loss 0.04158
wandb:       train_time 70.13467
wandb:         val_loss 0.06714
wandb:          val_mse 0.06726
wandb:           val_r2 -0.03677
wandb:         val_rmse 0.25935
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170626-4vmas745
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170626-4vmas745/logs
Standard experiment completed successfully: layer_7_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_7/complexity/results.json
Running question_type experiment for language ar, layer 8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:08:09,204][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_8/question_type
experiment_name: layer_8_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 8
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:08:09,204][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:08:09,204][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:08:09,204][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:08:09,209][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:08:09,209][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:08:10,980][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:08:14,126][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:08:14,127][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:08:14,196][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,228][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,335][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:08:14,346][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:08:14,346][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:08:14,348][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:08:14,398][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,443][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,455][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:08:14,457][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:08:14,457][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:08:14,458][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:08:14,504][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,536][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:08:14,558][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:08:14,560][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:08:14,561][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:08:14,561][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:08:14,562][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:08:14,562][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:08:14,562][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:08:14,563][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:08:14,563][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:08:14,563][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:08:14,563][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:08:14,563][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:08:14,563][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:08:14,564][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:08:14,564][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:08:14,564][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:08:14,564][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:08:14,564][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:08:14,564][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:08:14,564][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:08:14,565][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:08:14,565][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:08:14,565][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:08:14,565][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:08:14,565][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:08:14,565][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:08:14,565][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:08:14,566][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:08:14,566][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:08:14,566][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:08:14,566][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:08:14,567][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:08:19,083][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:08:19,084][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:08:19,085][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:08:19,086][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 8
[2025-04-29 17:08:19,086][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:50,  1.22it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.93it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.56it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.96it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 11.02it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.72it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 14.06it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.09it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.85it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.40it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.81it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.10it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.29it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.44it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.56it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.64it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.79it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.61it/s]
[2025-04-29 17:08:25,445][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6939
[2025-04-29 17:08:25,745][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6980, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:09,  6.28it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:04, 12.02it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 14.40it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.65it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.38it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.84it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.14it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.33it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.72it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.75it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 17:08:29,998][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6939
[2025-04-29 17:08:30,305][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6978, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.33it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.05it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.73it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.21it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.10it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.65it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:08:34,619][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6944
[2025-04-29 17:08:34,948][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6977, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.35it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.07it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.74it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.21it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.10it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.66it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.02it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  81%|████████  | 51/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:08:39,196][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6938
[2025-04-29 17:08:39,504][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6975, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:10,  5.85it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.58it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 14.09it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.43it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.21it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.71it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 17.04it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 5/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 17:08:43,739][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6922
[2025-04-29 17:08:44,051][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6973, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.32it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 11.02it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.00it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.72it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:08:48,325][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6928
[2025-04-29 17:08:48,662][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6971, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.24it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.93it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.63it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:08:52,944][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6932
[2025-04-29 17:08:53,279][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6970, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:11,  5.20it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.89it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:08:57,561][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6925
[2025-04-29 17:08:57,896][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6967, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:11,  5.62it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 11.36it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.95it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.33it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.69it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 17.03it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.27it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 9/15:  81%|████████  | 51/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:09:02,184][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6925
[2025-04-29 17:09:02,529][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6967, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:12,  4.94it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.57it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.32it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.86it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.79it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.39it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.79it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.04it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.23it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.45it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.50it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.58it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.59it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.61it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.62it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.63it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:09:06,270][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6923
[2025-04-29 17:09:06,588][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6965, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  5.07it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.73it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.47it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.98it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.90it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.48it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.67it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:09:10,932][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6918
[2025-04-29 17:09:11,276][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6963, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:11,  5.27it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.95it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.95it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.56it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.59it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.59it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.60it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:09:15,596][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6930
[2025-04-29 17:09:15,936][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6963, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:11,  5.27it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.96it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.62it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.09it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.68it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:09:20,252][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6922
[2025-04-29 17:09:20,606][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6961, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:12,  4.98it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.62it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.37it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.91it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.85it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 17:09:24,943][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6915
[2025-04-29 17:09:25,287][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6960, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.16it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.82it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.52it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.03it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.63it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.63it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.62it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.62it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.65it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:09:29,658][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6923
[2025-04-29 17:09:30,013][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6959, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▇▇▆▆▅▅▄▃▂▂▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss ▇▇█▇▃▄▅▃▃▃▂▅▃▁▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▇▇▆▆▅▅▄▄▃▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.45455
wandb:          best_val_f1 0.625
wandb:        best_val_loss 0.6959
wandb:                epoch 15
wandb:  final_test_accuracy 0.28571
wandb:        final_test_f1 0.44444
wandb: final_train_accuracy 0.4995
wandb:       final_train_f1 0.66622
wandb:   final_val_accuracy 0.45455
wandb:         final_val_f1 0.625
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69225
wandb:           train_time 69.49884
wandb:         val_accuracy 0.45455
wandb:               val_f1 0.625
wandb:             val_loss 0.6959
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170809-8vi7332i
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170809-8vi7332i/logs
Standard experiment completed successfully: layer_8_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_8/question_type/results.json
Running complexity experiment for language ar, layer 8
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:09:51,943][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_8/complexity
experiment_name: layer_8_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 8
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:09:51,944][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:09:51,944][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:09:51,944][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:09:51,955][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:09:51,955][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:09:53,549][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:09:56,862][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:09:56,863][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:09:56,931][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:56,976][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:57,060][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:09:57,071][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:09:57,072][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:09:57,073][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:09:57,118][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:57,160][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:57,171][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:09:57,173][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:09:57,173][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:09:57,174][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:09:57,197][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:57,217][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:09:57,238][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:09:57,240][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:09:57,240][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:09:57,241][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:09:57,241][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:09:57,241][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:09:57,241][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:09:57,242][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:09:57,242][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:09:57,242][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:09:57,242][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:09:57,242][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:09:57,243][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:09:57,243][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:09:57,243][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:09:57,243][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:09:57,243][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:09:57,243][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:09:57,244][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:09:57,244][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:09:57,245][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:09:57,245][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:09:57,245][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:09:57,245][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:09:57,245][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:09:57,246][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:09:57,246][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:10:02,048][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:10:02,049][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:10:02,050][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:10:02,051][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 8
[2025-04-29 17:10:02,051][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:51,  1.20it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.88it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.49it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.89it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.96it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.68it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 14.03it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.07it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.83it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.40it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.81it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.10it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.31it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.47it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.59it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.65it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.76it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.76it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.74it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.76it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.78it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.51it/s]
[2025-04-29 17:10:08,311][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1416
[2025-04-29 17:10:08,635][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.1371, Metrics: {'mse': 0.13862527906894684, 'rmse': 0.37232415858891943, 'r2': -1.1366767883300781}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  4.95it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.62it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.41it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 14.99it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:10:12,930][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.1235
[2025-04-29 17:10:13,267][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1236, Metrics: {'mse': 0.12493017315864563, 'rmse': 0.3534546267325491, 'r2': -0.9255895614624023}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.27it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.11it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 14.76it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 15.77it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.43it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:01<00:02, 17.15it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:10:17,629][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.1099
[2025-04-29 17:10:17,977][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1126, Metrics: {'mse': 0.1137586161494255, 'rmse': 0.3372812122686728, 'r2': -0.7533986568450928}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.31it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 11.02it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.70it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.18it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.23it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:10:22,232][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0959
[2025-04-29 17:10:22,570][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1029, Metrics: {'mse': 0.10389268398284912, 'rmse': 0.322323880565572, 'r2': -0.6013318300247192}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.29it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.08it/s]
[2025-04-29 17:10:26,816][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0855
[2025-04-29 17:10:27,168][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0949, Metrics: {'mse': 0.09579737484455109, 'rmse': 0.3095115100356545, 'r2': -0.4765561819076538}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.19it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.89it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.60it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.10it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:10:31,454][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0755
[2025-04-29 17:10:31,816][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0881, Metrics: {'mse': 0.08885431289672852, 'rmse': 0.29808440565841166, 'r2': -0.3695404529571533}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:11,  5.22it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.92it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.97it/s]
[2025-04-29 17:10:36,116][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0687
[2025-04-29 17:10:36,455][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0826, Metrics: {'mse': 0.08322972804307938, 'rmse': 0.2884956291576692, 'r2': -0.28284692764282227}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:12,  4.79it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.42it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.23it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.83it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.81it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.95it/s]
[2025-04-29 17:10:40,749][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0605
[2025-04-29 17:10:41,113][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0778, Metrics: {'mse': 0.0783473551273346, 'rmse': 0.2799059755120183, 'r2': -0.20759332180023193}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.83it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.06it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:10:45,423][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0549
[2025-04-29 17:10:45,784][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0735, Metrics: {'mse': 0.07395502924919128, 'rmse': 0.2719467397289243, 'r2': -0.1398930549621582}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:12,  5.16it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.85it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.57it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:10:50,084][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0501
[2025-04-29 17:10:50,443][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0706, Metrics: {'mse': 0.0709305927157402, 'rmse': 0.26632797959609916, 'r2': -0.09327638149261475}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:13,  4.73it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.31it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.13it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.75it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.73it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.38it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.80it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:01<00:02, 17.08it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.48it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:10:54,802][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0456
[2025-04-29 17:10:55,172][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0685, Metrics: {'mse': 0.0686827227473259, 'rmse': 0.2620738879540003, 'r2': -0.05862927436828613}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.75it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.47it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.96it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.88it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.46it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.09it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.45it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.50it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.56it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.68it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.68it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:10:59,497][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0425
[2025-04-29 17:10:59,859][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0670, Metrics: {'mse': 0.06712818890810013, 'rmse': 0.2590910822627829, 'r2': -0.034668684005737305}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.13it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.78it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 15.00it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:11:04,198][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0396
[2025-04-29 17:11:04,546][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0660, Metrics: {'mse': 0.06602008640766144, 'rmse': 0.2569437417172511, 'r2': -0.017589092254638672}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:13,  4.67it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.24it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.06it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.66it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.66it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.30it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.72it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 17.00it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.20it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.33it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.42it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.49it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.62it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.63it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.77it/s]
[2025-04-29 17:11:08,899][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0380
[2025-04-29 17:11:09,243][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0654, Metrics: {'mse': 0.06531184166669846, 'rmse': 0.2555618157446422, 'r2': -0.00667262077331543}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:13,  4.54it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.10it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 12.96it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.61it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.65it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.30it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.74it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:01<00:02, 17.04it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.24it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.38it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.76it/s]
[2025-04-29 17:11:13,637][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0365
[2025-04-29 17:11:14,001][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0651, Metrics: {'mse': 0.06495576351881027, 'rmse': 0.2548642060368821, 'r2': -0.0011843442916870117}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:     best_val_mse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:      best_val_r2 ▁▂▃▄▅▆▆▇▇▇█████
wandb:    best_val_rmse █▇▆▅▄▄▃▂▂▂▁▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▇▆▅▄▄▃▃▂▂▂▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:          val_mse █▇▆▅▄▃▃▂▂▂▁▁▁▁▁
wandb:           val_r2 ▁▂▃▄▅▆▆▇▇▇█████
wandb:         val_rmse █▇▆▅▄▄▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06508
wandb:     best_val_mse 0.06496
wandb:      best_val_r2 -0.00118
wandb:    best_val_rmse 0.25486
wandb:            epoch 15
wandb:   final_test_mse 0.0596
wandb:    final_test_r2 -0.02742
wandb:  final_test_rmse 0.24412
wandb:  final_train_mse 0.03285
wandb:   final_train_r2 -0.07007
wandb: final_train_rmse 0.18124
wandb:    final_val_mse 0.06496
wandb:     final_val_r2 -0.00118
wandb:   final_val_rmse 0.25486
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03648
wandb:       train_time 70.6336
wandb:         val_loss 0.06508
wandb:          val_mse 0.06496
wandb:           val_r2 -0.00118
wandb:         val_rmse 0.25486
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170951-mtteabzr
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_170951-mtteabzr/logs
Standard experiment completed successfully: layer_8_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_8/complexity/results.json
Running question_type experiment for language ar, layer 9
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:11:34,981][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_9/question_type
experiment_name: layer_9_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 9
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:11:34,981][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:11:34,981][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:11:34,981][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:11:35,032][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:11:35,032][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:11:36,845][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:11:39,994][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:11:39,995][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:11:40,074][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,126][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,303][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:11:40,314][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:11:40,315][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:11:40,316][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:11:40,352][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,404][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,426][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:11:40,427][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:11:40,427][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:11:40,428][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:11:40,465][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,509][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:11:40,550][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:11:40,552][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:11:40,552][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:11:40,553][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:11:40,553][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:11:40,554][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:11:40,554][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:11:40,554][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:11:40,554][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:11:40,554][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:11:40,554][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:11:40,555][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:11:40,555][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:11:40,555][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:11:40,555][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:11:40,555][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:11:40,555][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:11:40,555][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:11:40,556][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:11:40,556][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:11:40,557][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:11:40,557][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:11:40,557][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:11:40,557][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:11:40,557][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:11:40,558][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:11:40,558][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:11:45,957][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:11:45,958][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:11:45,959][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:11:45,959][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 9
[2025-04-29 17:11:45,959][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:52,  1.19it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.86it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.46it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.85it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.92it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.64it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.99it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.02it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.81it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.38it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.79it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.08it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.29it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.44it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.54it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.81it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.81it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.50it/s]
[2025-04-29 17:11:52,454][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6929
[2025-04-29 17:11:52,783][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6990, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  4.96it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.62it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.39it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 14.94it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:11:57,056][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6915
[2025-04-29 17:11:57,402][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6982, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.27it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 11.00it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.70it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.18it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:12:01,698][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6918
[2025-04-29 17:12:02,042][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6974, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:13,  4.70it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.32it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.16it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 14.79it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 15.80it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.44it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:01<00:02, 17.14it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:12:06,324][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6916
[2025-04-29 17:12:06,685][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6965, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:12,  4.83it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.47it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.27it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 14.87it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 15.84it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.46it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.87it/s]
[2025-04-29 17:12:10,961][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6896
[2025-04-29 17:12:11,311][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6959, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:12,  4.82it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.44it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.25it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 14.85it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.83it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.86it/s]
[2025-04-29 17:12:15,600][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6901
[2025-04-29 17:12:15,941][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6951, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  4.88it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.52it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.32it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 14.90it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.86it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.48it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.86it/s]
[2025-04-29 17:12:20,244][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6883
[2025-04-29 17:12:20,602][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6944, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:12,  5.16it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.85it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.98it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:12:24,894][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6878
[2025-04-29 17:12:25,250][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6937, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.74it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.47it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 14.99it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.67it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.67it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.65it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:12:29,568][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6859
[2025-04-29 17:12:29,931][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6935, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.25it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.11it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.74it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.40it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:12:34,239][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6864
[2025-04-29 17:12:34,611][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.80it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.99it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.89it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.83it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.08it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.52it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.63it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.63it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.63it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.63it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:12:38,947][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6862
[2025-04-29 17:12:39,318][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6921, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:13,  4.46it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:06,  9.98it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 12.87it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.55it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.59it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.27it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.72it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:01<00:02, 17.02it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.23it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.79it/s]
[2025-04-29 17:12:43,648][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6837
[2025-04-29 17:12:44,019][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6916, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:13,  4.69it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.28it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.09it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.71it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.72it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.36it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.78it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:01<00:02, 17.07it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.65it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.66it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:12:48,427][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6899
[2025-04-29 17:12:48,792][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6909, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:12,  4.80it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.39it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.17it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.75it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.74it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.35it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.76it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 17.04it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.20it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.33it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.43it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.50it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:12:53,107][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6855
[2025-04-29 17:12:53,476][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6902, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.12it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.78it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.47it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.96it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.87it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.44it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.07it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.24it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.35it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.45it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.65it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:12:57,806][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6840
[2025-04-29 17:12:58,167][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6896, Metrics: {'accuracy': 0.4772727272727273, 'f1': 0.6349206349206349}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁█████████
wandb:          best_val_f1 ▁▁▁▁▁▁█████████
wandb:        best_val_loss █▇▇▆▆▅▅▄▄▃▃▃▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss █▇▇▇▆▆▄▄▃▃▃▁▆▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁█████████
wandb:               val_f1 ▁▁▁▁▁▁█████████
wandb:             val_loss █▇▇▆▆▅▅▄▄▃▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.47727
wandb:          best_val_f1 0.63492
wandb:        best_val_loss 0.68958
wandb:                epoch 15
wandb:  final_test_accuracy 0.28571
wandb:        final_test_f1 0.44444
wandb: final_train_accuracy 0.49849
wandb:       final_train_f1 0.66533
wandb:   final_val_accuracy 0.47727
wandb:         final_val_f1 0.63492
wandb:        learning_rate 1e-05
wandb:           train_loss 0.68403
wandb:           train_time 70.63279
wandb:         val_accuracy 0.47727
wandb:               val_f1 0.63492
wandb:             val_loss 0.68958
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171135-fnpz85zz
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171135-fnpz85zz/logs
Standard experiment completed successfully: layer_9_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_9/question_type/results.json
Running complexity experiment for language ar, layer 9
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:13:20,029][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_9/complexity
experiment_name: layer_9_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 9
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:13:20,029][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:13:20,029][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:13:20,029][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:13:20,034][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:13:20,035][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:13:21,619][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:13:24,770][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:13:24,771][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:13:24,891][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:24,925][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:25,041][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:13:25,052][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:13:25,052][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:13:25,053][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:13:25,088][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:25,139][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:25,150][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:13:25,151][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:13:25,151][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:13:25,152][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:13:25,189][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:25,228][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:13:25,239][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:13:25,242][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:13:25,242][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:13:25,243][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:13:25,243][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:13:25,244][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:13:25,244][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:13:25,244][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:13:25,244][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:13:25,244][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:13:25,245][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:13:25,246][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:13:25,246][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:13:25,246][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:13:25,246][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:13:25,246][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:13:25,246][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:13:25,246][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:13:25,247][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:13:25,247][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:13:25,247][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:13:25,247][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:13:25,247][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:13:25,247][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:13:25,248][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:13:25,248][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:13:25,249][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:13:29,920][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:13:29,921][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:13:29,922][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:13:29,922][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 9
[2025-04-29 17:13:29,922][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:57,  1.08it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:16,  3.56it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.05it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.40it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.50it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.27it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.69it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.81it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.64it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.25it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.69it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.02it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.24it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.40it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.53it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.75it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.78it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.22it/s]
[2025-04-29 17:13:36,403][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1117
[2025-04-29 17:13:36,723][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.1044, Metrics: {'mse': 0.10539007931947708, 'rmse': 0.3246383823879688, 'r2': -0.6244117021560669}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  4.93it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.58it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.36it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 14.92it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 15.88it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.49it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.75it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.09it/s]
[2025-04-29 17:13:41,007][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.0856
[2025-04-29 17:13:41,330][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.0863, Metrics: {'mse': 0.08692708611488342, 'rmse': 0.2948339975560543, 'r2': -0.33983540534973145}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.26it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.98it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.06it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.63it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.73it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:13:45,665][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.0675
[2025-04-29 17:13:46,025][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.0748, Metrics: {'mse': 0.07516240328550339, 'rmse': 0.27415762489032364, 'r2': -0.15850257873535156}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.96it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.64it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.72it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:13:50,304][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0517
[2025-04-29 17:13:50,659][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0688, Metrics: {'mse': 0.06886434555053711, 'rmse': 0.26242016986225947, 'r2': -0.06142854690551758}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.20it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.90it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.59it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.10it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.97it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.39it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.52it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:13:54,938][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0437
[2025-04-29 17:13:55,290][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0661, Metrics: {'mse': 0.06601139158010483, 'rmse': 0.25692682144942525, 'r2': -0.017455101013183594}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:12,  5.13it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.82it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.07it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.58it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.96it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.72it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.72it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.74it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:13:59,575][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0390
[2025-04-29 17:13:59,932][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0657, Metrics: {'mse': 0.0654321014881134, 'rmse': 0.2557969927268759, 'r2': -0.008526206016540527}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  5.10it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.78it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.51it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.97it/s]
[2025-04-29 17:14:04,234][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0348
[2025-04-29 17:14:04,593][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0666, Metrics: {'mse': 0.06612488627433777, 'rmse': 0.25714759628341416, 'r2': -0.019204378128051758}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:13,  4.58it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.15it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.02it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.68it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.71it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.38it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:14:08,338][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0334
[2025-04-29 17:14:08,707][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0677, Metrics: {'mse': 0.06720500439405441, 'rmse': 0.2592392801912056, 'r2': -0.035852670669555664}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  4.94it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.58it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.36it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 14.93it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.90it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:14:12,437][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0322
[2025-04-29 17:14:12,807][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0691, Metrics: {'mse': 0.06850176304578781, 'rmse': 0.26172841467022223, 'r2': -0.05584001541137695}
[2025-04-29 17:14:12,808][src.training.lm_trainer][INFO] - Early stopping at epoch 9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▅▃▂▁▁
wandb:     best_val_mse █▅▃▂▁▁
wandb:      best_val_r2 ▁▄▆▇██
wandb:    best_val_rmse █▅▃▂▁▁
wandb:            epoch ▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▄▃▂▂▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▅▃▂▁▁▁▁▂
wandb:          val_mse █▅▃▂▁▁▁▁▂
wandb:           val_r2 ▁▄▆▇████▇
wandb:         val_rmse █▅▃▂▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.06572
wandb:     best_val_mse 0.06543
wandb:      best_val_r2 -0.00853
wandb:    best_val_rmse 0.2558
wandb:            epoch 9
wandb:   final_test_mse 0.06168
wandb:    final_test_r2 -0.06326
wandb:  final_test_rmse 0.24835
wandb:  final_train_mse 0.03081
wandb:   final_train_r2 -0.00362
wandb: final_train_rmse 0.17552
wandb:    final_val_mse 0.06543
wandb:     final_val_r2 -0.00853
wandb:   final_val_rmse 0.2558
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03225
wandb:       train_time 40.83735
wandb:         val_loss 0.06909
wandb:          val_mse 0.0685
wandb:           val_r2 -0.05584
wandb:         val_rmse 0.26173
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171320-m6m01c8o
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171320-m6m01c8o/logs
Standard experiment completed successfully: layer_9_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_9/complexity/results.json
Running question_type experiment for language ar, layer 10
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:14:35,116][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_10/question_type
experiment_name: layer_10_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 10
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:14:35,116][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:14:35,116][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:14:35,116][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:14:35,121][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:14:35,121][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:14:36,630][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:14:39,892][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:14:39,893][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:14:39,952][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:39,974][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:40,070][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:14:40,080][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:14:40,081][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:14:40,082][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:14:40,115][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:40,146][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:40,167][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:14:40,169][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:14:40,169][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:14:40,170][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:14:40,183][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:40,202][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:14:40,213][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:14:40,215][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:14:40,215][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:14:40,216][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:14:40,217][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:14:40,217][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:14:40,217][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:14:40,217][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:14:40,218][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:14:40,218][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:14:40,218][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:14:40,218][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:14:40,218][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:14:40,218][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:14:40,219][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:14:40,219][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:14:40,219][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:14:40,219][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:14:40,219][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:14:40,219][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:14:40,219][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:14:40,220][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:14:40,220][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:14:40,220][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:14:40,220][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:14:40,220][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:14:40,220][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:14:40,220][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:14:40,221][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:14:40,221][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:14:40,221][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:14:40,222][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:14:44,476][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:14:44,477][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:14:44,478][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:14:44,478][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 10
[2025-04-29 17:14:44,478][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:54,  1.14it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:16,  3.70it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.25it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.62it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.70it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.44it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.84it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.91it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.72it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.31it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.75it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.06it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.28it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.43it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.55it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.76it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.79it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.81it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.31it/s]
[2025-04-29 17:14:50,961][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6940
[2025-04-29 17:14:51,291][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6808, Metrics: {'accuracy': 0.5, 'f1': 0.6451612903225806}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:13,  4.73it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.36it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.20it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 14.82it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 15.83it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.70it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.75it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.82it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.04it/s]
[2025-04-29 17:14:55,566][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6861
[2025-04-29 17:14:55,914][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6694, Metrics: {'accuracy': 0.6590909090909091, 'f1': 0.7272727272727273}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:12,  4.88it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.54it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.35it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 14.94it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:15:00,234][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6751
[2025-04-29 17:15:00,593][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6566, Metrics: {'accuracy': 0.75, 'f1': 0.7843137254901961}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:12,  4.78it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.40it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.23it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 14.85it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 15.84it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:15:04,854][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6707
[2025-04-29 17:15:05,205][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6436, Metrics: {'accuracy': 0.7954545454545454, 'f1': 0.8163265306122449}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:12,  4.87it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.51it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.28it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 14.87it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 15.85it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:15:09,483][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6576
[2025-04-29 17:15:09,841][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6300, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:13,  4.69it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.29it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.12it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 14.73it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.73it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.37it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.79it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:01<00:02, 17.08it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.28it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:15:14,140][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6504
[2025-04-29 17:15:14,485][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6162, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  4.82it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.45it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.27it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 14.87it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.85it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.51it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:15:18,795][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6398
[2025-04-29 17:15:19,167][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6028, Metrics: {'accuracy': 0.8409090909090909, 'f1': 0.851063829787234}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:12,  4.82it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.45it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.26it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.86it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.84it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.46it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:15:23,446][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6290
[2025-04-29 17:15:23,813][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.5876, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  5.13it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.81it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.53it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.05it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.97it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.37it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:15:28,123][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6214
[2025-04-29 17:15:28,500][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.5743, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:13,  4.69it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.29it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.12it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.75it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.40it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.83it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:01<00:02, 17.12it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.74it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:15:32,818][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6105
[2025-04-29 17:15:33,187][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.5591, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  4.82it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.44it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.23it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.80it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.77it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.40it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.08it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.88it/s]
[2025-04-29 17:15:37,571][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.5950
[2025-04-29 17:15:37,932][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.5442, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.24it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.07it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.70it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.71it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.35it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.78it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:01<00:02, 17.07it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.37it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.45it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.60it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.67it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.67it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:15:42,278][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.5871
[2025-04-29 17:15:42,653][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.5297, Metrics: {'accuracy': 0.8863636363636364, 'f1': 0.8888888888888888}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:13,  4.61it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.17it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.02it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.66it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.67it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.32it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.75it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:01<00:02, 17.04it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.48it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.62it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.65it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.81it/s]
[2025-04-29 17:15:47,011][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.5772
[2025-04-29 17:15:47,375][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.5134, Metrics: {'accuracy': 0.8863636363636364, 'f1': 0.8888888888888888}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:12,  5.12it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.79it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 15.00it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.92it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.67it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.87it/s]
[2025-04-29 17:15:51,686][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.5679
[2025-04-29 17:15:52,031][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.4986, Metrics: {'accuracy': 0.8863636363636364, 'f1': 0.8888888888888888}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:13,  4.56it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.09it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 12.93it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.58it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.59it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.25it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.69it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:01<00:02, 16.98it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.19it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.33it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.42it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.49it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.60it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.61it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.62it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.63it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.77it/s]
[2025-04-29 17:15:56,395][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.5551
[2025-04-29 17:15:56,752][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.4851, Metrics: {'accuracy': 0.8863636363636364, 'f1': 0.8888888888888888}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▄▆▆▇▇▇████████
wandb:          best_val_f1 ▁▃▅▆▆▆▇▇▇▇▇████
wandb:        best_val_loss ██▇▇▆▆▅▅▄▄▃▃▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss ██▇▇▆▆▅▅▄▄▃▃▂▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▄▆▆▇▇▇████████
wandb:               val_f1 ▁▃▅▆▆▆▇▇▇▇▇████
wandb:             val_loss ██▇▇▆▆▅▅▄▄▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.88636
wandb:          best_val_f1 0.88889
wandb:        best_val_loss 0.4851
wandb:                epoch 15
wandb:  final_test_accuracy 0.50649
wandb:        final_test_f1 0.53659
wandb: final_train_accuracy 0.9809
wandb:       final_train_f1 0.98117
wandb:   final_val_accuracy 0.88636
wandb:         final_val_f1 0.88889
wandb:        learning_rate 1e-05
wandb:           train_loss 0.55511
wandb:           train_time 70.77492
wandb:         val_accuracy 0.88636
wandb:               val_f1 0.88889
wandb:             val_loss 0.4851
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171435-ma0zqt4d
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171435-ma0zqt4d/logs
Standard experiment completed successfully: layer_10_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_10/question_type/results.json
Running complexity experiment for language ar, layer 10
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:16:19,114][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_10/complexity
experiment_name: layer_10_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 10
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:16:19,115][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:16:19,115][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:16:19,115][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:16:19,120][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:16:19,120][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:16:20,735][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:16:23,917][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:16:23,918][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:16:24,021][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,064][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,210][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:16:24,222][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:16:24,223][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:16:24,224][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:16:24,269][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,322][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,363][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:16:24,365][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:16:24,365][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:16:24,366][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:16:24,411][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,461][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:16:24,483][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:16:24,485][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:16:24,485][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:16:24,486][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:16:24,487][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:16:24,487][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:16:24,487][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:16:24,487][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:16:24,487][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:16:24,488][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:16:24,488][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:16:24,488][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:16:24,488][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:16:24,488][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:16:24,488][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:16:24,489][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:16:24,489][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:16:24,489][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:16:24,489][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:16:24,489][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:16:24,489][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:16:24,490][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:16:24,490][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:16:24,490][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:16:24,490][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:16:24,490][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:16:24,490][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:16:24,491][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:16:24,491][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:16:24,491][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:16:24,491][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:16:24,492][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:16:29,533][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:16:29,534][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:16:29,535][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:16:29,535][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 10
[2025-04-29 17:16:29,535][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:53,  1.16it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.76it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  6.32it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.69it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.77it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.51it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.89it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.95it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.75it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.34it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.76it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.07it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.29it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.45it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.55it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.64it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.83it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.73it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.77it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.44it/s]
[2025-04-29 17:16:36,132][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.0932
[2025-04-29 17:16:36,448][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.0816, Metrics: {'mse': 0.08138282597064972, 'rmse': 0.2852767532951988, 'r2': -0.2543799877166748}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  5.10it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.79it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.53it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.00it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.61it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.26it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.43it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.83it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.01it/s]
[2025-04-29 17:16:40,730][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.0505
[2025-04-29 17:16:41,051][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.0769, Metrics: {'mse': 0.07596950232982635, 'rmse': 0.275625656153099, 'r2': -0.17094266414642334}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.19it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.88it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.57it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.08it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 15.99it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.20it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.81it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:16:45,386][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.0413
[2025-04-29 17:16:45,738][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.0794, Metrics: {'mse': 0.07842251658439636, 'rmse': 0.2800402052998754, 'r2': -0.20875179767608643}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.77it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.74it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.74it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.88it/s]
[2025-04-29 17:16:49,472][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0374
[2025-04-29 17:16:49,825][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0748, Metrics: {'mse': 0.07392113655805588, 'rmse': 0.2718844176448071, 'r2': -0.13937056064605713}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.23it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.92it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.60it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.10it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.00it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.72it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.73it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:16:54,106][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0354
[2025-04-29 17:16:54,443][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0707, Metrics: {'mse': 0.06987251341342926, 'rmse': 0.26433409430761906, 'r2': -0.07696783542633057}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:13,  4.64it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.23it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.09it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 14.73it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.39it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.90it/s]
[2025-04-29 17:16:58,733][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0330
[2025-04-29 17:16:59,088][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0707, Metrics: {'mse': 0.06994260102510452, 'rmse': 0.2644666349941038, 'r2': -0.07804811000823975}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:13,  4.63it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.22it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.07it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 14.72it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.73it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.39it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:01<00:02, 17.10it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:17:02,821][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0316
[2025-04-29 17:17:03,184][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0651, Metrics: {'mse': 0.06435731798410416, 'rmse': 0.25368744151830647, 'r2': 0.008039653301239014}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:13,  4.70it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.30it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.13it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.77it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.78it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.41it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:01<00:02, 17.12it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:17:07,500][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0306
[2025-04-29 17:17:07,869][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0661, Metrics: {'mse': 0.06542988866567612, 'rmse': 0.2557926673414938, 'r2': -0.008492231369018555}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:13,  4.56it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.13it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.01it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 14.67it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.70it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.36it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.80it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:01<00:02, 17.10it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.87it/s]
[2025-04-29 17:17:11,607][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0296
[2025-04-29 17:17:11,974][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0614, Metrics: {'mse': 0.06075427308678627, 'rmse': 0.2464838191175767, 'r2': 0.06357461214065552}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.25it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.10it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.74it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.39it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.66it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.66it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.67it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:17:16,304][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0309
[2025-04-29 17:17:16,654][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0591, Metrics: {'mse': 0.05849657207727432, 'rmse': 0.24186064598705248, 'r2': 0.09837329387664795}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:13,  4.76it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.32it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.13it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.73it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.70it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.33it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.75it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:01<00:02, 17.03it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.22it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.35it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.43it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.60it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.64it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.65it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.80it/s]
[2025-04-29 17:17:20,983][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0282
[2025-04-29 17:17:21,356][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0593, Metrics: {'mse': 0.05871030315756798, 'rmse': 0.24230209069995243, 'r2': 0.09507894515991211}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:13,  4.55it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.07it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 12.92it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.57it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.58it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.24it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.68it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:01<00:02, 16.98it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.18it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.32it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.42it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.49it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.65it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.66it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.79it/s]
[2025-04-29 17:17:25,111][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0291
[2025-04-29 17:17:25,482][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0571, Metrics: {'mse': 0.05645531043410301, 'rmse': 0.237603262675627, 'r2': 0.12983590364456177}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:13,  4.64it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.21it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.05it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.69it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.70it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.35it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.77it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:01<00:02, 17.05it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.38it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.74it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:17:29,857][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0275
[2025-04-29 17:17:30,223][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0583, Metrics: {'mse': 0.05770406499505043, 'rmse': 0.24021670423817415, 'r2': 0.1105884313583374}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:13,  4.53it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.07it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 12.94it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.59it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.64it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.30it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.74it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 17.03it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.24it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.38it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.48it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.75it/s]
[2025-04-29 17:17:33,986][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0288
[2025-04-29 17:17:34,355][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0554, Metrics: {'mse': 0.05476848781108856, 'rmse': 0.23402668183582948, 'r2': 0.15583544969558716}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.12it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.77it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 15.00it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.13it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.30it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:17:38,672][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0272
[2025-04-29 17:17:39,036][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0553, Metrics: {'mse': 0.054693982005119324, 'rmse': 0.23386744537262838, 'r2': 0.1569838523864746}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▇▆▅▄▃▂▁▁▁
wandb:     best_val_mse █▇▆▅▄▃▂▁▁▁
wandb:      best_val_r2 ▁▂▃▄▅▆▇███
wandb:    best_val_rmse █▇▆▅▄▃▂▂▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▇▇▆▅▅▄▄▃▂▂▁▂▁▁
wandb:          val_mse █▇▇▆▅▅▄▄▃▂▂▁▂▁▁
wandb:           val_r2 ▁▂▂▃▄▄▅▅▆▇▇█▇██
wandb:         val_rmse █▇▇▆▅▅▄▄▃▂▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.0553
wandb:     best_val_mse 0.05469
wandb:      best_val_r2 0.15698
wandb:    best_val_rmse 0.23387
wandb:            epoch 15
wandb:   final_test_mse 0.05565
wandb:    final_test_r2 0.04061
wandb:  final_test_rmse 0.2359
wandb:  final_train_mse 0.01998
wandb:   final_train_r2 0.34901
wandb: final_train_rmse 0.14136
wandb:    final_val_mse 0.05469
wandb:     final_val_r2 0.15698
wandb:   final_val_rmse 0.23387
wandb:    learning_rate 1e-05
wandb:       train_loss 0.0272
wandb:       train_time 67.88524
wandb:         val_loss 0.0553
wandb:          val_mse 0.05469
wandb:           val_r2 0.15698
wandb:         val_rmse 0.23387
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171619-83s3y80a
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171619-83s3y80a/logs
Standard experiment completed successfully: layer_10_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_10/complexity/results.json
Running question_type experiment for language ar, layer 11
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:18:04,341][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_11/question_type
experiment_name: layer_11_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 11
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:18:04,342][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:18:04,342][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:18:04,342][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:18:04,346][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:18:04,347][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:18:06,219][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:18:09,439][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:18:09,440][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:18:09,533][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,577][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,716][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:18:09,728][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:18:09,729][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:18:09,730][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:18:09,749][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,782][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,805][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:18:09,806][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:18:09,807][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:18:09,808][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:18:09,850][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,887][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:18:09,902][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:18:09,904][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:18:09,904][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:18:09,905][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:18:09,906][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:18:09,906][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:18:09,906][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:18:09,906][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:18:09,907][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:18:09,907][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:18:09,907][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:18:09,907][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:18:09,907][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:18:09,907][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:18:09,907][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:18:09,908][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:18:09,908][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:18:09,908][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:18:09,908][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:18:09,908][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:18:09,908][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:18:09,908][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:18:09,909][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:18:09,909][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:18:09,909][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:18:09,909][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:18:09,909][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:18:09,909][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:18:09,909][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:18:09,910][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:18:09,910][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:18:09,911][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:18:15,051][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:18:15,053][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:18:15,054][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:18:15,054][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 11
[2025-04-29 17:18:15,054][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:01<01:04,  1.03s/it]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:18,  3.23it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:10,  5.58it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:07,  7.87it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05,  9.97it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 11.79it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.29it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.47it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.39it/s]Epoch 1/15:  30%|███       | 19/63 [00:02<00:02, 16.06it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.57it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 16.93it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.13it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.31it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.47it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.56it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.64it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:03<00:01, 17.73it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.77it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.82it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.78it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 13.89it/s]
[2025-04-29 17:18:22,160][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6981
[2025-04-29 17:18:22,488][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6772, Metrics: {'accuracy': 0.75, 'f1': 0.7555555555555555}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  5.08it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.77it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.53it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.06it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.00it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.60it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.61it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.76it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.77it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.12it/s]
[2025-04-29 17:18:26,730][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6862
[2025-04-29 17:18:27,072][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6652, Metrics: {'accuracy': 0.7954545454545454, 'f1': 0.8085106382978723}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:13,  4.76it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.39it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.21it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 14.84it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 15.82it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:18:31,397][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6751
[2025-04-29 17:18:31,729][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6520, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.26it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.98it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.66it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.15it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 17.00it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.41it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.01it/s]
[2025-04-29 17:18:35,989][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6666
[2025-04-29 17:18:36,349][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6377, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.22it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.93it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.63it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.59it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:18:40,609][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6517
[2025-04-29 17:18:40,969][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6226, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.18it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.86it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.04it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.53it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:18:45,254][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6412
[2025-04-29 17:18:45,608][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6069, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.84it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.56it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.06it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:18:49,881][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6320
[2025-04-29 17:18:50,246][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.5909, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:12,  5.08it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.75it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 15.03it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.95it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:18:54,533][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6172
[2025-04-29 17:18:54,879][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.5730, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  5.14it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.81it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.52it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.03it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.15it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.57it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.95it/s]
[2025-04-29 17:18:59,179][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6073
[2025-04-29 17:18:59,547][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.5574, Metrics: {'accuracy': 0.8181818181818182, 'f1': 0.8333333333333334}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:12,  5.02it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.67it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.41it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.96it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.91it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:19:03,850][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.5940
[2025-04-29 17:19:04,213][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.5390, Metrics: {'accuracy': 0.8409090909090909, 'f1': 0.851063829787234}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  4.82it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.45it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.25it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.83it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.81it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.44it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.64it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:19:08,557][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.5731
[2025-04-29 17:19:08,920][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.5209, Metrics: {'accuracy': 0.8409090909090909, 'f1': 0.851063829787234}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:12,  4.95it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.58it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.34it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.88it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.83it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.43it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.83it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.10it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.28it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.52it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.56it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.60it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.66it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:19:13,239][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.5640
[2025-04-29 17:19:13,615][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.5036, Metrics: {'accuracy': 0.8409090909090909, 'f1': 0.851063829787234}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.08it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.73it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.45it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.97it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.87it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.46it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.12it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.66it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.67it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.67it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:19:17,997][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.5561
[2025-04-29 17:19:18,370][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.4869, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.23it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.05it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.68it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.68it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.32it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.75it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 17.04it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.22it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.36it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.68it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.71it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.78it/s]
[2025-04-29 17:19:22,718][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.5448
[2025-04-29 17:19:23,065][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.4727, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:12,  5.04it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.67it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.40it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.94it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.88it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:00<00:02, 17.11it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.68it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.66it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.67it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.68it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.68it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.99it/s]
[2025-04-29 17:19:27,386][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.5298
[2025-04-29 17:19:27,755][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.4600, Metrics: {'accuracy': 0.8636363636363636, 'f1': 0.8695652173913043}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▄▅▅▅▅▅▅▅▇▇▇███
wandb:          best_val_f1 ▁▄▆▆▆▆▆▆▆▇▇▇███
wandb:        best_val_loss ██▇▇▆▆▅▅▄▄▃▂▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss ██▇▇▆▆▅▅▄▄▃▂▂▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▄▅▅▅▅▅▅▅▇▇▇███
wandb:               val_f1 ▁▄▆▆▆▆▆▆▆▇▇▇███
wandb:             val_loss ██▇▇▆▆▅▅▄▄▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.86364
wandb:          best_val_f1 0.86957
wandb:        best_val_loss 0.45998
wandb:                epoch 15
wandb:  final_test_accuracy 0.48052
wandb:        final_test_f1 0.52381
wandb: final_train_accuracy 0.9799
wandb:       final_train_f1 0.98028
wandb:   final_val_accuracy 0.86364
wandb:         final_val_f1 0.86957
wandb:        learning_rate 1e-05
wandb:           train_loss 0.52978
wandb:           train_time 70.72229
wandb:         val_accuracy 0.86364
wandb:               val_f1 0.86957
wandb:             val_loss 0.45998
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171804-o1tr0r72
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171804-o1tr0r72/logs
Standard experiment completed successfully: layer_11_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_11/question_type/results.json
Running complexity experiment for language ar, layer 11
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:19:53,437][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_11/complexity
experiment_name: layer_11_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 11
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:19:53,437][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:19:53,437][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:19:53,437][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:19:53,442][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:19:53,443][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:19:55,497][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:19:58,713][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:19:58,714][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:19:58,844][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:58,880][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:59,026][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:19:59,037][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:19:59,037][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:19:59,038][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:19:59,055][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:59,113][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:59,137][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:19:59,138][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:19:59,138][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:19:59,139][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:19:59,168][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:59,209][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:19:59,221][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:19:59,222][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:19:59,223][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:19:59,224][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:19:59,224][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:19:59,224][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:19:59,224][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:19:59,225][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:19:59,225][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:19:59,225][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:19:59,225][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:19:59,225][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:19:59,226][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:19:59,226][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:19:59,226][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:19:59,226][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:19:59,226][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:19:59,227][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:19:59,227][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:19:59,228][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:19:59,228][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:19:59,228][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:19:59,228][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:19:59,228][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:19:59,228][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:19:59,229][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:19:59,229][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:20:04,308][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:20:04,309][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:20:04,311][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:20:04,311][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 11
[2025-04-29 17:20:04,311][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:52,  1.19it/s]Epoch 1/15:   5%|▍         | 3/63 [00:00<00:15,  3.85it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:08,  6.45it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.84it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:04, 10.91it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.63it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.98it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 15.03it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.81it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.39it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:01<00:02, 16.79it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.10it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.30it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.45it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.57it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.65it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.81it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.85it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.50it/s]
[2025-04-29 17:20:11,128][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1270
[2025-04-29 17:20:11,461][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.0979, Metrics: {'mse': 0.09875023365020752, 'rmse': 0.31424549901344256, 'r2': -0.5220695734024048}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.50it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.26it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.88it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.32it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.17it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.72it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.07it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.31it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.46it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.59it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.65it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.71it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.77it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.83it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.83it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.84it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.83it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.84it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.85it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.85it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.05it/s]
[2025-04-29 17:20:15,741][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.0625
[2025-04-29 17:20:16,085][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.0716, Metrics: {'mse': 0.07130995392799377, 'rmse': 0.2670392366825403, 'r2': -0.09912347793579102}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.19it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.90it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.63it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.13it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.04it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.42it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.54it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.72it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.74it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.82it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.81it/s]Epoch 3/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.82it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.03it/s]
[2025-04-29 17:20:20,404][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.0439
[2025-04-29 17:20:20,751][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.0735, Metrics: {'mse': 0.07299785315990448, 'rmse': 0.2701811487870767, 'r2': -0.12513971328735352}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:12,  5.06it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.75it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.03it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.75it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.80it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:20:24,461][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0396
[2025-04-29 17:20:24,809][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0717, Metrics: {'mse': 0.07121710479259491, 'rmse': 0.26686533081798935, 'r2': -0.09769237041473389}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.77it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.91it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.68it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.69it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.73it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.74it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.95it/s]
[2025-04-29 17:20:28,528][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0366
[2025-04-29 17:20:28,874][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0685, Metrics: {'mse': 0.06807946413755417, 'rmse': 0.26092041724931025, 'r2': -0.049330949783325195}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:11,  5.21it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.91it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.61it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 15.11it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 16.02it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.60it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.97it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.38it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.50it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.59it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.79it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 17.02it/s]
[2025-04-29 17:20:33,143][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0362
[2025-04-29 17:20:33,495][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0675, Metrics: {'mse': 0.06708312779664993, 'rmse': 0.25900410768296694, 'r2': -0.03397417068481445}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  4.81it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.43it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.25it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 14.85it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.84it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.46it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:20:37,798][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0339
[2025-04-29 17:20:38,163][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0634, Metrics: {'mse': 0.06298401951789856, 'rmse': 0.2509661720589023, 'r2': 0.029206812381744385}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:13,  4.75it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.36it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.19it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.80it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.80it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.44it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.33it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.78it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.86it/s]
[2025-04-29 17:20:42,461][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0323
[2025-04-29 17:20:42,808][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0635, Metrics: {'mse': 0.06308215856552124, 'rmse': 0.25116161841635204, 'r2': 0.02769416570663452}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  4.96it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.61it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.38it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 14.94it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.88it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.50it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.90it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.17it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.74it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.94it/s]
[2025-04-29 17:20:46,531][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0309
[2025-04-29 17:20:46,893][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0605, Metrics: {'mse': 0.06007671728730202, 'rmse': 0.24510552275969225, 'r2': 0.07401794195175171}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:12,  5.15it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.83it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.53it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 15.04it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.52it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.89it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.93it/s]
[2025-04-29 17:20:51,198][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0319
[2025-04-29 17:20:51,561][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0577, Metrics: {'mse': 0.05736187472939491, 'rmse': 0.23950339189538614, 'r2': 0.11586272716522217}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:13,  4.68it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.27it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.12it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.76it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.76it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.41it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.72it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:20:55,885][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0288
[2025-04-29 17:20:56,242][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0564, Metrics: {'mse': 0.05610055848956108, 'rmse': 0.23685556461599352, 'r2': 0.135303795337677}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:13,  4.60it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.16it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.00it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.64it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.66it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.31it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.75it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:01<00:02, 17.05it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.22it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.35it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.44it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.50it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.53it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.56it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.61it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.62it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.65it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.65it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.65it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.66it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.67it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.68it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.74it/s]
[2025-04-29 17:21:00,617][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0286
[2025-04-29 17:21:00,987][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0548, Metrics: {'mse': 0.05444889888167381, 'rmse': 0.23334287836073722, 'r2': 0.16076141595840454}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.09it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.75it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.47it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.99it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.90it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.48it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.12it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.50it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.89it/s]
[2025-04-29 17:21:05,306][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0280
[2025-04-29 17:21:05,657][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0553, Metrics: {'mse': 0.0549527145922184, 'rmse': 0.23441995348565872, 'r2': 0.15299594402313232}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:13,  4.51it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.02it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 12.89it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.55it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.56it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.22it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.67it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 16.97it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.18it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.31it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.41it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.48it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.53it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.57it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.61it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.65it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.66it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.73it/s]
[2025-04-29 17:21:09,426][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0270
[2025-04-29 17:21:09,795][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0523, Metrics: {'mse': 0.05202144756913185, 'rmse': 0.22808210707798157, 'r2': 0.19817644357681274}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:13,  4.68it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.26it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.10it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.71it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.71it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.35it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.77it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:01<00:02, 17.04it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.23it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.34it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.44it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.52it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.66it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.69it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.69it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:21:14,166][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0272
[2025-04-29 17:21:14,540][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0529, Metrics: {'mse': 0.05259442329406738, 'rmse': 0.22933474070464638, 'r2': 0.18934500217437744}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▄▃▃▃▂▂▂▁▁
wandb:     best_val_mse █▄▃▃▃▂▂▂▁▁
wandb:      best_val_r2 ▁▅▆▆▆▇▇▇██
wandb:    best_val_rmse █▄▄▄▃▂▂▂▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▄▄▄▃▃▃▃▂▂▂▁▁▁▁
wandb:          val_mse █▄▄▄▃▃▃▃▂▂▂▁▁▁▁
wandb:           val_r2 ▁▅▅▅▆▆▆▆▇▇▇████
wandb:         val_rmse █▄▄▄▄▄▃▃▂▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.05231
wandb:     best_val_mse 0.05202
wandb:      best_val_r2 0.19818
wandb:    best_val_rmse 0.22808
wandb:            epoch 15
wandb:   final_test_mse 0.05617
wandb:    final_test_r2 0.03167
wandb:  final_test_rmse 0.237
wandb:  final_train_mse 0.02017
wandb:   final_train_r2 0.34308
wandb: final_train_rmse 0.14201
wandb:    final_val_mse 0.05202
wandb:     final_val_r2 0.19818
wandb:   final_val_rmse 0.22808
wandb:    learning_rate 1e-05
wandb:       train_loss 0.02724
wandb:       train_time 67.76009
wandb:         val_loss 0.05291
wandb:          val_mse 0.05259
wandb:           val_r2 0.18935
wandb:         val_rmse 0.22933
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171953-zrjr9nio
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_171953-zrjr9nio/logs
Standard experiment completed successfully: layer_11_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_11/complexity/results.json
Running question_type experiment for language ar, layer 12
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:21:41,286][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_12/question_type
experiment_name: layer_12_question_type_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 12
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:21:41,287][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:21:41,287][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:21:41,287][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:21:41,291][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['ar']
[2025-04-29 17:21:41,292][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:21:43,988][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:21:47,153][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:21:47,154][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:21:47,325][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,393][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,573][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:21:47,586][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:21:47,587][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:21:47,587][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:21:47,679][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,711][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,724][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:21:47,725][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:21:47,725][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:21:47,728][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:21:47,798][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,844][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:21:47,869][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:21:47,871][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:21:47,871][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:21:47,872][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:21:47,873][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:21:47,873][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:21:47,873][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:21:47,874][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:21:47,874][src.data.datasets][INFO] -   Label 0: 498 examples (50.1%)
[2025-04-29 17:21:47,874][src.data.datasets][INFO] -   Label 1: 497 examples (49.9%)
[2025-04-29 17:21:47,874][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:21:47,874][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:21:47,875][src.data.datasets][INFO] -   Label 0: 24 examples (54.5%)
[2025-04-29 17:21:47,875][src.data.datasets][INFO] -   Label 1: 20 examples (45.5%)
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:21:47,875][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:21:47,876][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:21:47,876][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:21:47,876][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:21:47,876][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:21:47,876][src.data.datasets][INFO] -   Label 0: 55 examples (71.4%)
[2025-04-29 17:21:47,876][src.data.datasets][INFO] -   Label 1: 22 examples (28.6%)
[2025-04-29 17:21:47,877][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:21:47,877][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:21:47,877][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:21:47,877][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:21:47,878][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:21:47,878][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:21:54,347][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:21:54,348][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:21:54,349][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:21:54,349][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 12
[2025-04-29 17:21:54,349][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:58,  1.06it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:17,  3.48it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  5.94it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.27it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.37it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.15it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.58it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.72it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.56it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.20it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.67it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 17.00it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.23it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.41it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.53it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.62it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.76it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.78it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.79it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.80it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.83it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.81it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.80it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.18it/s]
[2025-04-29 17:22:01,421][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6974
[2025-04-29 17:22:01,749][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6996, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:11,  5.38it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 11.14it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.81it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 15.28it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 16.15it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.69it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 17.05it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.28it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.45it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.64it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.82it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.81it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.83it/s]Epoch 2/15:  81%|████████  | 51/63 [00:02<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.82it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.83it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.83it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.07it/s]
[2025-04-29 17:22:06,050][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6946
[2025-04-29 17:22:06,393][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6993, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.97it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.67it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.64it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 16.99it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.24it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.68it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.71it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.76it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.79it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.79it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:22:10,710][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6934
[2025-04-29 17:22:11,109][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6990, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:12,  5.06it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.74it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 15.96it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.56it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.21it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.49it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.58it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.64it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.74it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.76it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:22:15,376][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6945
[2025-04-29 17:22:15,738][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6987, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:13,  4.76it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.37it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.20it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 14.82it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 15.82it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.45it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.87it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.16it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.75it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.78it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:22:19,984][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6928
[2025-04-29 17:22:20,357][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6985, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:13,  4.72it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.32it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.16it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 14.78it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.76it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.41it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.85it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:01<00:02, 17.13it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.34it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.91it/s]
[2025-04-29 17:22:24,643][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6906
[2025-04-29 17:22:25,005][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6982, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  5.12it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.78it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.49it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.51it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.88it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.14it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.32it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.66it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.67it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.68it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.73it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:22:29,313][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6914
[2025-04-29 17:22:29,682][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6979, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:13,  4.63it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.21it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.05it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.69it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.70it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.34it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.77it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:01<00:02, 17.06it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.65it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.68it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.73it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:22:33,979][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6903
[2025-04-29 17:22:34,332][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6976, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:13,  4.63it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.19it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.03it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 14.66it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.68it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.33it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.76it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:01<00:02, 17.05it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.24it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.38it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.53it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.60it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.65it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.68it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.70it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:22:38,692][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6896
[2025-04-29 17:22:39,059][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6974, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:13,  4.69it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.29it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.12it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.75it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.40it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.83it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:01<00:02, 17.12it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.44it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.53it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.63it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.67it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.71it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.72it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.73it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:22:43,388][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6896
[2025-04-29 17:22:43,745][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6970, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:13,  4.49it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.03it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 12.91it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 14.60it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.65it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.32it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.77it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:01<00:02, 17.07it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.28it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.58it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.62it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.65it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.70it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.72it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.73it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.73it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.74it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.75it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.76it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.81it/s]
[2025-04-29 17:22:48,137][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6872
[2025-04-29 17:22:48,501][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6967, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:12,  4.87it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.48it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.26it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.83it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.80it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.41it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.82it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:00<00:02, 17.09it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.39it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.58it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.68it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.67it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.66it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.64it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.63it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.64it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.65it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:22:52,810][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6894
[2025-04-29 17:22:53,180][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6964, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:12,  5.07it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.72it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.44it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.95it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.88it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.47it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.86it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:00<00:02, 17.12it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.29it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.54it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.63it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.65it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.65it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.65it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.65it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.66it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:22:57,532][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6871
[2025-04-29 17:22:57,886][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6961, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:12,  5.04it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.67it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.40it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.91it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.84it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.42it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:00<00:02, 17.08it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.25it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.37it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.46it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.51it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.55it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.58it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.59it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.60it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.62it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.63it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.63it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.64it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.64it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.65it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.66it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.67it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.83it/s]
[2025-04-29 17:23:02,204][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6865
[2025-04-29 17:23:02,574][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6959, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:13,  4.68it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.24it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.07it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.70it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.69it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.33it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.76it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:01<00:02, 17.05it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.23it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.37it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.47it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.52it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.57it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.61it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.63it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.66it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.68it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.68it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.68it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.85it/s]
[2025-04-29 17:23:06,926][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6841
[2025-04-29 17:23:07,297][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6955, Metrics: {'accuracy': 0.45454545454545453, 'f1': 0.625}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss ██▇▇▆▆▅▅▄▄▃▃▂▂▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss █▇▆▆▆▄▅▄▄▄▃▄▃▂▁
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss ██▇▇▆▆▅▅▄▄▃▃▂▂▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.45455
wandb:          best_val_f1 0.625
wandb:        best_val_loss 0.69553
wandb:                epoch 15
wandb:  final_test_accuracy 0.28571
wandb:        final_test_f1 0.44444
wandb: final_train_accuracy 0.4995
wandb:       final_train_f1 0.66622
wandb:   final_val_accuracy 0.45455
wandb:         final_val_f1 0.625
wandb:        learning_rate 1e-05
wandb:           train_loss 0.68409
wandb:           train_time 70.8881
wandb:         val_accuracy 0.45455
wandb:               val_f1 0.625
wandb:             val_loss 0.69553
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172141-1hb1cmne
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172141-1hb1cmne/logs
Standard experiment completed successfully: layer_12_question_type_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_12/question_type/results.json
Running complexity experiment for language ar, layer 12
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:23:32,085][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_12/complexity
experiment_name: layer_12_complexity_ar
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - ar
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 12
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:23:32,085][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:23:32,085][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:23:32,085][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:23:32,090][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['ar']
[2025-04-29 17:23:32,090][__main__][INFO] - Processing language: ar
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:23:34,346][src.data.datasets][INFO] - Creating dataloaders for language: 'ar', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:23:37,549][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:23:37,550][src.data.datasets][INFO] - Loading 'base' dataset for ar language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:23:37,635][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:37,668][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:37,810][src.data.datasets][INFO] - Filtered from 7460 to 995 examples for language 'ar'
[2025-04-29 17:23:37,822][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:23:37,822][src.data.datasets][INFO] - Loaded 995 examples for ar (train)
[2025-04-29 17:23:37,824][src.data.datasets][INFO] - Loading 'base' dataset for ar language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:23:37,864][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:37,920][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:37,934][src.data.datasets][INFO] - Filtered from 441 to 44 examples for language 'ar'
[2025-04-29 17:23:37,935][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:23:37,936][src.data.datasets][INFO] - Loaded 44 examples for ar (validation)
[2025-04-29 17:23:37,937][src.data.datasets][INFO] - Loading 'base' dataset for ar language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:23:37,954][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:38,049][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:23:38,061][src.data.datasets][INFO] - Filtered from 719 to 77 examples for language 'ar'
[2025-04-29 17:23:38,063][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:23:38,063][src.data.datasets][INFO] - Loaded 77 examples for ar (test)
[2025-04-29 17:23:38,064][src.data.datasets][INFO] - Loaded datasets: train=995, val=44, test=77 examples
[2025-04-29 17:23:38,064][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:23:38,065][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:23:38,065][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:23:38,065][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:23:38,065][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:23:38,065][src.data.datasets][INFO] -   Mean: 0.4236, Std: 0.1752
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Sample text: هل النمر العربي معرض للانقراض؟...
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Sample label: 0.41602465510368347
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:23:38,066][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:23:38,067][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:23:38,067][src.data.datasets][INFO] -   Mean: 0.3847, Std: 0.2547
[2025-04-29 17:23:38,067][src.data.datasets][INFO] - Sample text: من هو مخترع الليزر ؟...
[2025-04-29 17:23:38,067][src.data.datasets][INFO] - Sample label: 0.09095905721187592
[2025-04-29 17:23:38,067][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:23:38,068][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:23:38,068][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:23:38,068][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:23:38,068][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:23:38,068][src.data.datasets][INFO] -   Mean: 0.4157, Std: 0.2408
[2025-04-29 17:23:38,068][src.data.datasets][INFO] - Sample text: قبل الإقدام على خطوات يعلن ـ هو نفسه ـ أنها تتناقض...
[2025-04-29 17:23:38,069][src.data.datasets][INFO] - Sample label: 0.5635213255882263
[2025-04-29 17:23:38,069][src.data.datasets][INFO] - Created datasets: train=995, val=44, test=77
[2025-04-29 17:23:38,069][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:23:38,069][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:23:38,070][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:23:43,359][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:23:43,360][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:23:43,361][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:23:43,362][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 12
[2025-04-29 17:23:43,362][__main__][INFO] - Successfully created model for ar
Epoch 1/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 1/15:   2%|▏         | 1/63 [00:00<00:58,  1.06it/s]Epoch 1/15:   5%|▍         | 3/63 [00:01<00:17,  3.50it/s]Epoch 1/15:   8%|▊         | 5/63 [00:01<00:09,  5.96it/s]Epoch 1/15:  11%|█         | 7/63 [00:01<00:06,  8.30it/s]Epoch 1/15:  14%|█▍        | 9/63 [00:01<00:05, 10.38it/s]Epoch 1/15:  17%|█▋        | 11/63 [00:01<00:04, 12.15it/s]Epoch 1/15:  21%|██        | 13/63 [00:01<00:03, 13.58it/s]Epoch 1/15:  24%|██▍       | 15/63 [00:01<00:03, 14.69it/s]Epoch 1/15:  27%|██▋       | 17/63 [00:01<00:02, 15.55it/s]Epoch 1/15:  30%|███       | 19/63 [00:01<00:02, 16.17it/s]Epoch 1/15:  33%|███▎      | 21/63 [00:02<00:02, 16.63it/s]Epoch 1/15:  37%|███▋      | 23/63 [00:02<00:02, 16.97it/s]Epoch 1/15:  40%|███▉      | 25/63 [00:02<00:02, 17.19it/s]Epoch 1/15:  43%|████▎     | 27/63 [00:02<00:02, 17.36it/s]Epoch 1/15:  46%|████▌     | 29/63 [00:02<00:01, 17.49it/s]Epoch 1/15:  49%|████▉     | 31/63 [00:02<00:01, 17.55it/s]Epoch 1/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.63it/s]Epoch 1/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 1/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 1/15:  62%|██████▏   | 39/63 [00:03<00:01, 17.70it/s]Epoch 1/15:  65%|██████▌   | 41/63 [00:03<00:01, 17.73it/s]Epoch 1/15:  68%|██████▊   | 43/63 [00:03<00:01, 17.74it/s]Epoch 1/15:  71%|███████▏  | 45/63 [00:03<00:01, 17.75it/s]Epoch 1/15:  75%|███████▍  | 47/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  78%|███████▊  | 49/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 1/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 1/15:  90%|█████████ | 57/63 [00:04<00:00, 17.72it/s]Epoch 1/15:  94%|█████████▎| 59/63 [00:04<00:00, 17.75it/s]Epoch 1/15:  97%|█████████▋| 61/63 [00:04<00:00, 17.78it/s]Epoch 1/15: 100%|██████████| 63/63 [00:04<00:00, 14.17it/s]
[2025-04-29 17:23:50,215][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1361
[2025-04-29 17:23:50,551][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.1329, Metrics: {'mse': 0.13420610129833221, 'rmse': 0.3663415091118289, 'r2': -1.0685622692108154}
Epoch 2/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 2/15:   2%|▏         | 1/63 [00:00<00:12,  4.97it/s]Epoch 2/15:   5%|▍         | 3/63 [00:00<00:05, 10.66it/s]Epoch 2/15:   8%|▊         | 5/63 [00:00<00:04, 13.42it/s]Epoch 2/15:  11%|█         | 7/63 [00:00<00:03, 14.98it/s]Epoch 2/15:  14%|█▍        | 9/63 [00:00<00:03, 15.93it/s]Epoch 2/15:  17%|█▋        | 11/63 [00:00<00:03, 16.55it/s]Epoch 2/15:  21%|██        | 13/63 [00:00<00:02, 16.95it/s]Epoch 2/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 2/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 2/15:  30%|███       | 19/63 [00:01<00:02, 17.53it/s]Epoch 2/15:  33%|███▎      | 21/63 [00:01<00:02, 17.62it/s]Epoch 2/15:  37%|███▋      | 23/63 [00:01<00:02, 17.67it/s]Epoch 2/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 2/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 2/15:  46%|████▌     | 29/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  49%|████▉     | 31/63 [00:01<00:01, 17.78it/s]Epoch 2/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.80it/s]Epoch 2/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.79it/s]Epoch 2/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.81it/s]Epoch 2/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.80it/s]Epoch 2/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.79it/s]Epoch 2/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 2/15:  81%|████████  | 51/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.80it/s]Epoch 2/15:  90%|█████████ | 57/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.82it/s]Epoch 2/15: 100%|██████████| 63/63 [00:03<00:00, 17.00it/s]
[2025-04-29 17:23:54,848][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.1152
[2025-04-29 17:23:55,187][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1259, Metrics: {'mse': 0.12717846035957336, 'rmse': 0.35662089164766186, 'r2': -0.9602431058883667}
Epoch 3/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 3/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 3/15:   5%|▍         | 3/63 [00:00<00:05, 10.97it/s]Epoch 3/15:   8%|▊         | 5/63 [00:00<00:04, 13.69it/s]Epoch 3/15:  11%|█         | 7/63 [00:00<00:03, 15.17it/s]Epoch 3/15:  14%|█▍        | 9/63 [00:00<00:03, 16.07it/s]Epoch 3/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 3/15:  21%|██        | 13/63 [00:00<00:02, 17.01it/s]Epoch 3/15:  24%|██▍       | 15/63 [00:00<00:02, 17.25it/s]Epoch 3/15:  27%|██▋       | 17/63 [00:01<00:02, 17.44it/s]Epoch 3/15:  30%|███       | 19/63 [00:01<00:02, 17.55it/s]Epoch 3/15:  33%|███▎      | 21/63 [00:01<00:02, 17.64it/s]Epoch 3/15:  37%|███▋      | 23/63 [00:01<00:02, 17.69it/s]Epoch 3/15:  40%|███▉      | 25/63 [00:01<00:02, 17.73it/s]Epoch 3/15:  43%|████▎     | 27/63 [00:01<00:02, 17.75it/s]Epoch 3/15:  46%|████▌     | 29/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  49%|████▉     | 31/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.77it/s]Epoch 3/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 3/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.80it/s]Epoch 3/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.81it/s]Epoch 3/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.81it/s]Epoch 3/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  81%|████████  | 51/63 [00:02<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 3/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 3/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 3/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 63/63 [00:03<00:00, 17.06it/s]
[2025-04-29 17:23:59,508][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.1084
[2025-04-29 17:23:59,867][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1198, Metrics: {'mse': 0.12096809595823288, 'rmse': 0.3478046807595218, 'r2': -0.8645206689834595}
Epoch 4/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 4/15:   2%|▏         | 1/63 [00:00<00:11,  5.27it/s]Epoch 4/15:   5%|▍         | 3/63 [00:00<00:05, 10.97it/s]Epoch 4/15:   8%|▊         | 5/63 [00:00<00:04, 13.65it/s]Epoch 4/15:  11%|█         | 7/63 [00:00<00:03, 15.12it/s]Epoch 4/15:  14%|█▍        | 9/63 [00:00<00:03, 16.01it/s]Epoch 4/15:  17%|█▋        | 11/63 [00:00<00:03, 16.57it/s]Epoch 4/15:  21%|██        | 13/63 [00:00<00:02, 16.94it/s]Epoch 4/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 4/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 4/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 4/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 4/15:  37%|███▋      | 23/63 [00:01<00:02, 17.60it/s]Epoch 4/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 4/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 4/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 4/15:  49%|████▉     | 31/63 [00:01<00:01, 17.71it/s]Epoch 4/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.72it/s]Epoch 4/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.73it/s]Epoch 4/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.72it/s]Epoch 4/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.69it/s]Epoch 4/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 4/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.72it/s]Epoch 4/15:  81%|████████  | 51/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.72it/s]Epoch 4/15:  90%|█████████ | 57/63 [00:03<00:00, 17.73it/s]Epoch 4/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.74it/s]Epoch 4/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 4/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:24:04,152][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1009
[2025-04-29 17:24:04,505][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1144, Metrics: {'mse': 0.11551687121391296, 'rmse': 0.3398777297998693, 'r2': -0.7804991006851196}
Epoch 5/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 5/15:   2%|▏         | 1/63 [00:00<00:11,  5.25it/s]Epoch 5/15:   5%|▍         | 3/63 [00:00<00:05, 10.96it/s]Epoch 5/15:   8%|▊         | 5/63 [00:00<00:04, 13.65it/s]Epoch 5/15:  11%|█         | 7/63 [00:00<00:03, 15.16it/s]Epoch 5/15:  14%|█▍        | 9/63 [00:00<00:03, 16.05it/s]Epoch 5/15:  17%|█▋        | 11/63 [00:00<00:03, 16.62it/s]Epoch 5/15:  21%|██        | 13/63 [00:00<00:02, 16.98it/s]Epoch 5/15:  24%|██▍       | 15/63 [00:00<00:02, 17.22it/s]Epoch 5/15:  27%|██▋       | 17/63 [00:01<00:02, 17.40it/s]Epoch 5/15:  30%|███       | 19/63 [00:01<00:02, 17.51it/s]Epoch 5/15:  33%|███▎      | 21/63 [00:01<00:02, 17.60it/s]Epoch 5/15:  37%|███▋      | 23/63 [00:01<00:02, 17.66it/s]Epoch 5/15:  40%|███▉      | 25/63 [00:01<00:02, 17.69it/s]Epoch 5/15:  43%|████▎     | 27/63 [00:01<00:02, 17.72it/s]Epoch 5/15:  46%|████▌     | 29/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 5/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.76it/s]Epoch 5/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.78it/s]Epoch 5/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 5/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 5/15:  81%|████████  | 51/63 [00:03<00:00, 17.74it/s]Epoch 5/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.74it/s]Epoch 5/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.73it/s]Epoch 5/15:  90%|█████████ | 57/63 [00:03<00:00, 17.73it/s]Epoch 5/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.75it/s]Epoch 5/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.75it/s]Epoch 5/15: 100%|██████████| 63/63 [00:03<00:00, 16.98it/s]
[2025-04-29 17:24:08,780][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0926
[2025-04-29 17:24:09,150][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.1097, Metrics: {'mse': 0.11074823886156082, 'rmse': 0.3327885798244297, 'r2': -0.7069987058639526}
Epoch 6/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 6/15:   2%|▏         | 1/63 [00:00<00:13,  4.65it/s]Epoch 6/15:   5%|▍         | 3/63 [00:00<00:05, 10.22it/s]Epoch 6/15:   8%|▊         | 5/63 [00:00<00:04, 13.07it/s]Epoch 6/15:  11%|█         | 7/63 [00:00<00:03, 14.70it/s]Epoch 6/15:  14%|█▍        | 9/63 [00:00<00:03, 15.72it/s]Epoch 6/15:  17%|█▋        | 11/63 [00:00<00:03, 16.37it/s]Epoch 6/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 6/15:  24%|██▍       | 15/63 [00:01<00:02, 17.10it/s]Epoch 6/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 6/15:  30%|███       | 19/63 [00:01<00:02, 17.46it/s]Epoch 6/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 6/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 6/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 6/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 6/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 6/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 6/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.74it/s]Epoch 6/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.76it/s]Epoch 6/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.78it/s]Epoch 6/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 6/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.78it/s]Epoch 6/15:  81%|████████  | 51/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.78it/s]Epoch 6/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.77it/s]Epoch 6/15:  90%|█████████ | 57/63 [00:03<00:00, 17.79it/s]Epoch 6/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.80it/s]Epoch 6/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.80it/s]Epoch 6/15: 100%|██████████| 63/63 [00:03<00:00, 16.80it/s]
[2025-04-29 17:24:13,491][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0899
[2025-04-29 17:24:13,854][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.1057, Metrics: {'mse': 0.10667861253023148, 'rmse': 0.3266169201530005, 'r2': -0.6442722082138062}
Epoch 7/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 7/15:   2%|▏         | 1/63 [00:00<00:12,  5.14it/s]Epoch 7/15:   5%|▍         | 3/63 [00:00<00:05, 10.83it/s]Epoch 7/15:   8%|▊         | 5/63 [00:00<00:04, 13.54it/s]Epoch 7/15:  11%|█         | 7/63 [00:00<00:03, 15.01it/s]Epoch 7/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 7/15:  17%|█▋        | 11/63 [00:00<00:03, 16.53it/s]Epoch 7/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 7/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 7/15:  27%|██▋       | 17/63 [00:01<00:02, 17.35it/s]Epoch 7/15:  30%|███       | 19/63 [00:01<00:02, 17.47it/s]Epoch 7/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 7/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 7/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 7/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 7/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 7/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 7/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 7/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.74it/s]Epoch 7/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 7/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.73it/s]Epoch 7/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.75it/s]Epoch 7/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 7/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 7/15: 100%|██████████| 63/63 [00:03<00:00, 16.95it/s]
[2025-04-29 17:24:18,172][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0872
[2025-04-29 17:24:18,522][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.1017, Metrics: {'mse': 0.10261418670415878, 'rmse': 0.320334491905194, 'r2': -0.5816259384155273}
Epoch 8/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 8/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 8/15:   5%|▍         | 3/63 [00:00<00:05, 10.23it/s]Epoch 8/15:   8%|▊         | 5/63 [00:00<00:04, 13.09it/s]Epoch 8/15:  11%|█         | 7/63 [00:00<00:03, 14.73it/s]Epoch 8/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 8/15:  17%|█▋        | 11/63 [00:00<00:03, 16.41it/s]Epoch 8/15:  21%|██        | 13/63 [00:00<00:02, 16.84it/s]Epoch 8/15:  24%|██▍       | 15/63 [00:01<00:02, 17.13it/s]Epoch 8/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 8/15:  30%|███       | 19/63 [00:01<00:02, 17.43it/s]Epoch 8/15:  33%|███▎      | 21/63 [00:01<00:02, 17.54it/s]Epoch 8/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 8/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 8/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 8/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 8/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 8/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.71it/s]Epoch 8/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 8/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 8/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 8/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 8/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:24:22,859][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0814
[2025-04-29 17:24:23,203][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0984, Metrics: {'mse': 0.09923500567674637, 'rmse': 0.31501588162622274, 'r2': -0.5295414924621582}
Epoch 9/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 9/15:   2%|▏         | 1/63 [00:00<00:12,  5.08it/s]Epoch 9/15:   5%|▍         | 3/63 [00:00<00:05, 10.76it/s]Epoch 9/15:   8%|▊         | 5/63 [00:00<00:04, 13.50it/s]Epoch 9/15:  11%|█         | 7/63 [00:00<00:03, 15.01it/s]Epoch 9/15:  14%|█▍        | 9/63 [00:00<00:03, 15.94it/s]Epoch 9/15:  17%|█▋        | 11/63 [00:00<00:03, 16.54it/s]Epoch 9/15:  21%|██        | 13/63 [00:00<00:02, 16.92it/s]Epoch 9/15:  24%|██▍       | 15/63 [00:00<00:02, 17.18it/s]Epoch 9/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 9/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 9/15:  33%|███▎      | 21/63 [00:01<00:02, 17.57it/s]Epoch 9/15:  37%|███▋      | 23/63 [00:01<00:02, 17.62it/s]Epoch 9/15:  40%|███▉      | 25/63 [00:01<00:02, 17.66it/s]Epoch 9/15:  43%|████▎     | 27/63 [00:01<00:02, 17.70it/s]Epoch 9/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 9/15:  49%|████▉     | 31/63 [00:01<00:01, 17.73it/s]Epoch 9/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.74it/s]Epoch 9/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 9/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 9/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.76it/s]Epoch 9/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 9/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.75it/s]Epoch 9/15:  90%|█████████ | 57/63 [00:03<00:00, 17.76it/s]Epoch 9/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 9/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 9/15: 100%|██████████| 63/63 [00:03<00:00, 16.96it/s]
[2025-04-29 17:24:27,542][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0782
[2025-04-29 17:24:27,910][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0954, Metrics: {'mse': 0.09624898433685303, 'rmse': 0.31024020425607807, 'r2': -0.4835169315338135}
Epoch 10/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 10/15:   2%|▏         | 1/63 [00:00<00:13,  4.66it/s]Epoch 10/15:   5%|▍         | 3/63 [00:00<00:05, 10.24it/s]Epoch 10/15:   8%|▊         | 5/63 [00:00<00:04, 13.10it/s]Epoch 10/15:  11%|█         | 7/63 [00:00<00:03, 14.74it/s]Epoch 10/15:  14%|█▍        | 9/63 [00:00<00:03, 15.75it/s]Epoch 10/15:  17%|█▋        | 11/63 [00:00<00:03, 16.40it/s]Epoch 10/15:  21%|██        | 13/63 [00:00<00:02, 16.81it/s]Epoch 10/15:  24%|██▍       | 15/63 [00:01<00:02, 17.11it/s]Epoch 10/15:  27%|██▋       | 17/63 [00:01<00:02, 17.31it/s]Epoch 10/15:  30%|███       | 19/63 [00:01<00:02, 17.45it/s]Epoch 10/15:  33%|███▎      | 21/63 [00:01<00:02, 17.55it/s]Epoch 10/15:  37%|███▋      | 23/63 [00:01<00:02, 17.61it/s]Epoch 10/15:  40%|███▉      | 25/63 [00:01<00:02, 17.65it/s]Epoch 10/15:  43%|████▎     | 27/63 [00:01<00:02, 17.69it/s]Epoch 10/15:  46%|████▌     | 29/63 [00:01<00:01, 17.71it/s]Epoch 10/15:  49%|████▉     | 31/63 [00:01<00:01, 17.72it/s]Epoch 10/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.73it/s]Epoch 10/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 10/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.76it/s]Epoch 10/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.76it/s]Epoch 10/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.77it/s]Epoch 10/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.77it/s]Epoch 10/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.77it/s]Epoch 10/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.77it/s]Epoch 10/15:  81%|████████  | 51/63 [00:03<00:00, 17.77it/s]Epoch 10/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 10/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 10/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 10/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 10/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.78it/s]Epoch 10/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:24:32,252][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0758
[2025-04-29 17:24:32,620][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0927, Metrics: {'mse': 0.09348754584789276, 'rmse': 0.30575733163391644, 'r2': -0.44095396995544434}
Epoch 11/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 11/15:   2%|▏         | 1/63 [00:00<00:12,  5.07it/s]Epoch 11/15:   5%|▍         | 3/63 [00:00<00:05, 10.75it/s]Epoch 11/15:   8%|▊         | 5/63 [00:00<00:04, 13.48it/s]Epoch 11/15:  11%|█         | 7/63 [00:00<00:03, 15.02it/s]Epoch 11/15:  14%|█▍        | 9/63 [00:00<00:03, 15.95it/s]Epoch 11/15:  17%|█▋        | 11/63 [00:00<00:03, 16.53it/s]Epoch 11/15:  21%|██        | 13/63 [00:00<00:02, 16.93it/s]Epoch 11/15:  24%|██▍       | 15/63 [00:00<00:02, 17.19it/s]Epoch 11/15:  27%|██▋       | 17/63 [00:01<00:02, 17.36it/s]Epoch 11/15:  30%|███       | 19/63 [00:01<00:02, 17.48it/s]Epoch 11/15:  33%|███▎      | 21/63 [00:01<00:02, 17.56it/s]Epoch 11/15:  37%|███▋      | 23/63 [00:01<00:02, 17.63it/s]Epoch 11/15:  40%|███▉      | 25/63 [00:01<00:02, 17.67it/s]Epoch 11/15:  43%|████▎     | 27/63 [00:01<00:02, 17.71it/s]Epoch 11/15:  46%|████▌     | 29/63 [00:01<00:01, 17.72it/s]Epoch 11/15:  49%|████▉     | 31/63 [00:01<00:01, 17.74it/s]Epoch 11/15:  52%|█████▏    | 33/63 [00:01<00:01, 17.75it/s]Epoch 11/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.74it/s]Epoch 11/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.75it/s]Epoch 11/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.75it/s]Epoch 11/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.76it/s]Epoch 11/15:  81%|████████  | 51/63 [00:03<00:00, 17.76it/s]Epoch 11/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.76it/s]Epoch 11/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.76it/s]Epoch 11/15:  90%|█████████ | 57/63 [00:03<00:00, 17.77it/s]Epoch 11/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.77it/s]Epoch 11/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.76it/s]Epoch 11/15: 100%|██████████| 63/63 [00:03<00:00, 16.92it/s]
[2025-04-29 17:24:36,965][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0713
[2025-04-29 17:24:37,344][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0904, Metrics: {'mse': 0.09107577800750732, 'rmse': 0.3017876372675119, 'r2': -0.4037806987762451}
Epoch 12/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 12/15:   2%|▏         | 1/63 [00:00<00:13,  4.58it/s]Epoch 12/15:   5%|▍         | 3/63 [00:00<00:05, 10.15it/s]Epoch 12/15:   8%|▊         | 5/63 [00:00<00:04, 13.02it/s]Epoch 12/15:  11%|█         | 7/63 [00:00<00:03, 14.68it/s]Epoch 12/15:  14%|█▍        | 9/63 [00:00<00:03, 15.71it/s]Epoch 12/15:  17%|█▋        | 11/63 [00:00<00:03, 16.36it/s]Epoch 12/15:  21%|██        | 13/63 [00:00<00:02, 16.80it/s]Epoch 12/15:  24%|██▍       | 15/63 [00:01<00:02, 17.10it/s]Epoch 12/15:  27%|██▋       | 17/63 [00:01<00:02, 17.28it/s]Epoch 12/15:  30%|███       | 19/63 [00:01<00:02, 17.42it/s]Epoch 12/15:  33%|███▎      | 21/63 [00:01<00:02, 17.52it/s]Epoch 12/15:  37%|███▋      | 23/63 [00:01<00:02, 17.59it/s]Epoch 12/15:  40%|███▉      | 25/63 [00:01<00:02, 17.64it/s]Epoch 12/15:  43%|████▎     | 27/63 [00:01<00:02, 17.68it/s]Epoch 12/15:  46%|████▌     | 29/63 [00:01<00:01, 17.69it/s]Epoch 12/15:  49%|████▉     | 31/63 [00:01<00:01, 17.70it/s]Epoch 12/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.71it/s]Epoch 12/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.71it/s]Epoch 12/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.71it/s]Epoch 12/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.71it/s]Epoch 12/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 12/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.71it/s]Epoch 12/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.71it/s]Epoch 12/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 12/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.69it/s]Epoch 12/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 12/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.73it/s]Epoch 12/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 63/63 [00:03<00:00, 16.84it/s]
[2025-04-29 17:24:41,709][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0709
[2025-04-29 17:24:42,071][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0882, Metrics: {'mse': 0.08886603266000748, 'rmse': 0.2981040634744979, 'r2': -0.3697211742401123}
Epoch 13/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 13/15:   2%|▏         | 1/63 [00:00<00:13,  4.67it/s]Epoch 13/15:   5%|▍         | 3/63 [00:00<00:05, 10.27it/s]Epoch 13/15:   8%|▊         | 5/63 [00:00<00:04, 13.10it/s]Epoch 13/15:  11%|█         | 7/63 [00:00<00:03, 14.72it/s]Epoch 13/15:  14%|█▍        | 9/63 [00:00<00:03, 15.73it/s]Epoch 13/15:  17%|█▋        | 11/63 [00:00<00:03, 16.37it/s]Epoch 13/15:  21%|██        | 13/63 [00:00<00:02, 16.79it/s]Epoch 13/15:  24%|██▍       | 15/63 [00:01<00:02, 17.08it/s]Epoch 13/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 13/15:  30%|███       | 19/63 [00:01<00:02, 17.40it/s]Epoch 13/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 13/15:  37%|███▋      | 23/63 [00:01<00:02, 17.56it/s]Epoch 13/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 13/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 13/15:  46%|████▌     | 29/63 [00:01<00:01, 17.66it/s]Epoch 13/15:  49%|████▉     | 31/63 [00:01<00:01, 17.63it/s]Epoch 13/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.64it/s]Epoch 13/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.66it/s]Epoch 13/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.68it/s]Epoch 13/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 13/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 13/15:  81%|████████  | 51/63 [00:03<00:00, 17.70it/s]Epoch 13/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 13/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 13/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 13/15: 100%|██████████| 63/63 [00:03<00:00, 16.76it/s]
[2025-04-29 17:24:46,452][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0662
[2025-04-29 17:24:46,805][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0858, Metrics: {'mse': 0.08647055923938751, 'rmse': 0.2940587683429751, 'r2': -0.33279895782470703}
Epoch 14/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 14/15:   2%|▏         | 1/63 [00:00<00:13,  4.67it/s]Epoch 14/15:   5%|▍         | 3/63 [00:00<00:05, 10.25it/s]Epoch 14/15:   8%|▊         | 5/63 [00:00<00:04, 13.09it/s]Epoch 14/15:  11%|█         | 7/63 [00:00<00:03, 14.72it/s]Epoch 14/15:  14%|█▍        | 9/63 [00:00<00:03, 15.72it/s]Epoch 14/15:  17%|█▋        | 11/63 [00:00<00:03, 16.36it/s]Epoch 14/15:  21%|██        | 13/63 [00:00<00:02, 16.79it/s]Epoch 14/15:  24%|██▍       | 15/63 [00:01<00:02, 17.07it/s]Epoch 14/15:  27%|██▋       | 17/63 [00:01<00:02, 17.27it/s]Epoch 14/15:  30%|███       | 19/63 [00:01<00:02, 17.41it/s]Epoch 14/15:  33%|███▎      | 21/63 [00:01<00:02, 17.49it/s]Epoch 14/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 14/15:  40%|███▉      | 25/63 [00:01<00:02, 17.60it/s]Epoch 14/15:  43%|████▎     | 27/63 [00:01<00:02, 17.63it/s]Epoch 14/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 14/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 14/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.67it/s]Epoch 14/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 14/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 14/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.70it/s]Epoch 14/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.70it/s]Epoch 14/15:  90%|█████████ | 57/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 63/63 [00:03<00:00, 16.82it/s]
[2025-04-29 17:24:51,170][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0645
[2025-04-29 17:24:51,547][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0837, Metrics: {'mse': 0.08423474431037903, 'rmse': 0.29023222479659117, 'r2': -0.29833757877349854}
Epoch 15/15:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 15/15:   2%|▏         | 1/63 [00:00<00:13,  4.64it/s]Epoch 15/15:   5%|▍         | 3/63 [00:00<00:05, 10.22it/s]Epoch 15/15:   8%|▊         | 5/63 [00:00<00:04, 13.05it/s]Epoch 15/15:  11%|█         | 7/63 [00:00<00:03, 14.69it/s]Epoch 15/15:  14%|█▍        | 9/63 [00:00<00:03, 15.69it/s]Epoch 15/15:  17%|█▋        | 11/63 [00:00<00:03, 16.35it/s]Epoch 15/15:  21%|██        | 13/63 [00:00<00:02, 16.77it/s]Epoch 15/15:  24%|██▍       | 15/63 [00:01<00:02, 17.07it/s]Epoch 15/15:  27%|██▋       | 17/63 [00:01<00:02, 17.26it/s]Epoch 15/15:  30%|███       | 19/63 [00:01<00:02, 17.38it/s]Epoch 15/15:  33%|███▎      | 21/63 [00:01<00:02, 17.48it/s]Epoch 15/15:  37%|███▋      | 23/63 [00:01<00:02, 17.55it/s]Epoch 15/15:  40%|███▉      | 25/63 [00:01<00:02, 17.59it/s]Epoch 15/15:  43%|████▎     | 27/63 [00:01<00:02, 17.62it/s]Epoch 15/15:  46%|████▌     | 29/63 [00:01<00:01, 17.64it/s]Epoch 15/15:  49%|████▉     | 31/63 [00:01<00:01, 17.67it/s]Epoch 15/15:  52%|█████▏    | 33/63 [00:02<00:01, 17.67it/s]Epoch 15/15:  56%|█████▌    | 35/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  59%|█████▊    | 37/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  62%|██████▏   | 39/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  65%|██████▌   | 41/63 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 43/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  71%|███████▏  | 45/63 [00:02<00:01, 17.70it/s]Epoch 15/15:  75%|███████▍  | 47/63 [00:02<00:00, 17.70it/s]Epoch 15/15:  78%|███████▊  | 49/63 [00:02<00:00, 17.71it/s]Epoch 15/15:  81%|████████  | 51/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  84%|████████▍ | 53/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  87%|████████▋ | 55/63 [00:03<00:00, 17.71it/s]Epoch 15/15:  90%|█████████ | 57/63 [00:03<00:00, 17.72it/s]Epoch 15/15:  94%|█████████▎| 59/63 [00:03<00:00, 17.72it/s]Epoch 15/15:  97%|█████████▋| 61/63 [00:03<00:00, 17.73it/s]Epoch 15/15: 100%|██████████| 63/63 [00:03<00:00, 16.86it/s]
[2025-04-29 17:24:55,919][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0603
[2025-04-29 17:24:56,294][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0818, Metrics: {'mse': 0.08238618820905685, 'rmse': 0.2870299430530844, 'r2': -0.26984524726867676}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▇▆▅▅▄▄▃▃▂▂▂▂▁▁
wandb:     best_val_mse █▇▆▅▅▄▄▃▃▂▂▂▂▁▁
wandb:      best_val_r2 ▁▂▃▄▄▅▅▆▆▇▇▇▇██
wandb:    best_val_rmse █▇▆▆▅▄▄▃▃▃▂▂▂▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▅▄▄▃▃▃▂▂▂▂▁▁
wandb:       train_time ▁
wandb:         val_loss █▇▆▅▅▄▄▃▃▂▂▂▂▁▁
wandb:          val_mse █▇▆▅▅▄▄▃▃▂▂▂▂▁▁
wandb:           val_r2 ▁▂▃▄▄▅▅▆▆▇▇▇▇██
wandb:         val_rmse █▇▆▆▅▄▄▃▃▃▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.08185
wandb:     best_val_mse 0.08239
wandb:      best_val_r2 -0.26985
wandb:    best_val_rmse 0.28703
wandb:            epoch 15
wandb:   final_test_mse 0.08584
wandb:    final_test_r2 -0.47984
wandb:  final_test_rmse 0.29298
wandb:  final_train_mse 0.05822
wandb:   final_train_r2 -0.89663
wandb: final_train_rmse 0.24129
wandb:    final_val_mse 0.08239
wandb:     final_val_r2 -0.26985
wandb:   final_val_rmse 0.28703
wandb:    learning_rate 1e-05
wandb:       train_loss 0.06031
wandb:       train_time 71.15096
wandb:         val_loss 0.08185
wandb:          val_mse 0.08239
wandb:           val_r2 -0.26985
wandb:         val_rmse 0.28703
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172332-gboayyx3
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172332-gboayyx3/logs
Standard experiment completed successfully: layer_12_complexity_ar
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/ar/layer_12/complexity/results.json
Running question_type experiment for language en, layer 1
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:25:23,424][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_1/question_type
experiment_name: layer_1_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 1
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:25:23,425][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:25:23,425][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:25:23,425][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:25:23,429][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:25:23,430][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:25:25,913][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:25:29,096][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:25:29,097][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:25:29,224][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,311][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,502][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:25:29,516][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:25:29,517][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:25:29,518][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:25:29,579][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,604][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,615][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:25:29,617][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:25:29,617][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:25:29,618][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:25:29,688][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,765][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:25:29,787][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:25:29,789][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:25:29,789][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:25:29,790][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:25:29,790][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:25:29,791][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:25:29,791][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:25:29,791][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:25:29,791][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:25:29,791][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:25:29,791][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:25:29,791][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:25:29,792][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:25:29,792][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:25:29,792][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:25:29,792][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:25:29,792][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:25:29,792][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:25:29,793][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:25:29,793][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:25:29,793][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:25:29,794][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:25:29,794][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:25:29,794][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:25:29,794][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:25:29,794][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:25:29,795][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:25:35,826][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:25:35,827][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:25:35,829][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:25:35,829][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 1
[2025-04-29 17:25:35,829][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:06,  1.12it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:19,  3.66it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.20it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.56it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.65it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.39it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.80it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.87it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.70it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.31it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.75it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.07it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.27it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.44it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.56it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.64it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.83it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.83it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.83it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.78it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.79it/s]
[2025-04-29 17:25:43,758][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6983
[2025-04-29 17:25:44,181][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6961, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:13,  5.47it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 11.19it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.82it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.28it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.12it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.67it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 17.00it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.25it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.40it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.82it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.09it/s]
[2025-04-29 17:25:49,158][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6939
[2025-04-29 17:25:49,602][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6947, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:15,  4.85it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.48it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.27it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.86it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.83it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.68it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.74it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.74it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.74it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.74it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.75it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:25:54,630][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6985
[2025-04-29 17:25:55,086][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6937, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.92it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.57it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.34it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.90it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.73it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:26:00,042][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6974
[2025-04-29 17:26:00,490][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6933, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:15,  4.70it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:07, 10.27it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.10it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.73it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.73it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.79it/s]Epoch 5/15:  20%|██        | 15/75 [00:01<00:03, 17.09it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.71it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.71it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.72it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:26:05,481][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6955
[2025-04-29 17:26:05,940][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:15,  4.81it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.44it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.26it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.85it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.84it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.98it/s]
[2025-04-29 17:26:10,908][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6950
[2025-04-29 17:26:11,371][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.74it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.36it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.18it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.78it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.12it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:26:16,366][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6927
[2025-04-29 17:26:16,828][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.07it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.73it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.45it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.98it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.90it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.49it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.88it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.61it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.67it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.70it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.71it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.73it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:26:21,807][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6925
[2025-04-29 17:26:22,278][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:15,  4.70it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.29it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.13it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.77it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.77it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.11it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.68it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.74it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.72it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:26:27,298][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6968
[2025-04-29 17:26:27,756][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:14,  5.05it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:06, 10.72it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.46it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 15.00it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.93it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.53it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 10/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.66it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.67it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:26:32,750][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6937
[2025-04-29 17:26:33,240][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:16,  4.58it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:07, 10.14it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 12.99it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.63it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.65it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:26:37,693][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6952
[2025-04-29 17:26:38,180][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:15,  4.64it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.19it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.02it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.68it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:26:42,603][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6938
[2025-04-29 17:26:43,055][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
[2025-04-29 17:26:43,055][src.training.lm_trainer][INFO] - Early stopping at epoch 12
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▅▃▂▁▁▁▁▁
wandb:                epoch ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ███████████▁
wandb:           train_loss █▃█▇▅▄▁▁▆▂▄▂
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▅▃▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.69287
wandb:                epoch 12
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69376
wandb:           train_time 64.37236
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69292
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172523-6leiu2tw
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172523-6leiu2tw/logs
Standard experiment completed successfully: layer_1_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_1/question_type/results.json
Running complexity experiment for language en, layer 1
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:27:12,276][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_1/complexity
experiment_name: layer_1_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 1
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:27:12,276][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:27:12,276][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:27:12,276][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:27:12,281][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:27:12,282][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:27:14,462][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:27:17,761][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:27:17,761][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:27:17,897][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:17,950][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:18,177][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:27:18,190][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:27:18,191][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:27:18,192][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:27:18,264][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:18,360][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:18,412][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:27:18,413][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:27:18,414][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:27:18,415][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:27:18,474][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:18,547][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:27:18,558][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:27:18,560][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:27:18,560][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:27:18,561][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:27:18,561][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:27:18,561][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:27:18,561][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:27:18,561][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:27:18,562][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:27:18,562][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:27:18,562][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:27:18,562][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:27:18,562][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:27:18,563][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:27:18,563][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:27:18,563][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:27:18,563][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:27:18,563][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:27:18,563][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:27:18,563][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:27:18,564][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:27:18,564][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:27:18,564][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:27:18,564][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:27:18,564][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:27:18,564][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:27:18,565][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:27:18,565][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:27:18,565][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:27:18,565][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:27:18,565][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:27:18,566][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:27:24,858][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:27:24,859][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:27:24,860][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:27:24,860][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 1
[2025-04-29 17:27:24,860][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:05,  1.14it/s]Epoch 1/15:   4%|▍         | 3/75 [00:00<00:19,  3.71it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.26it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.63it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.71it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.45it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.84it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.92it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.73it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.33it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.76it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.07it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.28it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.43it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.55it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.61it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.70it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.74it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.76it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.79it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.86it/s]
[2025-04-29 17:27:32,522][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3561
[2025-04-29 17:27:32,952][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2162, Metrics: {'mse': 0.22715070843696594, 'rmse': 0.47660330300677306, 'r2': -4.427577972412109}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:15,  4.74it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.23it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 14.85it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.49it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.39it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.65it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.77it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.79it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.81it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.82it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.82it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.82it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.81it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.82it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:27:37,959][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.2269
[2025-04-29 17:27:38,407][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1276, Metrics: {'mse': 0.135799378156662, 'rmse': 0.3685096717274351, 'r2': -2.244813919067383}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.17it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.89it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.61it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.03it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.60it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.98it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.24it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.55it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.63it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.76it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.77it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.78it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.79it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.80it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.80it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.80it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.81it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.81it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.80it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.81it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.82it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.09it/s]
[2025-04-29 17:27:43,420][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.1419
[2025-04-29 17:27:43,887][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.0785, Metrics: {'mse': 0.08444694429636002, 'rmse': 0.29059756416109206, 'r2': -1.0177898406982422}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.83it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.44it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.25it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.85it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.44it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:27:48,859][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0897
[2025-04-29 17:27:49,315][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0533, Metrics: {'mse': 0.05742672458291054, 'rmse': 0.23963873765088678, 'r2': -0.3721640110015869}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:16,  4.45it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:07,  9.99it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 12.89it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.59it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.34it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.79it/s]Epoch 5/15:  20%|██        | 15/75 [00:01<00:03, 17.09it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:27:54,314][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.0623
[2025-04-29 17:27:54,782][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0430, Metrics: {'mse': 0.045674968510866165, 'rmse': 0.2137170290614816, 'r2': -0.09136557579040527}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.23it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.93it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.63it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 16.02it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.59it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.97it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.22it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.39it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.65it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 17.05it/s]
[2025-04-29 17:27:59,745][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0498
[2025-04-29 17:28:00,212][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0406, Metrics: {'mse': 0.042252495884895325, 'rmse': 0.20555411911439606, 'r2': -0.009588360786437988}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.88it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.51it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.29it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.87it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.83it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.44it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.72it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:28:05,249][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0437
[2025-04-29 17:28:05,705][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0410, Metrics: {'mse': 0.04203932732343674, 'rmse': 0.2050349417134473, 'r2': -0.004494905471801758}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  4.96it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.62it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.39it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.90it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.89it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.73it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.73it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.96it/s]
[2025-04-29 17:28:10,129][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0413
[2025-04-29 17:28:10,589][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0425, Metrics: {'mse': 0.043020136654376984, 'rmse': 0.20741296163542186, 'r2': -0.027930498123168945}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  4.98it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.63it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.39it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.88it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.89it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.72it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.71it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 17.06it/s]
[2025-04-29 17:28:14,988][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0396
[2025-04-29 17:28:15,453][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0441, Metrics: {'mse': 0.04427270591259003, 'rmse': 0.2104108027468885, 'r2': -0.05785965919494629}
[2025-04-29 17:28:15,454][src.training.lm_trainer][INFO] - Early stopping at epoch 9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▄▃▂▁▁
wandb:     best_val_mse █▅▃▂▁▁
wandb:      best_val_r2 ▁▄▆▇██
wandb:    best_val_rmse █▅▃▂▁▁
wandb:            epoch ▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▅▃▂▂▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▄▃▂▁▁▁▁▁
wandb:          val_mse █▅▃▂▁▁▁▁▁
wandb:           val_r2 ▁▄▆▇█████
wandb:         val_rmse █▅▃▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.04056
wandb:     best_val_mse 0.04225
wandb:      best_val_r2 -0.00959
wandb:    best_val_rmse 0.20555
wandb:            epoch 9
wandb:   final_test_mse 0.04838
wandb:    final_test_r2 -0.25525
wandb:  final_test_rmse 0.21994
wandb:  final_train_mse 0.0351
wandb:   final_train_r2 -0.30833
wandb: final_train_rmse 0.18735
wandb:    final_val_mse 0.04225
wandb:     final_val_r2 -0.00959
wandb:   final_val_rmse 0.20555
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03955
wandb:       train_time 47.98276
wandb:         val_loss 0.04411
wandb:          val_mse 0.04427
wandb:           val_r2 -0.05786
wandb:         val_rmse 0.21041
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172712-okmx0hos
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172712-okmx0hos/logs
Standard experiment completed successfully: layer_1_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_1/complexity/results.json
Running question_type experiment for language en, layer 2
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:28:43,446][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_2/question_type
experiment_name: layer_2_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:28:43,446][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:28:43,446][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:28:43,446][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:28:43,450][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:28:43,451][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:28:46,013][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:28:49,375][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:28:49,375][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:28:49,525][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:49,556][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:49,708][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:28:49,719][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:28:49,720][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:28:49,721][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:28:49,820][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:49,890][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:49,933][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:28:49,935][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:28:49,936][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:28:49,946][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:28:50,026][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:50,059][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:28:50,094][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:28:50,097][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:28:50,097][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:28:50,099][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:28:50,099][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:28:50,099][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:28:50,100][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:28:50,100][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:28:50,100][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:28:50,100][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:28:50,100][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:28:50,100][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:28:50,101][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:28:50,101][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:28:50,101][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:28:50,102][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:28:50,102][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:28:50,102][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:28:50,102][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:28:50,102][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:28:50,102][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:28:50,102][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:28:50,103][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:28:50,103][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:28:50,103][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:28:50,103][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:28:50,103][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:28:56,679][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:28:56,680][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:28:56,681][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:28:56,681][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 17:28:56,681][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:13,  1.00it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:21,  3.34it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:12,  5.73it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  8.04it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.13it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 11.92it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.39it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.54it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.43it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:02<00:03, 16.09it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.56it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 16.91it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.16it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.34it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.46it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.56it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.61it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:03<00:02, 17.70it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.71it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.73it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.74it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.73it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.74it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.75it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:04<00:01, 17.73it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.73it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.73it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.75it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.75it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.74it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.75it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:05<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.49it/s]
[2025-04-29 17:29:04,620][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6986
[2025-04-29 17:29:05,076][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6959, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:14,  5.08it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.76it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.95it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.54it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.05it/s]
[2025-04-29 17:29:10,065][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6957
[2025-04-29 17:29:10,503][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6950, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.26it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.98it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.67it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.18it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.07it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.65it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 17.01it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.24it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.40it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.53it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.61it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.66it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.77it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.78it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.80it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.80it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.81it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.08it/s]
[2025-04-29 17:29:15,507][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6995
[2025-04-29 17:29:15,978][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6943, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.82it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.46it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.28it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.86it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.47it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.16it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.74it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.80it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.80it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.80it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:29:20,949][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6996
[2025-04-29 17:29:21,401][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6938, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.28it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.94it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.63it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 16.05it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.60it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.98it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.39it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.72it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.74it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.73it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.74it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.75it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 17.13it/s]
[2025-04-29 17:29:26,328][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6958
[2025-04-29 17:29:26,796][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6935, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:15,  4.63it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:07, 10.21it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.06it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.69it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.68it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 6/15:  20%|██        | 15/75 [00:01<00:03, 17.06it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.73it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.74it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.74it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:29:31,784][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6960
[2025-04-29 17:29:32,241][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6933, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.81it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.44it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.25it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.84it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.83it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:29:37,257][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6946
[2025-04-29 17:29:37,733][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6931, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.10it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.78it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 15.01it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.94it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.53it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:29:42,695][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6937
[2025-04-29 17:29:43,163][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  5.10it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.78it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.51it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.54it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.74it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:29:48,186][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6968
[2025-04-29 17:29:48,655][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:15,  4.80it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:06, 10.42it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.23it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.83it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.82it/s]Epoch 10/15:  20%|██        | 15/75 [00:00<00:03, 17.10it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.61it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.67it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:29:53,650][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6947
[2025-04-29 17:29:54,120][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.80it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.52it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.55it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 11/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:01<00:02, 17.72it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.66it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.66it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.66it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.67it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:29:59,133][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6954
[2025-04-29 17:29:59,605][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  5.03it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.65it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.37it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.89it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.79it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.06it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.43it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.50it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.56it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.60it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.62it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.62it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.64it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.64it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.63it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.64it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.61it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.60it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.61it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.60it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.61it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.62it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.63it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.61it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.61it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.62it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.64it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:30:04,623][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6936
[2025-04-29 17:30:05,088][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:07, 10.17it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.01it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.65it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.66it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.66it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.65it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.66it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.82it/s]
[2025-04-29 17:30:10,171][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6961
[2025-04-29 17:30:10,651][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:15,  4.64it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:07, 10.19it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.03it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.68it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.34it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:30:15,709][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6959
[2025-04-29 17:30:16,183][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:16,  4.57it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:07, 10.11it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 12.97it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.62it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.64it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 15/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.86it/s]
[2025-04-29 17:30:20,635][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6957
[2025-04-29 17:30:21,100][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▆▄▃▃▂▂▁▁▁▁▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate █████████████▁▁
wandb:           train_loss ▇▃██▄▄▂▁▅▂▃▁▄▄▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▆▄▃▃▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.6928
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69567
wandb:           train_time 81.65971
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69281
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172843-44gvvn8n
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_172843-44gvvn8n/logs
Standard experiment completed successfully: layer_2_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_2/question_type/results.json
Running complexity experiment for language en, layer 2
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:30:48,871][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_2/complexity
experiment_name: layer_2_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 2
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:30:48,872][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:30:48,872][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:30:48,872][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:30:48,877][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:30:48,877][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:30:51,129][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:30:54,342][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:30:54,343][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:30:54,498][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,542][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,695][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:30:54,709][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:30:54,710][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:30:54,721][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:30:54,789][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,822][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,833][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:30:54,835][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:30:54,835][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:30:54,836][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:30:54,880][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,910][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:30:54,921][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:30:54,923][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:30:54,923][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:30:54,924][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:30:54,925][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:30:54,925][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:30:54,925][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:30:54,925][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:30:54,925][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:30:54,926][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:30:54,926][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:30:54,926][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:30:54,926][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:30:54,926][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:30:54,926][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:30:54,927][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:30:54,927][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:30:54,927][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:30:54,927][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:30:54,927][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:30:54,927][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:30:54,928][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:30:54,928][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:30:54,928][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:30:54,928][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:30:54,928][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:30:54,928][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:30:54,928][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:30:54,929][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:30:54,929][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:30:54,929][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:30:54,929][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:31:00,841][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:31:00,843][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:31:00,844][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:31:00,844][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 2
[2025-04-29 17:31:00,844][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:06,  1.11it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:19,  3.63it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.14it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.50it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.59it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.34it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.75it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.84it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.67it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.28it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.72it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.05it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.26it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.43it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.54it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.60it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.76it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.80it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.77it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.73it/s]
[2025-04-29 17:31:08,241][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3838
[2025-04-29 17:31:08,663][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2507, Metrics: {'mse': 0.2625138461589813, 'rmse': 0.5123610505873581, 'r2': -5.2725510597229}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:13,  5.35it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 11.06it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.72it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.19it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.07it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.63it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.98it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.22it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.09it/s]
[2025-04-29 17:31:13,654][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3001
[2025-04-29 17:31:14,094][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1883, Metrics: {'mse': 0.19847719371318817, 'rmse': 0.4455077931003993, 'r2': -3.742448329925537}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.28it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 11.00it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.69it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.17it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.07it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.65it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 17.00it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.25it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.43it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.53it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.62it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.66it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.70it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.70it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:31:19,136][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2282
[2025-04-29 17:31:19,586][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1418, Metrics: {'mse': 0.1504846215248108, 'rmse': 0.38792347379967973, 'r2': -2.595705509185791}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.77it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.39it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.17it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.79it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 4/15:  20%|██        | 15/75 [00:01<00:03, 17.10it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.71it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.72it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.72it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.73it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:31:24,573][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1738
[2025-04-29 17:31:25,048][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1074, Metrics: {'mse': 0.11480246484279633, 'rmse': 0.33882512427917194, 'r2': -1.743109941482544}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:15,  4.75it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.20it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.82it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.70it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.71it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.71it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.72it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:31:30,037][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1352
[2025-04-29 17:31:30,496][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0826, Metrics: {'mse': 0.08879977464675903, 'rmse': 0.2979929103968063, 'r2': -1.1217970848083496}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.19it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.90it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.60it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.11it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 16.02it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.59it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.97it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.22it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.77it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 17.10it/s]
[2025-04-29 17:31:35,460][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1060
[2025-04-29 17:31:35,925][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0657, Metrics: {'mse': 0.07086125016212463, 'rmse': 0.26619776513360255, 'r2': -0.6931707859039307}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:14,  5.17it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.87it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.57it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 15.08it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.98it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.57it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.95it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.20it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.72it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.72it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.72it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.66it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 17.03it/s]
[2025-04-29 17:31:40,916][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0867
[2025-04-29 17:31:41,371][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0546, Metrics: {'mse': 0.058858130127191544, 'rmse': 0.24260694575216007, 'r2': -0.406366229057312}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.78it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.51it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.55it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.20it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.99it/s]
[2025-04-29 17:31:46,376][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0726
[2025-04-29 17:31:46,836][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0474, Metrics: {'mse': 0.05077771469950676, 'rmse': 0.22533911045246174, 'r2': -0.21329140663146973}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:15,  4.65it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:07, 10.24it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.08it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.70it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.72it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.81it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.10it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:31:51,877][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0609
[2025-04-29 17:31:52,332][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0432, Metrics: {'mse': 0.04585526883602142, 'rmse': 0.2141384338133195, 'r2': -0.09567368030548096}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:15,  4.67it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.26it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.10it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.74it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.75it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.11it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.68it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:31:57,337][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0524
[2025-04-29 17:31:57,783][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0411, Metrics: {'mse': 0.04318508878350258, 'rmse': 0.207810223000464, 'r2': -0.031871914863586426}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:14,  5.00it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.67it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.43it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.97it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.90it/s]Epoch 11/15:  20%|██        | 15/75 [00:00<00:03, 17.16it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.74it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.73it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:32:02,832][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0470
[2025-04-29 17:32:03,319][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0407, Metrics: {'mse': 0.04220927134156227, 'rmse': 0.2054489506947219, 'r2': -0.00855553150177002}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:15,  4.68it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.27it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.12it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.76it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.39it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.09it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.63it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.64it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.66it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.67it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:32:08,342][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0448
[2025-04-29 17:32:08,796][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0410, Metrics: {'mse': 0.04213747754693031, 'rmse': 0.20527415216468514, 'r2': -0.006840109825134277}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.81it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.41it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.20it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.79it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.77it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.81it/s]Epoch 13/15:  20%|██        | 15/75 [00:00<00:03, 17.09it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.27it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:32:13,235][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0423
[2025-04-29 17:32:13,701][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0417, Metrics: {'mse': 0.04255317896604538, 'rmse': 0.2062842188972423, 'r2': -0.016772985458374023}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:15,  4.85it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:06, 10.47it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.26it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.83it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.81it/s]Epoch 14/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.66it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.66it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:32:18,146][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0387
[2025-04-29 17:32:18,614][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0426, Metrics: {'mse': 0.04315941780805588, 'rmse': 0.20774844838904544, 'r2': -0.031258583068847656}
[2025-04-29 17:32:18,615][src.training.lm_trainer][INFO] - Early stopping at epoch 14
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▄▃▂▂▁▁▁▁▁
wandb:     best_val_mse █▆▄▃▂▂▂▁▁▁▁
wandb:      best_val_r2 ▁▃▅▆▇▇▇████
wandb:    best_val_rmse █▆▅▄▃▂▂▁▁▁▁
wandb:            epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▃▂▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▄▃▂▂▁▁▁▁▁▁▁▁
wandb:          val_mse █▆▄▃▂▂▂▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▅▆▇▇▇███████
wandb:         val_rmse █▆▅▄▃▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.04067
wandb:     best_val_mse 0.04221
wandb:      best_val_r2 -0.00856
wandb:    best_val_rmse 0.20545
wandb:            epoch 14
wandb:   final_test_mse 0.04725
wandb:    final_test_r2 -0.22604
wandb:  final_test_rmse 0.21737
wandb:  final_train_mse 0.03386
wandb:   final_train_r2 -0.262
wandb: final_train_rmse 0.184
wandb:    final_val_mse 0.04221
wandb:     final_val_r2 -0.00856
wandb:   final_val_rmse 0.20545
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03866
wandb:       train_time 75.46674
wandb:         val_loss 0.04261
wandb:          val_mse 0.04316
wandb:           val_r2 -0.03126
wandb:         val_rmse 0.20775
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173048-fgaua8r2
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173048-fgaua8r2/logs
Standard experiment completed successfully: layer_2_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_2/complexity/results.json
Running question_type experiment for language en, layer 3
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:32:46,936][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_3/question_type
experiment_name: layer_3_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 3
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:32:46,936][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:32:46,936][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:32:46,936][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:32:46,941][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:32:46,941][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:32:49,319][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:32:52,483][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:32:52,483][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:32:52,682][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:52,787][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:53,043][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:32:53,057][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:32:53,058][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:32:53,058][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:32:53,102][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:53,177][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:53,219][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:32:53,221][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:32:53,221][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:32:53,222][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:32:53,296][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:53,431][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:32:53,443][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:32:53,445][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:32:53,445][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:32:53,446][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:32:53,447][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:32:53,447][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:32:53,447][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:32:53,447][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:32:53,448][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:32:53,448][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:32:53,448][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:32:53,448][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:32:53,448][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:32:53,448][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:32:53,448][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:32:53,449][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:32:53,449][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:32:53,449][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:32:53,449][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:32:53,449][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:32:53,449][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:32:53,449][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:32:53,450][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:32:53,450][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:32:53,450][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:32:53,451][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:32:53,451][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:33:00,474][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:33:00,475][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:33:00,476][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:33:00,476][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 3
[2025-04-29 17:33:00,476][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:09,  1.07it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:20,  3.51it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  5.98it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  8.32it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.41it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.18it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.62it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.73it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.58it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.21it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.67it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.02it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.24it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.41it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.52it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.60it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.80it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.64it/s]
[2025-04-29 17:33:08,319][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6971
[2025-04-29 17:33:08,726][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6950, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:14,  5.22it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.92it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.63it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.11it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.01it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.57it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.95it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.06it/s]
[2025-04-29 17:33:13,695][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6948
[2025-04-29 17:33:14,125][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6944, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.22it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.93it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.64it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.03it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.61it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.98it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.52it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.60it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.66it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.77it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.01it/s]
[2025-04-29 17:33:19,157][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6986
[2025-04-29 17:33:19,613][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6938, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.91it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.55it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.32it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.88it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.84it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.96it/s]
[2025-04-29 17:33:24,586][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6990
[2025-04-29 17:33:25,034][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6935, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:15,  4.73it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.33it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.16it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.79it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 5/15:  20%|██        | 15/75 [00:01<00:03, 17.12it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.74it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:33:29,999][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6949
[2025-04-29 17:33:30,491][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6932, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.24it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.93it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.60it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.08it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.97it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.54it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.68it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.68it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 17.01it/s]
[2025-04-29 17:33:35,453][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6955
[2025-04-29 17:33:35,911][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6931, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.77it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.38it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.20it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.82it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.73it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.74it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.74it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.74it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.75it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:33:40,903][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6939
[2025-04-29 17:33:41,371][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.20it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.89it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.60it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 15.10it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 16.01it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.59it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.96it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.20it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:01<00:02, 17.71it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:33:46,334][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6933
[2025-04-29 17:33:46,796][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  5.09it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.75it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.48it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.93it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.91it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.73it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.74it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:33:51,810][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6964
[2025-04-29 17:33:52,286][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:14,  5.11it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:06, 10.79it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.95it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.91it/s]Epoch 10/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.73it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.63it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.64it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 17.04it/s]
[2025-04-29 17:33:57,252][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6944
[2025-04-29 17:33:57,716][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:15,  4.74it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.35it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.17it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.79it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 17.12it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.71it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.70it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.66it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.62it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.64it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.65it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:34:02,774][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6951
[2025-04-29 17:34:03,237][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  5.12it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.79it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.47it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.99it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.90it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.64it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.65it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.63it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.63it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.63it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.64it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:34:08,235][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6933
[2025-04-29 17:34:08,696][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.81it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.51it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 15.01it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 13/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.66it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.64it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.63it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.63it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.62it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.63it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.64it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.64it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.65it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:34:13,725][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6952
[2025-04-29 17:34:14,190][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:16,  4.62it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:07, 10.17it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.02it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.66it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.66it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.63it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:34:19,200][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6956
[2025-04-29 17:34:19,654][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:14,  4.95it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:06, 10.59it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 13.34it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.90it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.84it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 15/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:34:24,076][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6954
[2025-04-29 17:34:24,538][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▆▄▃▂▂▂▁▁▁▁▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate █████████████▁▁
wandb:           train_loss ▆▃██▃▄▂▁▅▂▃▁▃▄▄
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▆▄▃▂▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.69275
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69536
wandb:           train_time 81.34512
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69276
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173246-5maj5lpe
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173246-5maj5lpe/logs
Standard experiment completed successfully: layer_3_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_3/question_type/results.json
Running complexity experiment for language en, layer 3
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:34:51,662][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_3/complexity
experiment_name: layer_3_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 3
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:34:51,663][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:34:51,663][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:34:51,663][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:34:51,667][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:34:51,668][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:34:53,960][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:34:57,143][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:34:57,144][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:34:57,216][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,269][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,456][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:34:57,469][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:34:57,470][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:34:57,471][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:34:57,519][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,599][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,620][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:34:57,622][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:34:57,623][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:34:57,623][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:34:57,669][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,731][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:34:57,749][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:34:57,751][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:34:57,751][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:34:57,752][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:34:57,753][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:34:57,753][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:34:57,753][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:34:57,753][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:34:57,754][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:34:57,754][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:34:57,754][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:34:57,754][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:34:57,755][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:34:57,755][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:34:57,755][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:34:57,755][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:34:57,755][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:34:57,755][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:34:57,756][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:34:57,756][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:34:57,757][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:34:57,757][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:34:57,757][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:34:57,757][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:34:57,757][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:34:57,758][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:34:57,758][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:35:03,275][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:35:03,276][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:35:03,277][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:35:03,277][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 3
[2025-04-29 17:35:03,277][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:07,  1.09it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:20,  3.58it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.07it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  8.42it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.51it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.25it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.67it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.77it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.60it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.21it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.66it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 16.98it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.20it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.37it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.48it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.56it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.72it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.73it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.75it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.74it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.74it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.75it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.72it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.74it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.75it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.75it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.76it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.65it/s]
[2025-04-29 17:35:10,842][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3524
[2025-04-29 17:35:11,264][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2301, Metrics: {'mse': 0.24151656031608582, 'rmse': 0.49144334395338574, 'r2': -4.770838260650635}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:15,  4.91it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.58it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.37it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.21it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.39it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.60it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.66it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.73it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.76it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.79it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.77it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.01it/s]
[2025-04-29 17:35:16,268][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.2756
[2025-04-29 17:35:16,715][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1745, Metrics: {'mse': 0.1843254268169403, 'rmse': 0.429331371806138, 'r2': -3.404303550720215}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.17it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.88it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.61it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.04it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.62it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 17.00it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.25it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.52it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.61it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.65it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.70it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.76it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.76it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.74it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.74it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.71it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.74it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.04it/s]
[2025-04-29 17:35:21,757][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2114
[2025-04-29 17:35:22,202][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1331, Metrics: {'mse': 0.14151239395141602, 'rmse': 0.376181331210649, 'r2': -2.381321430206299}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.90it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.55it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.33it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.87it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.49it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.89it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.98it/s]
[2025-04-29 17:35:27,189][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1617
[2025-04-29 17:35:27,644][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1011, Metrics: {'mse': 0.10824346542358398, 'rmse': 0.3290037468230172, 'r2': -1.586388111114502}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.20it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.90it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.59it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.10it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 16.00it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.58it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.95it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.21it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.76it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.74it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.74it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:35:32,633][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1257
[2025-04-29 17:35:33,107][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0783, Metrics: {'mse': 0.08423476666212082, 'rmse': 0.2902322633032393, 'r2': -1.0127201080322266}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.15it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.85it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.56it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.07it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.98it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.56it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.95it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.20it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.76it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:35:38,084][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0988
[2025-04-29 17:35:38,550][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0634, Metrics: {'mse': 0.06829831749200821, 'rmse': 0.2613394679186598, 'r2': -0.6319317817687988}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:14,  5.15it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.83it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.54it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.97it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.55it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.96it/s]
[2025-04-29 17:35:43,565][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0816
[2025-04-29 17:35:44,024][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0536, Metrics: {'mse': 0.05768398568034172, 'rmse': 0.2401749064335026, 'r2': -0.37831103801727295}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.10it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.77it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.55it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.67it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 17.11it/s]
[2025-04-29 17:35:48,988][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0692
[2025-04-29 17:35:49,447][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0473, Metrics: {'mse': 0.05059344321489334, 'rmse': 0.22492986287928365, 'r2': -0.20888841152191162}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  5.01it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.66it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.40it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.96it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.90it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.89it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.16it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.99it/s]
[2025-04-29 17:35:54,485][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0586
[2025-04-29 17:35:54,941][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0436, Metrics: {'mse': 0.046253502368927, 'rmse': 0.21506627436426895, 'r2': -0.10518920421600342}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:15,  4.63it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.20it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.03it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.34it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.77it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.06it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.71it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.73it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.73it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.75it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.74it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:35:59,973][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0514
[2025-04-29 17:36:00,463][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0419, Metrics: {'mse': 0.04395902156829834, 'rmse': 0.2096640683767687, 'r2': -0.05036437511444092}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:23,  3.14it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:08,  8.04it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:06, 11.18it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:05, 13.26it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 14.66it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:04, 15.60it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.26it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 16.71it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.03it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.24it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.40it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.51it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:02<00:02, 17.65it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.66it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.67it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.67it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.67it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.68it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.47it/s]
[2025-04-29 17:36:05,642][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0468
[2025-04-29 17:36:06,118][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0414, Metrics: {'mse': 0.04300921410322189, 'rmse': 0.20738662951892992, 'r2': -0.027669548988342285}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  5.10it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.72it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.43it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.94it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.81it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.06it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.44it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.50it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.55it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.60it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.63it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.67it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.66it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:36:11,141][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0449
[2025-04-29 17:36:11,611][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0416, Metrics: {'mse': 0.042815931141376495, 'rmse': 0.20692010811271216, 'r2': -0.02305126190185547}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.81it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.40it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.18it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.76it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.73it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.35it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.44it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.56it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.60it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.61it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.62it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.62it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.62it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.62it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.64it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:36:16,069][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0426
[2025-04-29 17:36:16,549][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0421, Metrics: {'mse': 0.04305630177259445, 'rmse': 0.20750012475320215, 'r2': -0.02879476547241211}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:16,  4.53it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:07, 10.07it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 12.94it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.61it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.64it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:36:20,999][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0388
[2025-04-29 17:36:21,473][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0429, Metrics: {'mse': 0.04351633042097092, 'rmse': 0.20860568166032994, 'r2': -0.039786696434020996}
[2025-04-29 17:36:21,474][src.training.lm_trainer][INFO] - Early stopping at epoch 14
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▄▃▂▂▁▁▁▁▁
wandb:     best_val_mse █▆▄▃▂▂▂▁▁▁▁
wandb:      best_val_r2 ▁▃▅▆▇▇▇████
wandb:    best_val_rmse █▆▅▄▃▂▂▁▁▁▁
wandb:            epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▃▂▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▄▃▂▂▁▁▁▁▁▁▁▁
wandb:          val_mse █▆▄▃▂▂▂▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▅▆▇▇▇███████
wandb:         val_rmse █▆▅▄▃▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.04141
wandb:     best_val_mse 0.04301
wandb:      best_val_r2 -0.02767
wandb:    best_val_rmse 0.20739
wandb:            epoch 14
wandb:   final_test_mse 0.04832
wandb:    final_test_r2 -0.25374
wandb:  final_test_rmse 0.21981
wandb:  final_train_mse 0.03445
wandb:   final_train_r2 -0.28391
wandb: final_train_rmse 0.1856
wandb:    final_val_mse 0.04301
wandb:     final_val_r2 -0.02767
wandb:   final_val_rmse 0.20739
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03878
wandb:       train_time 75.75267
wandb:         val_loss 0.04285
wandb:          val_mse 0.04352
wandb:           val_r2 -0.03979
wandb:         val_rmse 0.20861
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173451-q8ygd3ur
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173451-q8ygd3ur/logs
Standard experiment completed successfully: layer_3_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_3/complexity/results.json
Running question_type experiment for language en, layer 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:36:53,068][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_4/question_type
experiment_name: layer_4_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 4
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:36:53,068][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:36:53,069][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:36:53,069][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:36:53,073][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:36:53,074][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:36:55,434][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:36:58,627][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:36:58,627][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:36:58,809][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:58,856][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:59,050][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:36:59,064][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:36:59,065][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:36:59,066][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:36:59,156][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:59,179][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:59,192][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:36:59,194][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:36:59,194][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:36:59,195][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:36:59,285][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:59,381][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:36:59,413][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:36:59,415][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:36:59,415][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:36:59,416][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:36:59,416][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:36:59,417][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:36:59,417][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:36:59,417][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:36:59,417][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:36:59,417][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:36:59,417][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:36:59,418][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:36:59,418][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:36:59,418][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:36:59,418][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:36:59,418][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:36:59,418][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:36:59,419][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:36:59,419][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:36:59,420][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:36:59,420][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:36:59,420][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:36:59,420][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:36:59,420][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:36:59,420][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:36:59,421][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:36:59,421][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:37:05,665][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:37:05,666][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:37:05,667][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:37:05,667][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 4
[2025-04-29 17:37:05,667][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:07,  1.10it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:19,  3.62it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.13it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  8.50it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.58it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.34it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.74it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.84it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.66it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.27it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.73it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.05it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.24it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.41it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.53it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.62it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.77it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.84it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.85it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.67it/s]
[2025-04-29 17:37:13,510][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6990
[2025-04-29 17:37:13,934][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6961, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:12,  5.73it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 11.46it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:04, 14.04it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.41it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.24it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.76it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 17.11it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.33it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.49it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.59it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.66it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.78it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.78it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.78it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.78it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.82it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.82it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:02<00:01, 17.83it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.81it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.81it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.83it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.17it/s]
[2025-04-29 17:37:18,866][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6958
[2025-04-29 17:37:19,300][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6951, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:16,  4.60it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:07, 10.19it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.06it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.72it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.75it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.42it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 3/15:  20%|██        | 15/75 [00:01<00:03, 17.13it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.79it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.80it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 16.96it/s]
[2025-04-29 17:37:24,334][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.7001
[2025-04-29 17:37:24,782][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6944, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:14,  4.93it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.60it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.38it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.88it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.91it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.37it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:37:29,741][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.7001
[2025-04-29 17:37:30,191][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6939, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.27it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.97it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.65it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.14it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 16.03it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.59it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.96it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.22it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.39it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.65it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 17.03it/s]
[2025-04-29 17:37:35,133][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6959
[2025-04-29 17:37:35,591][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6935, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.16it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.83it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.54it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.03it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.94it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.90it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.72it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.73it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.74it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.75it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 17.05it/s]
[2025-04-29 17:37:40,549][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6958
[2025-04-29 17:37:41,013][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6933, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:07, 10.18it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.03it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.68it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.70it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.34it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.08it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.63it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.64it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.63it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.66it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.66it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.67it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.67it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.66it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.65it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.66it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:37:46,050][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6950
[2025-04-29 17:37:46,525][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6931, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.13it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.82it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.53it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 15.05it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.53it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.90it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.51it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.56it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.59it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.64it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.64it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.64it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.64it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.64it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.66it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.65it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.65it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.66it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.89it/s]
[2025-04-29 17:37:51,531][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6935
[2025-04-29 17:37:52,076][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:16,  4.62it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:07, 10.18it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.02it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.66it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.33it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.63it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.66it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.66it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.67it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:37:57,124][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6970
[2025-04-29 17:37:57,561][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:14,  5.10it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:06, 10.78it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.49it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 15.00it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.90it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.49it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 10/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.67it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.67it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:38:02,560][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6943
[2025-04-29 17:38:03,022][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:14,  5.12it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.79it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 15.01it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 11/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.67it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.98it/s]
[2025-04-29 17:38:08,046][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6955
[2025-04-29 17:38:08,534][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  5.16it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.82it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.51it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 15.01it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.89it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.47it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.09it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.42it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.50it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.56it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:38:13,527][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6934
[2025-04-29 17:38:13,985][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.77it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.35it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.15it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.74it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.72it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.34it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.03it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.34it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.44it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.50it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.58it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.63it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.64it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.66it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:38:19,041][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6954
[2025-04-29 17:38:19,511][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:14,  5.13it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:06, 10.81it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.51it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.88it/s]Epoch 14/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:38:24,515][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6959
[2025-04-29 17:38:24,977][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:15,  4.70it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:07, 10.26it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 13.08it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.70it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.69it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.73it/s]Epoch 15/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.34it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.42it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.63it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.63it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.67it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:38:30,034][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6955
[2025-04-29 17:38:30,474][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▆▄▃▃▂▂▁▁▁▁▁▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss ▇▃██▄▄▃▁▅▂▃▁▃▄▃
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▆▄▃▃▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.69271
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69553
wandb:           train_time 82.07884
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69271
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173653-w17fgrb9
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173653-w17fgrb9/logs
Standard experiment completed successfully: layer_4_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_4/question_type/results.json
Running complexity experiment for language en, layer 4
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:38:56,596][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_4/complexity
experiment_name: layer_4_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 4
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:38:56,597][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:38:56,597][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:38:56,597][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:38:56,602][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:38:56,602][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:38:58,696][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:39:01,979][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:39:01,980][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:39:02,105][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,138][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,304][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:39:02,316][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:39:02,316][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:39:02,317][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:39:02,354][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,408][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,419][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:39:02,421][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:39:02,421][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:39:02,422][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:39:02,448][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,513][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:39:02,535][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:39:02,537][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:39:02,537][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:39:02,538][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:39:02,539][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:39:02,539][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:39:02,539][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:39:02,540][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:39:02,540][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:39:02,540][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:39:02,540][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:39:02,540][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:39:02,541][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:39:02,541][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:39:02,541][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:39:02,541][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:39:02,541][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:39:02,541][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:39:02,542][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:39:02,542][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:39:02,543][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:39:02,543][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:39:02,543][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:39:02,543][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:39:02,543][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:39:02,544][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:39:02,544][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:39:08,052][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:39:08,053][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:39:08,054][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:39:08,054][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 4
[2025-04-29 17:39:08,054][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:02,  1.18it/s]Epoch 1/15:   4%|▍         | 3/75 [00:00<00:18,  3.83it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:10,  6.42it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.81it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.88it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.60it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.95it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:03, 15.00it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.80it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.36it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:01<00:03, 16.77it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.09it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.28it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.44it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.54it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.63it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.84it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.90it/s]
[2025-04-29 17:39:15,224][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3910
[2025-04-29 17:39:15,679][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2553, Metrics: {'mse': 0.2672761380672455, 'rmse': 0.5169875608438229, 'r2': -5.3863420486450195}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:15,  4.85it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.48it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.30it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 14.86it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.84it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.88it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.16it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:39:20,682][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.3040
[2025-04-29 17:39:21,122][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1919, Metrics: {'mse': 0.20222191512584686, 'rmse': 0.4496909106551375, 'r2': -3.8319249153137207}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.17it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.87it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.58it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.10it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.01it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.57it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.96it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.65it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.76it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.79it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.03it/s]
[2025-04-29 17:39:26,153][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2310
[2025-04-29 17:39:26,616][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1449, Metrics: {'mse': 0.1537647694349289, 'rmse': 0.3921285113772383, 'r2': -2.674081802368164}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:14,  5.23it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.95it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.63it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 15.13it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 16.03it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.61it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.97it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.40it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.51it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.07it/s]
[2025-04-29 17:39:31,579][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1748
[2025-04-29 17:39:32,035][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1086, Metrics: {'mse': 0.11604086309671402, 'rmse': 0.34064771112795406, 'r2': -1.772700309753418}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.20it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.88it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.57it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.07it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.97it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.56it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.93it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.73it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.73it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.74it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:39:37,012][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1340
[2025-04-29 17:39:37,451][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0823, Metrics: {'mse': 0.08848052471876144, 'rmse': 0.29745676109102215, 'r2': -1.1141688823699951}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.23it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.92it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.61it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.09it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.99it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.57it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.95it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.20it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.72it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.71it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.71it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.71it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.67it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.68it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.69it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:39:42,439][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1047
[2025-04-29 17:39:42,911][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0650, Metrics: {'mse': 0.07001107931137085, 'rmse': 0.2645960682084502, 'r2': -0.6728568077087402}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.78it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.19it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.80it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.44it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 7/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.67it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.71it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.71it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:39:47,932][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0850
[2025-04-29 17:39:48,411][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0540, Metrics: {'mse': 0.05810151621699333, 'rmse': 0.2410425610073734, 'r2': -0.3882875442504883}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  5.12it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.77it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.48it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.96it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.89it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.10it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.45it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.52it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.55it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.58it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.61it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.64it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.66it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.63it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.65it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.66it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.90it/s]
[2025-04-29 17:39:53,417][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0721
[2025-04-29 17:39:53,885][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0470, Metrics: {'mse': 0.05031418055295944, 'rmse': 0.2243082266724951, 'r2': -0.20221567153930664}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.81it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.91it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:39:58,911][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0607
[2025-04-29 17:39:59,368][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0432, Metrics: {'mse': 0.045816171914339066, 'rmse': 0.21404712545217483, 'r2': -0.09473955631256104}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:15,  4.69it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.28it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.11it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.72it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.72it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.77it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.05it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:40:04,389][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0529
[2025-04-29 17:40:04,848][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0415, Metrics: {'mse': 0.0435192734003067, 'rmse': 0.2086127354700731, 'r2': -0.03985702991485596}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:15,  4.65it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:07, 10.20it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.02it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.65it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.65it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.72it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 17.00it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.19it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.33it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.41it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.47it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.52it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.54it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.56it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.59it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.61it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.61it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.66it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.67it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.83it/s]
[2025-04-29 17:40:09,926][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0485
[2025-04-29 17:40:10,393][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0410, Metrics: {'mse': 0.04261079058051109, 'rmse': 0.20642381301708165, 'r2': -0.018149614334106445}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:16,  4.49it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.01it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 12.89it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.56it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.60it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.27it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.71it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.00it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.20it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.34it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.43it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.61it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.64it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.86it/s]
[2025-04-29 17:40:15,430][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0464
[2025-04-29 17:40:15,891][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0413, Metrics: {'mse': 0.04245821759104729, 'rmse': 0.2060539191353741, 'r2': -0.014503955841064453}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.92it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.55it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.32it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.88it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.83it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.43it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 13/15:  20%|██        | 15/75 [00:00<00:03, 17.10it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.64it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.64it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.67it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:40:20,336][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0447
[2025-04-29 17:40:20,781][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0418, Metrics: {'mse': 0.04273277893662453, 'rmse': 0.2067190821782656, 'r2': -0.021064400672912598}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:15,  4.81it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:06, 10.43it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.22it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.81it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.77it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.79it/s]Epoch 14/15:  20%|██        | 15/75 [00:00<00:03, 17.07it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:40:25,215][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0413
[2025-04-29 17:40:25,670][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0425, Metrics: {'mse': 0.043140728026628494, 'rmse': 0.20770346175889437, 'r2': -0.03081202507019043}
[2025-04-29 17:40:25,671][src.training.lm_trainer][INFO] - Early stopping at epoch 14
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▄▃▂▂▁▁▁▁▁
wandb:     best_val_mse █▆▄▃▂▂▁▁▁▁▁
wandb:      best_val_r2 ▁▃▅▆▇▇█████
wandb:    best_val_rmse █▆▅▄▃▂▂▁▁▁▁
wandb:            epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▃▂▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▄▃▂▂▁▁▁▁▁▁▁▁
wandb:          val_mse █▆▄▃▂▂▁▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▅▆▇▇████████
wandb:         val_rmse █▆▅▄▃▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.04105
wandb:     best_val_mse 0.04261
wandb:      best_val_r2 -0.01815
wandb:    best_val_rmse 0.20642
wandb:            epoch 14
wandb:   final_test_mse 0.04781
wandb:    final_test_r2 -0.24046
wandb:  final_test_rmse 0.21865
wandb:  final_train_mse 0.03416
wandb:   final_train_r2 -0.27344
wandb: final_train_rmse 0.18484
wandb:    final_val_mse 0.04261
wandb:     final_val_r2 -0.01815
wandb:   final_val_rmse 0.20642
wandb:    learning_rate 1e-05
wandb:       train_loss 0.0413
wandb:       train_time 75.48372
wandb:         val_loss 0.04249
wandb:          val_mse 0.04314
wandb:           val_r2 -0.03081
wandb:         val_rmse 0.2077
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173856-7pu51p37
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_173856-7pu51p37/logs
Standard experiment completed successfully: layer_4_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_4/complexity/results.json
Running question_type experiment for language en, layer 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:40:50,304][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_5/question_type
experiment_name: layer_5_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 5
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:40:50,304][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:40:50,304][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:40:50,304][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:40:50,309][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:40:50,309][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:40:52,078][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:40:55,355][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:40:55,355][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:40:55,420][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,450][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,564][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:40:55,575][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:40:55,576][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:40:55,577][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:40:55,612][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,632][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,642][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:40:55,644][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:40:55,644][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:40:55,645][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:40:55,657][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,687][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:40:55,698][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:40:55,700][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:40:55,700][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:40:55,701][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:40:55,701][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:40:55,702][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:40:55,702][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:40:55,702][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:40:55,702][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:40:55,702][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:40:55,702][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:40:55,703][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:40:55,703][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:40:55,703][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:40:55,703][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:40:55,703][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:40:55,703][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:40:55,703][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:40:55,704][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:40:55,704][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:40:55,705][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:40:55,705][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:40:55,705][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:40:55,705][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:40:55,705][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:40:55,705][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:40:55,706][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:40:59,996][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:40:59,997][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:40:59,998][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:40:59,998][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 5
[2025-04-29 17:40:59,998][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:08,  1.08it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:20,  3.56it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.04it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  8.38it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.48it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.24it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.66it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.77it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.62it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.24it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.70it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.02it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.25it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.42it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.53it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.62it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.82it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.67it/s]
[2025-04-29 17:41:07,244][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6969
[2025-04-29 17:41:07,673][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6949, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:14,  5.09it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.76it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.49it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.54it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.92it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.04it/s]
[2025-04-29 17:41:12,648][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6943
[2025-04-29 17:41:13,087][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6942, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:16,  4.57it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:07, 10.14it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.00it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.69it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.79it/s]Epoch 3/15:  20%|██        | 15/75 [00:01<00:03, 17.07it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.27it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.70it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.71it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.71it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.72it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.72it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.71it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.71it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:41:18,316][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6983
[2025-04-29 17:41:18,790][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6937, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.76it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.38it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.20it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.82it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.44it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.73it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.73it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.73it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.72it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.72it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.72it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.74it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:41:23,770][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6985
[2025-04-29 17:41:24,224][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6934, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.05it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.71it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.45it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.00it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.91it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.91it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.36it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.99it/s]
[2025-04-29 17:41:29,273][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6951
[2025-04-29 17:41:29,733][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6931, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:15,  4.64it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:07, 10.23it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.08it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.74it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.76it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 6/15:  20%|██        | 15/75 [00:01<00:03, 17.10it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:41:34,713][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6952
[2025-04-29 17:41:35,191][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:07, 10.19it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.04it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.68it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.69it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.05it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.66it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:41:40,207][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6938
[2025-04-29 17:41:40,647][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:07, 10.15it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.01it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.66it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.33it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 8/15:  20%|██        | 15/75 [00:01<00:03, 17.06it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.44it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.52it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.86it/s]
[2025-04-29 17:41:45,662][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6930
[2025-04-29 17:41:46,126][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:07, 10.16it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.01it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.68it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.33it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.05it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:41:51,178][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6964
[2025-04-29 17:41:51,651][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:16,  4.59it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.15it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.00it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.65it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.64it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.64it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.64it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.64it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.66it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.67it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.82it/s]
[2025-04-29 17:41:56,667][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6943
[2025-04-29 17:41:57,152][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:14,  5.05it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.71it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.44it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.87it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 11/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.61it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:42:02,191][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6946
[2025-04-29 17:42:02,677][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:16,  4.62it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.19it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.03it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.67it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.33it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.65it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.86it/s]
[2025-04-29 17:42:07,695][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6937
[2025-04-29 17:42:08,177][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:14,  5.03it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.68it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.41it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.87it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.47it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 13/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.62it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 17.04it/s]
[2025-04-29 17:42:13,171][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6951
[2025-04-29 17:42:13,656][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:16,  4.59it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:07, 10.14it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.00it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.65it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 17.03it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.66it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.66it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:42:18,682][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6954
[2025-04-29 17:42:19,163][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:16,  4.55it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:07, 10.09it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 12.95it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.62it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.65it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 15/15:  20%|██        | 15/75 [00:01<00:03, 17.03it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.71it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:42:23,617][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6952
[2025-04-29 17:42:24,104][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6927, Metrics: {'accuracy': 0.5, 'f1': 0.0}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▆▄▃▂▂▂▁▁▁▁▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate █████████████▁▁
wandb:           train_loss ▆▃██▄▄▂▁▅▃▃▂▄▄▄
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▆▄▃▂▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.6927
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69522
wandb:           train_time 81.97568
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69272
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174050-rz78wm31
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174050-rz78wm31/logs
Standard experiment completed successfully: layer_5_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_5/question_type/results.json
Running complexity experiment for language en, layer 5
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:42:45,468][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_5/complexity
experiment_name: layer_5_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 5
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:42:45,469][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:42:45,469][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:42:45,469][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:42:45,474][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:42:45,474][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:42:47,277][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:42:50,431][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:42:50,432][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:42:50,485][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,508][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,590][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:42:50,604][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:42:50,605][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:42:50,606][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:42:50,631][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,662][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,674][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:42:50,676][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:42:50,676][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:42:50,677][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:42:50,703][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,726][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:42:50,736][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:42:50,738][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:42:50,738][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:42:50,739][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:42:50,740][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:42:50,740][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:42:50,740][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:42:50,740][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:42:50,741][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:42:50,741][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:42:50,741][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:42:50,741][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:42:50,742][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:42:50,742][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:42:50,742][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:42:50,742][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:42:50,742][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:42:50,742][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:42:50,742][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:42:50,743][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:42:50,743][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:42:50,743][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:42:50,743][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:42:50,743][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:42:50,743][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:42:50,743][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:42:50,744][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:42:50,744][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:42:50,744][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:42:50,744][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:42:50,744][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:42:50,745][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:42:55,254][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:42:55,255][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:42:55,256][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:42:55,256][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 5
[2025-04-29 17:42:55,256][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:01<01:14,  1.01s/it]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:21,  3.29it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:12,  5.66it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:08,  7.96it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.06it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 11.87it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.36it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.53it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.43it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:02<00:03, 16.11it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.60it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 16.95it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.20it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.37it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.51it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.59it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:03<00:02, 17.73it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.76it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:04<00:01, 17.81it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.77it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:05<00:00, 17.83it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.42it/s]
[2025-04-29 17:43:02,430][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3422
[2025-04-29 17:43:02,852][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2192, Metrics: {'mse': 0.23028472065925598, 'rmse': 0.47987990232896394, 'r2': -4.502462863922119}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:14,  5.02it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.68it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.43it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 14.98it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.91it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.90it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.17it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.71it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.73it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.73it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.73it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.73it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.75it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.02it/s]
[2025-04-29 17:43:07,854][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.2611
[2025-04-29 17:43:08,297][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1604, Metrics: {'mse': 0.16970907151699066, 'rmse': 0.4119576088834756, 'r2': -3.055058002471924}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:16,  4.47it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:07, 10.02it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 12.91it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.62it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 3/15:  20%|██        | 15/75 [00:01<00:03, 17.09it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.01it/s]
[2025-04-29 17:43:13,562][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.1939
[2025-04-29 17:43:14,055][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1177, Metrics: {'mse': 0.12546369433403015, 'rmse': 0.35420854638761917, 'r2': -1.9978511333465576}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:16,  4.50it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:07, 10.06it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 12.94it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.60it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.64it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 4/15:  20%|██        | 15/75 [00:01<00:03, 17.07it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.27it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.61it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.64it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.71it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.72it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.72it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.71it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.81it/s]
[2025-04-29 17:43:19,091][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1449
[2025-04-29 17:43:19,578][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0876, Metrics: {'mse': 0.09404651075601578, 'rmse': 0.3066700356344189, 'r2': -1.2471635341644287}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:16,  4.55it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:07, 10.10it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 12.96it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.62it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 5/15:  20%|██        | 15/75 [00:01<00:03, 17.05it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.64it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:43:24,627][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1109
[2025-04-29 17:43:25,095][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0676, Metrics: {'mse': 0.07286223769187927, 'rmse': 0.2699300607414433, 'r2': -0.7409828901290894}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:15,  4.92it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.56it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.35it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.88it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.89it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.16it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.66it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.66it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.66it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.66it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.66it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.66it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.65it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.64it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.66it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.67it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.68it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:43:30,108][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.0868
[2025-04-29 17:43:30,597][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0549, Metrics: {'mse': 0.05909717082977295, 'rmse': 0.24309909672759575, 'r2': -0.41207802295684814}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:17,  4.35it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:07,  9.85it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 12.78it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.50it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.58it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.26it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.71it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.64it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.65it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.80it/s]
[2025-04-29 17:43:35,676][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0707
[2025-04-29 17:43:36,177][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0471, Metrics: {'mse': 0.05048619583249092, 'rmse': 0.22469133457365667, 'r2': -0.20632588863372803}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:16,  4.55it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:07, 10.09it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 12.96it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.63it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.65it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 8/15:  20%|██        | 15/75 [00:01<00:03, 17.05it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.75it/s]
[2025-04-29 17:43:41,228][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0601
[2025-04-29 17:43:41,709][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0430, Metrics: {'mse': 0.045556291937828064, 'rmse': 0.21343919962796915, 'r2': -0.08852994441986084}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:15,  4.80it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.40it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.19it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.78it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.74it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.76it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.22it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.45it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.51it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.55it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.58it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.61it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.64it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.63it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.68it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:43:46,754][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0519
[2025-04-29 17:43:47,243][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0413, Metrics: {'mse': 0.043222084641456604, 'rmse': 0.2078992175104481, 'r2': -0.03275585174560547}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:16,  4.54it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.09it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 12.97it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.62it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.64it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.63it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.83it/s]
[2025-04-29 17:43:52,275][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0457
[2025-04-29 17:43:52,776][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0411, Metrics: {'mse': 0.042492907494306564, 'rmse': 0.2061380787101368, 'r2': -0.015332818031311035}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:16,  4.46it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:07,  9.99it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 12.87it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.56it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.61it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.28it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.72it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:43:57,842][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0424
[2025-04-29 17:43:58,323][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0418, Metrics: {'mse': 0.04272199049592018, 'rmse': 0.20669298608303133, 'r2': -0.020806550979614258}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.17it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.01it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.66it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.75it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.25it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:44:02,777][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0417
[2025-04-29 17:44:03,239][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0427, Metrics: {'mse': 0.04335779324173927, 'rmse': 0.20822534245797095, 'r2': -0.03599858283996582}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.67it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:07, 10.23it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.05it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.66it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.66it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.72it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.01it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.34it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.43it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.50it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.52it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.56it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.86it/s]
[2025-04-29 17:44:07,691][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0402
[2025-04-29 17:44:08,170][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0438, Metrics: {'mse': 0.04415889456868172, 'rmse': 0.2101401783778669, 'r2': -0.05514025688171387}
[2025-04-29 17:44:08,171][src.training.lm_trainer][INFO] - Early stopping at epoch 13
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▄▃▂▂▁▁▁▁
wandb:     best_val_mse █▆▄▃▂▂▁▁▁▁
wandb:      best_val_r2 ▁▃▅▆▇▇████
wandb:    best_val_rmse █▆▅▄▃▂▁▁▁▁
wandb:            epoch ▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▃▃▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▄▃▂▂▁▁▁▁▁▁▁
wandb:          val_mse █▆▄▃▂▂▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▅▆▇▇███████
wandb:         val_rmse █▆▅▄▃▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.0411
wandb:     best_val_mse 0.04249
wandb:      best_val_r2 -0.01533
wandb:    best_val_rmse 0.20614
wandb:            epoch 13
wandb:   final_test_mse 0.04635
wandb:    final_test_r2 -0.20278
wandb:  final_test_rmse 0.2153
wandb:  final_train_mse 0.03286
wandb:   final_train_r2 -0.22475
wandb: final_train_rmse 0.18127
wandb:    final_val_mse 0.04249
wandb:     final_val_r2 -0.01533
wandb:   final_val_rmse 0.20614
wandb:    learning_rate 1e-05
wandb:       train_loss 0.04017
wandb:       train_time 70.94579
wandb:         val_loss 0.04377
wandb:          val_mse 0.04416
wandb:           val_r2 -0.05514
wandb:         val_rmse 0.21014
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174245-4g96dant
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174245-4g96dant/logs
Standard experiment completed successfully: layer_5_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_5/complexity/results.json
Running question_type experiment for language en, layer 6
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:44:32,970][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_6/question_type
experiment_name: layer_6_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 6
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:44:32,970][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:44:32,970][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:44:32,970][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:44:32,975][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:44:32,975][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:44:34,663][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:44:37,898][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:44:37,898][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:44:38,026][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,111][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,335][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:44:38,349][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:44:38,350][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:44:38,351][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:44:38,410][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,506][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,518][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:44:38,520][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:44:38,520][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:44:38,521][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:44:38,539][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,605][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:44:38,617][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:44:38,619][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:44:38,619][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:44:38,620][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:44:38,620][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:44:38,621][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:44:38,621][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:44:38,621][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:44:38,621][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:44:38,621][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:44:38,621][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:44:38,621][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:44:38,622][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:44:38,622][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:44:38,622][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:44:38,622][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:44:38,622][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:44:38,622][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:44:38,623][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:44:38,623][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:44:38,623][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:44:38,624][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:44:38,624][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:44:38,624][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:44:38,624][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:44:38,624][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:44:38,625][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:44:44,049][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:44:44,050][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:44:44,051][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:44:44,051][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 6
[2025-04-29 17:44:44,051][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:00,  1.21it/s]Epoch 1/15:   4%|▍         | 3/75 [00:00<00:18,  3.92it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:10,  6.54it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.94it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:05, 11.01it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.71it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 14.05it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:03, 15.08it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.85it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.41it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:01<00:03, 16.83it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.09it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.30it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.45it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.56it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.62it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.82it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.95it/s]
[2025-04-29 17:44:52,039][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6959
[2025-04-29 17:44:52,468][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6942, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:14,  5.05it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 10.74it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.48it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 14.99it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.94it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.53it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.91it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.18it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.35it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.70it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.74it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.73it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.74it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.10it/s]
[2025-04-29 17:44:57,424][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6938
[2025-04-29 17:44:57,874][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6938, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:15,  4.85it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.47it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.26it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.85it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.13it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.72it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.70it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.70it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.71it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.71it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.72it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.73it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.72it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.72it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.71it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.72it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.73it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.74it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:45:02,917][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6978
[2025-04-29 17:45:03,376][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6935, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.80it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:06, 10.43it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.24it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.84it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 4/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.48it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.95it/s]
[2025-04-29 17:45:08,354][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6982
[2025-04-29 17:45:08,805][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6933, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.23it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.93it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.63it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.14it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 16.04it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.60it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.96it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.21it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.49it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.57it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.74it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.72it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.71it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.71it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.68it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.72it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.74it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.77it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.99it/s]
[2025-04-29 17:45:13,765][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6949
[2025-04-29 17:45:14,223][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6931, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:14,  5.19it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:06, 10.87it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.56it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 15.05it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.96it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.52it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.90it/s]Epoch 6/15:  20%|██        | 15/75 [00:00<00:03, 17.15it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.44it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.52it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.62it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.74it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.74it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.74it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.74it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.74it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.74it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.75it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.76it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:45:19,212][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6954
[2025-04-29 17:45:19,686][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.72it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.32it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.16it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.77it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.76it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.36it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.08it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.58it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.67it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.68it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.70it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.70it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.63it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.64it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.62it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.63it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.64it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.66it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.67it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:45:24,715][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6939
[2025-04-29 17:45:25,174][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6930, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:14,  4.97it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.62it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.37it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.44it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 8/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.89it/s]
[2025-04-29 17:45:30,187][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6933
[2025-04-29 17:45:30,644][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:16,  4.58it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:07, 10.14it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 12.99it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.64it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.65it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.73it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.02it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.68it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.69it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.83it/s]
[2025-04-29 17:45:35,698][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6965
[2025-04-29 17:45:36,175][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6929, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:14,  5.07it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:06, 10.74it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.46it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.98it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.89it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.48it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.87it/s]Epoch 10/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 17.04it/s]
[2025-04-29 17:45:41,166][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6945
[2025-04-29 17:45:41,634][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:21,  3.39it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:08,  8.43it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:06, 11.54it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:05, 13.53it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 14.85it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:04, 15.74it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.33it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 16.75it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.04it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.22it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.37it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.46it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.53it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.64it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.65it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.60it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.62it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.66it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.68it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.67it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.69it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.55it/s]
[2025-04-29 17:45:46,770][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6949
[2025-04-29 17:45:47,242][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  5.01it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.65it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.38it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.67it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:45:52,271][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6935
[2025-04-29 17:45:52,734][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:16,  4.44it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:07,  9.95it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 12.83it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.52it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.56it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.25it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.70it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.00it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.35it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.45it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.52it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.82it/s]
[2025-04-29 17:45:57,825][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6953
[2025-04-29 17:45:58,294][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:15,  4.77it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.17it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.73it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.36it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 17.06it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.66it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.67it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.67it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.67it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.66it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:46:02,739][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6955
[2025-04-29 17:46:03,233][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:14,  4.99it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:06, 10.64it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 13.38it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.92it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.86it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.85it/s]Epoch 15/15:  20%|██        | 15/75 [00:00<00:03, 17.11it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.28it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.67it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:46:07,668][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6955
[2025-04-29 17:46:08,154][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6928, Metrics: {'accuracy': 0.5, 'f1': 0.0}
[2025-04-29 17:46:08,155][src.training.lm_trainer][INFO] - Early stopping at epoch 15
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▆▄▃▃▂▂▁▁▁▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ██████████████▁
wandb:           train_loss ▅▂▇█▃▄▂▁▅▃▃▁▄▄▄
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▆▄▃▃▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0
wandb:        best_val_loss 0.69281
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0
wandb:        learning_rate 1e-05
wandb:           train_loss 0.69554
wandb:           train_time 81.13562
wandb:         val_accuracy 0.5
wandb:               val_f1 0
wandb:             val_loss 0.69284
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174433-a2gpk8w7
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174433-a2gpk8w7/logs
Standard experiment completed successfully: layer_6_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_6/question_type/results.json
Running complexity experiment for language en, layer 6
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:46:32,220][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_6/complexity
experiment_name: layer_6_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 6
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:46:32,220][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:46:32,220][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:46:32,220][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:46:32,225][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:46:32,226][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:46:34,165][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:46:37,274][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:46:37,274][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:46:37,370][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,454][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,604][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:46:37,615][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:46:37,616][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:46:37,617][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:46:37,665][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,708][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,740][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:46:37,742][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:46:37,742][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:46:37,743][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:46:37,809][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,881][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:46:37,893][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:46:37,895][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:46:37,895][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:46:37,896][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:46:37,896][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:46:37,896][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:46:37,896][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:46:37,897][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:46:37,897][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:46:37,897][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:46:37,897][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:46:37,897][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:46:37,898][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:46:37,898][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:46:37,898][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:46:37,898][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:46:37,898][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:46:37,898][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:46:37,898][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:46:37,899][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:46:37,899][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:46:37,899][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:46:37,899][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:46:37,899][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:46:37,899][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:46:37,900][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:46:37,900][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:46:37,900][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:46:37,900][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:46:37,900][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:46:37,901][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:46:37,901][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:46:43,168][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:46:43,169][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:46:43,170][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:46:43,170][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 6
[2025-04-29 17:46:43,170][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:05,  1.13it/s]Epoch 1/15:   4%|▍         | 3/75 [00:00<00:19,  3.68it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.22it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.59it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.67it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.41it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.81it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.89it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.70it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.31it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.74it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.05it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.27it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.44it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.55it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.63it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.78it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.83it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.82it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.84it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.79it/s]
[2025-04-29 17:46:50,800][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.3199
[2025-04-29 17:46:51,218][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.2111, Metrics: {'mse': 0.22189556062221527, 'rmse': 0.4710579164202798, 'r2': -4.302010536193848}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:13,  5.43it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 11.13it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 13.78it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.23it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.09it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.63it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.99it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.53it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.61it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.67it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.76it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.78it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.79it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.79it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.79it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.74it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.74it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.76it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.16it/s]
[2025-04-29 17:46:56,189][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.2575
[2025-04-29 17:46:56,601][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.1650, Metrics: {'mse': 0.17452773451805115, 'rmse': 0.41776516671217473, 'r2': -3.1701955795288086}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:15,  4.67it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:07, 10.24it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.11it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.43it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 3/15:  20%|██        | 15/75 [00:01<00:03, 17.15it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.34it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:02<00:02, 17.75it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.05it/s]
[2025-04-29 17:47:01,835][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.2031
[2025-04-29 17:47:02,287][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.1296, Metrics: {'mse': 0.1379048079252243, 'rmse': 0.37135536609186665, 'r2': -2.295121192932129}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.65it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:07, 10.25it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.10it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.75it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 4/15:  20%|██        | 15/75 [00:01<00:03, 17.12it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.55it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.75it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:47:07,259][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.1595
[2025-04-29 17:47:07,731][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.1011, Metrics: {'mse': 0.10822793841362, 'rmse': 0.32898014896589123, 'r2': -1.5860168933868408}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:16,  4.59it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:07, 10.17it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.04it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.70it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.73it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.82it/s]Epoch 5/15:  20%|██        | 15/75 [00:01<00:03, 17.11it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.60it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:02<00:02, 17.71it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.73it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.74it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.75it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:47:12,779][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.1272
[2025-04-29 17:47:13,237][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.0806, Metrics: {'mse': 0.08662457019090652, 'rmse': 0.29432052288433186, 'r2': -1.0698223114013672}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:16,  4.59it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:07, 10.15it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.03it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.68it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.72it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.82it/s]Epoch 6/15:  20%|██        | 15/75 [00:01<00:03, 17.11it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.31it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.45it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.68it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.72it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.78it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:47:18,237][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.1031
[2025-04-29 17:47:18,697][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.0662, Metrics: {'mse': 0.07139269262552261, 'rmse': 0.26719411038704166, 'r2': -0.7058693170547485}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.68it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:07, 10.27it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.12it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.76it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.83it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.11it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.43it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.53it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.59it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.63it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.66it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.71it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.72it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.73it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.72it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.71it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.71it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.72it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.91it/s]
[2025-04-29 17:47:23,749][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.0855
[2025-04-29 17:47:24,233][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.0559, Metrics: {'mse': 0.06026562675833702, 'rmse': 0.2454905838486214, 'r2': -0.4399973154067993}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:16,  4.54it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:07, 10.09it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 12.96it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.61it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.64it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.73it/s]Epoch 8/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.38it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.48it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.71it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.71it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.68it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:47:29,252][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.0727
[2025-04-29 17:47:29,724][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.0489, Metrics: {'mse': 0.052549656480550766, 'rmse': 0.2292371184615414, 'r2': -0.2556304931640625}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:16,  4.51it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:07, 10.04it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 12.92it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 14.60it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.62it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.30it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.72it/s]Epoch 9/15:  20%|██        | 15/75 [00:01<00:03, 17.03it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:47:34,800][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.0617
[2025-04-29 17:47:35,279][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.0445, Metrics: {'mse': 0.04741279408335686, 'rmse': 0.21774479117388057, 'r2': -0.13288938999176025}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:16,  4.60it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.15it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 12.98it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.61it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.63it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.28it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.72it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.01it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.33it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.41it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.53it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.56it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.61it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.63it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.63it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.63it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.62it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.63it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.63it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.63it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.62it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.63it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.63it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.66it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.68it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.69it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.84it/s]
[2025-04-29 17:47:40,316][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.0534
[2025-04-29 17:47:40,784][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.0419, Metrics: {'mse': 0.044285304844379425, 'rmse': 0.2104407395073003, 'r2': -0.05816066265106201}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:14,  4.96it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.61it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.35it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.89it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.82it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.40it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 11/15:  20%|██        | 15/75 [00:00<00:03, 17.04it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.22it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.44it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.61it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.63it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.63it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.62it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.63it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.63it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.63it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.66it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:47:45,840][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.0477
[2025-04-29 17:47:46,284][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.0408, Metrics: {'mse': 0.0426793172955513, 'rmse': 0.20658973182506263, 'r2': -0.019786953926086426}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:14,  4.96it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:06, 10.60it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.36it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.91it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.85it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.45it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 12/15:  20%|██        | 15/75 [00:00<00:03, 17.10it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.68it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:47:51,312][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.0447
[2025-04-29 17:47:51,791][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.0406, Metrics: {'mse': 0.042044807225465775, 'rmse': 0.2050483046149511, 'r2': -0.004625916481018066}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:16,  4.58it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:07, 10.13it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 12.97it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.60it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.62it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.27it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.70it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 16.99it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.19it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.33it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.42it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.49it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.53it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.56it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.64it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.66it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.66it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.65it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.63it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.61it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.63it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.65it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.74it/s]
[2025-04-29 17:47:56,867][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.0415
[2025-04-29 17:47:57,331][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.0409, Metrics: {'mse': 0.04203887656331062, 'rmse': 0.20503384248291945, 'r2': -0.0044841766357421875}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:17,  4.33it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:07,  9.81it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 12.72it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.43it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.51it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.21it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.67it/s]Epoch 14/15:  20%|██        | 15/75 [00:01<00:03, 16.98it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.18it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.32it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.42it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.48it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.54it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.57it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.59it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.61it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.63it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.67it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.67it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.63it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.67it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.80it/s]
[2025-04-29 17:48:01,799][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.0381
[2025-04-29 17:48:02,275][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.0416, Metrics: {'mse': 0.04239566624164581, 'rmse': 0.20590207925527565, 'r2': -0.013009309768676758}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:16,  4.39it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:07,  9.88it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 12.78it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.47it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.54it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.23it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.69it/s]Epoch 15/15:  20%|██        | 15/75 [00:01<00:03, 17.00it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.21it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.46it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.57it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.60it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.67it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.68it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.68it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:48:06,723][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.0378
[2025-04-29 17:48:07,207][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.0423, Metrics: {'mse': 0.042876314371824265, 'rmse': 0.2070659662325614, 'r2': -0.024494051933288574}
[2025-04-29 17:48:07,208][src.training.lm_trainer][INFO] - Early stopping at epoch 15
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_loss █▆▅▃▃▂▂▁▁▁▁▁
wandb:     best_val_mse █▆▅▄▃▂▂▁▁▁▁▁
wandb:      best_val_r2 ▁▃▄▅▆▇▇█████
wandb:    best_val_rmse █▇▅▄▃▃▂▂▁▁▁▁
wandb:            epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:   final_test_mse ▁
wandb:    final_test_r2 ▁
wandb:  final_test_rmse ▁
wandb:  final_train_mse ▁
wandb:   final_train_r2 ▁
wandb: final_train_rmse ▁
wandb:    final_val_mse ▁
wandb:     final_val_r2 ▁
wandb:   final_val_rmse ▁
wandb:    learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss █▆▅▄▃▃▂▂▂▁▁▁▁▁▁
wandb:       train_time ▁
wandb:         val_loss █▆▅▃▃▂▂▁▁▁▁▁▁▁▁
wandb:          val_mse █▆▅▄▃▂▂▁▁▁▁▁▁▁▁
wandb:           val_r2 ▁▃▄▅▆▇▇████████
wandb:         val_rmse █▇▅▄▃▃▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_loss 0.04058
wandb:     best_val_mse 0.04204
wandb:      best_val_r2 -0.00463
wandb:    best_val_rmse 0.20505
wandb:            epoch 15
wandb:   final_test_mse 0.04651
wandb:    final_test_r2 -0.20691
wandb:  final_test_rmse 0.21567
wandb:  final_train_mse 0.03336
wandb:   final_train_r2 -0.24335
wandb: final_train_rmse 0.18264
wandb:    final_val_mse 0.04204
wandb:     final_val_r2 -0.00463
wandb:   final_val_rmse 0.20505
wandb:    learning_rate 1e-05
wandb:       train_loss 0.03778
wandb:       train_time 81.48249
wandb:         val_loss 0.04227
wandb:          val_mse 0.04288
wandb:           val_r2 -0.02449
wandb:         val_rmse 0.20707
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174632-6b07nnhd
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174632-6b07nnhd/logs
Standard experiment completed successfully: layer_6_complexity_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_6/complexity/results.json
Running question_type experiment for language en, layer 7
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:48:33,665][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_7/question_type
experiment_name: layer_7_question_type_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 7
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: classification
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: question_type
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false

[2025-04-29 17:48:33,665][__main__][INFO] - Normalized task: question_type
[2025-04-29 17:48:33,665][__main__][INFO] - Using explicit task_type from config: classification
[2025-04-29 17:48:33,666][__main__][INFO] - Determined Task Type: classification
[2025-04-29 17:48:34,271][__main__][INFO] - Running LM probe experiment for task 'question_type' (type: classification) on languages: ['en']
[2025-04-29 17:48:34,272][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:48:36,741][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'question_type', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:48:39,928][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:48:39,928][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:48:40,029][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,086][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,245][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:48:40,258][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:48:40,259][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:48:40,259][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:48:40,289][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,335][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,347][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:48:40,349][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:48:40,349][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:48:40,350][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:48:40,376][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,441][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:48:40,451][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:48:40,453][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:48:40,454][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:48:40,455][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:48:40,456][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:48:40,456][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:48:40,456][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:48:40,456][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:48:40,457][src.data.datasets][INFO] -   Label 0: 596 examples (50.0%)
[2025-04-29 17:48:40,457][src.data.datasets][INFO] -   Label 1: 596 examples (50.0%)
[2025-04-29 17:48:40,457][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:48:40,457][src.data.datasets][INFO] - Sample label: 1
[2025-04-29 17:48:40,457][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:48:40,457][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:48:40,457][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:48:40,458][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:48:40,458][src.data.datasets][INFO] -   Label 0: 36 examples (50.0%)
[2025-04-29 17:48:40,458][src.data.datasets][INFO] -   Label 1: 36 examples (50.0%)
[2025-04-29 17:48:40,458][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:48:40,458][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:48:40,458][src.data.datasets][INFO] - Task 'question_type' is classification: True
[2025-04-29 17:48:40,458][src.data.datasets][INFO] - Getting feature name for task: 'question_type', submetric: 'None'
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Selected feature name: 'question_type' for task: 'question_type'
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Label statistics for question_type (feature: question_type):
[2025-04-29 17:48:40,459][src.data.datasets][INFO] -   Label 0: 55 examples (50.0%)
[2025-04-29 17:48:40,459][src.data.datasets][INFO] -   Label 1: 55 examples (50.0%)
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Sample label: 0
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:48:40,459][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:48:40,460][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:48:40,461][src.models.model_factory][INFO] - Creating lm_probe model for classification task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:48:46,360][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:48:46,361][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:48:46,362][src.models.model_factory][INFO] - Created classification head with 1 outputs
[2025-04-29 17:48:46,363][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 7
[2025-04-29 17:48:46,363][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:06,  1.11it/s]Epoch 1/15:   4%|▍         | 3/75 [00:01<00:19,  3.64it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:11,  6.16it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.52it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.61it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.37it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.78it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.88it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.70it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.29it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:02<00:03, 16.73it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.05it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.26it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.42it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.54it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.62it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.68it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.72it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:03<00:02, 17.77it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.78it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.79it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.83it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:04<00:01, 17.77it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.78it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.80it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.84it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.81it/s]
[2025-04-29 17:48:54,126][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.6939
[2025-04-29 17:48:54,551][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.6953, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:12,  5.69it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:06, 11.43it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 14.00it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 15.41it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 16.22it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:03, 16.76it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 17.08it/s]Epoch 2/15:  20%|██        | 15/75 [00:00<00:03, 17.33it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.45it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.55it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.60it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.66it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:01<00:02, 17.73it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.73it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.74it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.75it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:02<00:01, 17.79it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.80it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.79it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 17.17it/s]
[2025-04-29 17:48:59,484][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.6940
[2025-04-29 17:48:59,918][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.6952, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.82it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.57it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.08it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 16.02it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.59it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.97it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.23it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.53it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.59it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.69it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.76it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.01it/s]
[2025-04-29 17:49:05,075][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.6943
[2025-04-29 17:49:05,562][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.6952, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:15,  4.65it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:07, 10.24it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 13.10it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.75it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 4/15:  20%|██        | 15/75 [00:01<00:03, 17.13it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.33it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.47it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.62it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.70it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.74it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.78it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.77it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.92it/s]
[2025-04-29 17:49:10,557][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.6943
[2025-04-29 17:49:11,004][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.6951, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:14,  5.05it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:06, 10.73it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 13.48it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 15.02it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.95it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.54it/s]Epoch 5/15:  17%|█▋        | 13/75 [00:00<00:03, 16.94it/s]Epoch 5/15:  20%|██        | 15/75 [00:00<00:03, 17.19it/s]Epoch 5/15:  23%|██▎       | 17/75 [00:01<00:03, 17.38it/s]Epoch 5/15:  25%|██▌       | 19/75 [00:01<00:03, 17.50it/s]Epoch 5/15:  28%|██▊       | 21/75 [00:01<00:03, 17.58it/s]Epoch 5/15:  31%|███       | 23/75 [00:01<00:02, 17.64it/s]Epoch 5/15:  33%|███▎      | 25/75 [00:01<00:02, 17.67it/s]Epoch 5/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 5/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 5/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 5/15:  44%|████▍     | 33/75 [00:01<00:02, 17.75it/s]Epoch 5/15:  47%|████▋     | 35/75 [00:02<00:02, 17.76it/s]Epoch 5/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 5/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.77it/s]Epoch 5/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  60%|██████    | 45/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.77it/s]Epoch 5/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.75it/s]Epoch 5/15:  71%|███████   | 53/75 [00:03<00:01, 17.74it/s]Epoch 5/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.75it/s]Epoch 5/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.76it/s]Epoch 5/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.75it/s]Epoch 5/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.76it/s]Epoch 5/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.77it/s]Epoch 5/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.78it/s]Epoch 5/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 5/15: 100%|██████████| 75/75 [00:04<00:00, 17.00it/s]
[2025-04-29 17:49:16,000][src.training.lm_trainer][INFO] - Epoch 5/15, Train Loss: 0.6942
[2025-04-29 17:49:16,469][src.training.lm_trainer][INFO] - Epoch 5/15, Val Loss: 0.6950, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 6/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 6/15:   1%|▏         | 1/75 [00:00<00:15,  4.69it/s]Epoch 6/15:   4%|▍         | 3/75 [00:00<00:07, 10.28it/s]Epoch 6/15:   7%|▋         | 5/75 [00:00<00:05, 13.11it/s]Epoch 6/15:   9%|▉         | 7/75 [00:00<00:04, 14.74it/s]Epoch 6/15:  12%|█▏        | 9/75 [00:00<00:04, 15.73it/s]Epoch 6/15:  15%|█▍        | 11/75 [00:00<00:03, 16.39it/s]Epoch 6/15:  17%|█▋        | 13/75 [00:00<00:03, 16.81it/s]Epoch 6/15:  20%|██        | 15/75 [00:01<00:03, 17.09it/s]Epoch 6/15:  23%|██▎       | 17/75 [00:01<00:03, 17.29it/s]Epoch 6/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 6/15:  28%|██▊       | 21/75 [00:01<00:03, 17.51it/s]Epoch 6/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 6/15:  33%|███▎      | 25/75 [00:01<00:02, 17.61it/s]Epoch 6/15:  36%|███▌      | 27/75 [00:01<00:02, 17.65it/s]Epoch 6/15:  39%|███▊      | 29/75 [00:01<00:02, 17.68it/s]Epoch 6/15:  41%|████▏     | 31/75 [00:01<00:02, 17.69it/s]Epoch 6/15:  44%|████▍     | 33/75 [00:02<00:02, 17.69it/s]Epoch 6/15:  47%|████▋     | 35/75 [00:02<00:02, 17.71it/s]Epoch 6/15:  49%|████▉     | 37/75 [00:02<00:02, 17.73it/s]Epoch 6/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.74it/s]Epoch 6/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.75it/s]Epoch 6/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.77it/s]Epoch 6/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.76it/s]Epoch 6/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  71%|███████   | 53/75 [00:03<00:01, 17.76it/s]Epoch 6/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.77it/s]Epoch 6/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.77it/s]Epoch 6/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.76it/s]Epoch 6/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.75it/s]Epoch 6/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.76it/s]Epoch 6/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.77it/s]Epoch 6/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.79it/s]Epoch 6/15: 100%|██████████| 75/75 [00:04<00:00, 16.94it/s]
[2025-04-29 17:49:21,462][src.training.lm_trainer][INFO] - Epoch 6/15, Train Loss: 0.6940
[2025-04-29 17:49:21,923][src.training.lm_trainer][INFO] - Epoch 6/15, Val Loss: 0.6950, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 7/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 7/15:   1%|▏         | 1/75 [00:00<00:15,  4.71it/s]Epoch 7/15:   4%|▍         | 3/75 [00:00<00:06, 10.32it/s]Epoch 7/15:   7%|▋         | 5/75 [00:00<00:05, 13.15it/s]Epoch 7/15:   9%|▉         | 7/75 [00:00<00:04, 14.78it/s]Epoch 7/15:  12%|█▏        | 9/75 [00:00<00:04, 15.78it/s]Epoch 7/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 7/15:  17%|█▋        | 13/75 [00:00<00:03, 16.84it/s]Epoch 7/15:  20%|██        | 15/75 [00:01<00:03, 17.13it/s]Epoch 7/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 7/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 7/15:  28%|██▊       | 21/75 [00:01<00:03, 17.54it/s]Epoch 7/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 7/15:  33%|███▎      | 25/75 [00:01<00:02, 17.65it/s]Epoch 7/15:  36%|███▌      | 27/75 [00:01<00:02, 17.69it/s]Epoch 7/15:  39%|███▊      | 29/75 [00:01<00:02, 17.72it/s]Epoch 7/15:  41%|████▏     | 31/75 [00:01<00:02, 17.73it/s]Epoch 7/15:  44%|████▍     | 33/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  49%|████▉     | 37/75 [00:02<00:02, 17.74it/s]Epoch 7/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.75it/s]Epoch 7/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  60%|██████    | 45/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.76it/s]Epoch 7/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.74it/s]Epoch 7/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.74it/s]Epoch 7/15:  71%|███████   | 53/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.72it/s]Epoch 7/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.73it/s]Epoch 7/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.72it/s]Epoch 7/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 7/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.72it/s]Epoch 7/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 7/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 7/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 7/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 7/15: 100%|██████████| 75/75 [00:04<00:00, 16.93it/s]
[2025-04-29 17:49:26,943][src.training.lm_trainer][INFO] - Epoch 7/15, Train Loss: 0.6938
[2025-04-29 17:49:27,411][src.training.lm_trainer][INFO] - Epoch 7/15, Val Loss: 0.6949, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 8/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 8/15:   1%|▏         | 1/75 [00:00<00:15,  4.71it/s]Epoch 8/15:   4%|▍         | 3/75 [00:00<00:06, 10.31it/s]Epoch 8/15:   7%|▋         | 5/75 [00:00<00:05, 13.13it/s]Epoch 8/15:   9%|▉         | 7/75 [00:00<00:04, 14.75it/s]Epoch 8/15:  12%|█▏        | 9/75 [00:00<00:04, 15.74it/s]Epoch 8/15:  15%|█▍        | 11/75 [00:00<00:03, 16.38it/s]Epoch 8/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 8/15:  20%|██        | 15/75 [00:01<00:03, 17.08it/s]Epoch 8/15:  23%|██▎       | 17/75 [00:01<00:03, 17.27it/s]Epoch 8/15:  25%|██▌       | 19/75 [00:01<00:03, 17.41it/s]Epoch 8/15:  28%|██▊       | 21/75 [00:01<00:03, 17.49it/s]Epoch 8/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 8/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 8/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 8/15:  39%|███▊      | 29/75 [00:01<00:02, 17.65it/s]Epoch 8/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 8/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 8/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 8/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 8/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 8/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.71it/s]Epoch 8/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 8/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  71%|███████   | 53/75 [00:03<00:01, 17.71it/s]Epoch 8/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 8/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.71it/s]Epoch 8/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 8/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.70it/s]Epoch 8/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.71it/s]Epoch 8/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.72it/s]Epoch 8/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.73it/s]Epoch 8/15: 100%|██████████| 75/75 [00:04<00:00, 16.89it/s]
[2025-04-29 17:49:32,412][src.training.lm_trainer][INFO] - Epoch 8/15, Train Loss: 0.6937
[2025-04-29 17:49:32,855][src.training.lm_trainer][INFO] - Epoch 8/15, Val Loss: 0.6948, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 9/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 9/15:   1%|▏         | 1/75 [00:00<00:14,  5.14it/s]Epoch 9/15:   4%|▍         | 3/75 [00:00<00:06, 10.81it/s]Epoch 9/15:   7%|▋         | 5/75 [00:00<00:05, 13.52it/s]Epoch 9/15:   9%|▉         | 7/75 [00:00<00:04, 15.03it/s]Epoch 9/15:  12%|█▏        | 9/75 [00:00<00:04, 15.92it/s]Epoch 9/15:  15%|█▍        | 11/75 [00:00<00:03, 16.50it/s]Epoch 9/15:  17%|█▋        | 13/75 [00:00<00:03, 16.88it/s]Epoch 9/15:  20%|██        | 15/75 [00:00<00:03, 17.14it/s]Epoch 9/15:  23%|██▎       | 17/75 [00:01<00:03, 17.32it/s]Epoch 9/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 9/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 9/15:  31%|███       | 23/75 [00:01<00:02, 17.57it/s]Epoch 9/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 9/15:  36%|███▌      | 27/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  39%|███▊      | 29/75 [00:01<00:02, 17.61it/s]Epoch 9/15:  41%|████▏     | 31/75 [00:01<00:02, 17.62it/s]Epoch 9/15:  44%|████▍     | 33/75 [00:02<00:02, 17.62it/s]Epoch 9/15:  47%|████▋     | 35/75 [00:02<00:02, 17.63it/s]Epoch 9/15:  49%|████▉     | 37/75 [00:02<00:02, 17.63it/s]Epoch 9/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.60it/s]Epoch 9/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.61it/s]Epoch 9/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.62it/s]Epoch 9/15:  60%|██████    | 45/75 [00:02<00:01, 17.62it/s]Epoch 9/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.63it/s]Epoch 9/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.63it/s]Epoch 9/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.64it/s]Epoch 9/15:  71%|███████   | 53/75 [00:03<00:01, 17.64it/s]Epoch 9/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 9/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.64it/s]Epoch 9/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 9/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.65it/s]Epoch 9/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 9/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.66it/s]Epoch 9/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 9/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.66it/s]Epoch 9/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.65it/s]Epoch 9/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.66it/s]Epoch 9/15: 100%|██████████| 75/75 [00:04<00:00, 16.88it/s]
[2025-04-29 17:49:37,888][src.training.lm_trainer][INFO] - Epoch 9/15, Train Loss: 0.6939
[2025-04-29 17:49:38,360][src.training.lm_trainer][INFO] - Epoch 9/15, Val Loss: 0.6947, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 10/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 10/15:   1%|▏         | 1/75 [00:00<00:15,  4.68it/s]Epoch 10/15:   4%|▍         | 3/75 [00:00<00:07, 10.27it/s]Epoch 10/15:   7%|▋         | 5/75 [00:00<00:05, 13.10it/s]Epoch 10/15:   9%|▉         | 7/75 [00:00<00:04, 14.72it/s]Epoch 10/15:  12%|█▏        | 9/75 [00:00<00:04, 15.72it/s]Epoch 10/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]Epoch 10/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 10/15:  20%|██        | 15/75 [00:01<00:03, 17.07it/s]Epoch 10/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 10/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 10/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 10/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 10/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 10/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 10/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 10/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 10/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 10/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 10/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.65it/s]Epoch 10/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 10/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 10/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.65it/s]Epoch 10/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.65it/s]Epoch 10/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.66it/s]Epoch 10/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.65it/s]Epoch 10/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.66it/s]Epoch 10/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 10/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 10/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 10/15: 100%|██████████| 75/75 [00:04<00:00, 16.85it/s]
[2025-04-29 17:49:43,366][src.training.lm_trainer][INFO] - Epoch 10/15, Train Loss: 0.6935
[2025-04-29 17:49:43,835][src.training.lm_trainer][INFO] - Epoch 10/15, Val Loss: 0.6947, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 11/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 11/15:   1%|▏         | 1/75 [00:00<00:15,  4.77it/s]Epoch 11/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 11/15:   7%|▋         | 5/75 [00:00<00:05, 13.18it/s]Epoch 11/15:   9%|▉         | 7/75 [00:00<00:04, 14.78it/s]Epoch 11/15:  12%|█▏        | 9/75 [00:00<00:04, 15.75it/s]Epoch 11/15:  15%|█▍        | 11/75 [00:00<00:03, 16.37it/s]Epoch 11/15:  17%|█▋        | 13/75 [00:00<00:03, 16.77it/s]Epoch 11/15:  20%|██        | 15/75 [00:01<00:03, 17.06it/s]Epoch 11/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 11/15:  25%|██▌       | 19/75 [00:01<00:03, 17.39it/s]Epoch 11/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 11/15:  31%|███       | 23/75 [00:01<00:02, 17.54it/s]Epoch 11/15:  33%|███▎      | 25/75 [00:01<00:02, 17.59it/s]Epoch 11/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 11/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 11/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 11/15:  44%|████▍     | 33/75 [00:02<00:02, 17.65it/s]Epoch 11/15:  47%|████▋     | 35/75 [00:02<00:02, 17.66it/s]Epoch 11/15:  49%|████▉     | 37/75 [00:02<00:02, 17.67it/s]Epoch 11/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 11/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  60%|██████    | 45/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 11/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.70it/s]Epoch 11/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 11/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 11/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 11/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.70it/s]Epoch 11/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.71it/s]Epoch 11/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.72it/s]Epoch 11/15: 100%|██████████| 75/75 [00:04<00:00, 16.90it/s]
[2025-04-29 17:49:48,892][src.training.lm_trainer][INFO] - Epoch 11/15, Train Loss: 0.6938
[2025-04-29 17:49:49,373][src.training.lm_trainer][INFO] - Epoch 11/15, Val Loss: 0.6946, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 12/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 12/15:   1%|▏         | 1/75 [00:00<00:16,  4.61it/s]Epoch 12/15:   4%|▍         | 3/75 [00:00<00:07, 10.17it/s]Epoch 12/15:   7%|▋         | 5/75 [00:00<00:05, 13.02it/s]Epoch 12/15:   9%|▉         | 7/75 [00:00<00:04, 14.65it/s]Epoch 12/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 12/15:  15%|█▍        | 11/75 [00:00<00:03, 16.31it/s]Epoch 12/15:  17%|█▋        | 13/75 [00:00<00:03, 16.74it/s]Epoch 12/15:  20%|██        | 15/75 [00:01<00:03, 17.04it/s]Epoch 12/15:  23%|██▎       | 17/75 [00:01<00:03, 17.23it/s]Epoch 12/15:  25%|██▌       | 19/75 [00:01<00:03, 17.37it/s]Epoch 12/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 12/15:  31%|███       | 23/75 [00:01<00:02, 17.53it/s]Epoch 12/15:  33%|███▎      | 25/75 [00:01<00:02, 17.58it/s]Epoch 12/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 12/15:  39%|███▊      | 29/75 [00:01<00:02, 17.63it/s]Epoch 12/15:  41%|████▏     | 31/75 [00:01<00:02, 17.65it/s]Epoch 12/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  47%|████▋     | 35/75 [00:02<00:02, 17.67it/s]Epoch 12/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 12/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 12/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 12/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 12/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.69it/s]Epoch 12/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 12/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.71it/s]Epoch 12/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.71it/s]Epoch 12/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.70it/s]Epoch 12/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.69it/s]Epoch 12/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 12/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 12/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 12/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:49:54,378][src.training.lm_trainer][INFO] - Epoch 12/15, Train Loss: 0.6935
[2025-04-29 17:49:54,843][src.training.lm_trainer][INFO] - Epoch 12/15, Val Loss: 0.6945, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 13/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 13/15:   1%|▏         | 1/75 [00:00<00:15,  4.76it/s]Epoch 13/15:   4%|▍         | 3/75 [00:00<00:06, 10.37it/s]Epoch 13/15:   7%|▋         | 5/75 [00:00<00:05, 13.17it/s]Epoch 13/15:   9%|▉         | 7/75 [00:00<00:04, 14.77it/s]Epoch 13/15:  12%|█▏        | 9/75 [00:00<00:04, 15.74it/s]Epoch 13/15:  15%|█▍        | 11/75 [00:00<00:03, 16.37it/s]Epoch 13/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 13/15:  20%|██        | 15/75 [00:01<00:03, 17.08it/s]Epoch 13/15:  23%|██▎       | 17/75 [00:01<00:03, 17.26it/s]Epoch 13/15:  25%|██▌       | 19/75 [00:01<00:03, 17.40it/s]Epoch 13/15:  28%|██▊       | 21/75 [00:01<00:03, 17.47it/s]Epoch 13/15:  31%|███       | 23/75 [00:01<00:02, 17.55it/s]Epoch 13/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 13/15:  36%|███▌      | 27/75 [00:01<00:02, 17.63it/s]Epoch 13/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 13/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 13/15:  44%|████▍     | 33/75 [00:02<00:02, 17.66it/s]Epoch 13/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  49%|████▉     | 37/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.68it/s]Epoch 13/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  60%|██████    | 45/75 [00:02<00:01, 17.70it/s]Epoch 13/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 13/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.68it/s]Epoch 13/15:  71%|███████   | 53/75 [00:03<00:01, 17.69it/s]Epoch 13/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 13/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.69it/s]Epoch 13/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.67it/s]Epoch 13/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.67it/s]Epoch 13/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.69it/s]Epoch 13/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.70it/s]Epoch 13/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.71it/s]Epoch 13/15: 100%|██████████| 75/75 [00:04<00:00, 16.87it/s]
[2025-04-29 17:49:59,896][src.training.lm_trainer][INFO] - Epoch 13/15, Train Loss: 0.6934
[2025-04-29 17:50:00,360][src.training.lm_trainer][INFO] - Epoch 13/15, Val Loss: 0.6945, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 14/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 14/15:   1%|▏         | 1/75 [00:00<00:14,  4.95it/s]Epoch 14/15:   4%|▍         | 3/75 [00:00<00:06, 10.58it/s]Epoch 14/15:   7%|▋         | 5/75 [00:00<00:05, 13.33it/s]Epoch 14/15:   9%|▉         | 7/75 [00:00<00:04, 14.86it/s]Epoch 14/15:  12%|█▏        | 9/75 [00:00<00:04, 15.80it/s]Epoch 14/15:  15%|█▍        | 11/75 [00:00<00:03, 16.41it/s]Epoch 14/15:  17%|█▋        | 13/75 [00:00<00:03, 16.80it/s]Epoch 14/15:  20%|██        | 15/75 [00:00<00:03, 17.06it/s]Epoch 14/15:  23%|██▎       | 17/75 [00:01<00:03, 17.24it/s]Epoch 14/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 14/15:  28%|██▊       | 21/75 [00:01<00:03, 17.45it/s]Epoch 14/15:  31%|███       | 23/75 [00:01<00:02, 17.51it/s]Epoch 14/15:  33%|███▎      | 25/75 [00:01<00:02, 17.55it/s]Epoch 14/15:  36%|███▌      | 27/75 [00:01<00:02, 17.58it/s]Epoch 14/15:  39%|███▊      | 29/75 [00:01<00:02, 17.60it/s]Epoch 14/15:  41%|████▏     | 31/75 [00:01<00:02, 17.59it/s]Epoch 14/15:  44%|████▍     | 33/75 [00:02<00:02, 17.61it/s]Epoch 14/15:  47%|████▋     | 35/75 [00:02<00:02, 17.62it/s]Epoch 14/15:  49%|████▉     | 37/75 [00:02<00:02, 17.62it/s]Epoch 14/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.64it/s]Epoch 14/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  60%|██████    | 45/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.66it/s]Epoch 14/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.65it/s]Epoch 14/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  71%|███████   | 53/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.65it/s]Epoch 14/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.63it/s]Epoch 14/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.64it/s]Epoch 14/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.66it/s]Epoch 14/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.66it/s]Epoch 14/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.67it/s]Epoch 14/15: 100%|██████████| 75/75 [00:04<00:00, 16.83it/s]
[2025-04-29 17:50:05,399][src.training.lm_trainer][INFO] - Epoch 14/15, Train Loss: 0.6934
[2025-04-29 17:50:05,871][src.training.lm_trainer][INFO] - Epoch 14/15, Val Loss: 0.6944, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
Epoch 15/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 15/15:   1%|▏         | 1/75 [00:00<00:14,  5.03it/s]Epoch 15/15:   4%|▍         | 3/75 [00:00<00:06, 10.68it/s]Epoch 15/15:   7%|▋         | 5/75 [00:00<00:05, 13.42it/s]Epoch 15/15:   9%|▉         | 7/75 [00:00<00:04, 14.95it/s]Epoch 15/15:  12%|█▏        | 9/75 [00:00<00:04, 15.87it/s]Epoch 15/15:  15%|█▍        | 11/75 [00:00<00:03, 16.46it/s]Epoch 15/15:  17%|█▋        | 13/75 [00:00<00:03, 16.86it/s]Epoch 15/15:  20%|██        | 15/75 [00:00<00:03, 17.12it/s]Epoch 15/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 15/15:  25%|██▌       | 19/75 [00:01<00:03, 17.42it/s]Epoch 15/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 15/15:  31%|███       | 23/75 [00:01<00:02, 17.56it/s]Epoch 15/15:  33%|███▎      | 25/75 [00:01<00:02, 17.60it/s]Epoch 15/15:  36%|███▌      | 27/75 [00:01<00:02, 17.62it/s]Epoch 15/15:  39%|███▊      | 29/75 [00:01<00:02, 17.64it/s]Epoch 15/15:  41%|████▏     | 31/75 [00:01<00:02, 17.66it/s]Epoch 15/15:  44%|████▍     | 33/75 [00:02<00:02, 17.67it/s]Epoch 15/15:  47%|████▋     | 35/75 [00:02<00:02, 17.68it/s]Epoch 15/15:  49%|████▉     | 37/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.69it/s]Epoch 15/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  60%|██████    | 45/75 [00:02<00:01, 17.68it/s]Epoch 15/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.69it/s]Epoch 15/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  71%|███████   | 53/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.70it/s]Epoch 15/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.70it/s]Epoch 15/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.68it/s]Epoch 15/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.64it/s]Epoch 15/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.65it/s]Epoch 15/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.68it/s]Epoch 15/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.69it/s]Epoch 15/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.70it/s]Epoch 15/15: 100%|██████████| 75/75 [00:04<00:00, 16.97it/s]
[2025-04-29 17:50:10,892][src.training.lm_trainer][INFO] - Epoch 15/15, Train Loss: 0.6935
[2025-04-29 17:50:11,358][src.training.lm_trainer][INFO] - Epoch 15/15, Val Loss: 0.6944, Metrics: {'accuracy': 0.5, 'f1': 0.6666666666666666}
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:    best_val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          best_val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        best_val_loss █▇▇▆▆▅▅▄▃▃▃▂▂▁▁
wandb:                epoch ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:  final_test_accuracy ▁
wandb:        final_test_f1 ▁
wandb: final_train_accuracy ▁
wandb:       final_train_f1 ▁
wandb:   final_val_accuracy ▁
wandb:         final_val_f1 ▁
wandb:        learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_loss ▅▆██▇▅▄▄▅▂▄▂▁▁▂
wandb:           train_time ▁
wandb:         val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               val_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_loss █▇▇▆▆▅▅▄▃▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:    best_val_accuracy 0.5
wandb:          best_val_f1 0.66667
wandb:        best_val_loss 0.69439
wandb:                epoch 15
wandb:  final_test_accuracy 0.5
wandb:        final_test_f1 0.66667
wandb: final_train_accuracy 0.5
wandb:       final_train_f1 0.66667
wandb:   final_val_accuracy 0.5
wandb:         final_val_f1 0.66667
wandb:        learning_rate 1e-05
wandb:           train_loss 0.6935
wandb:           train_time 82.87086
wandb:         val_accuracy 0.5
wandb:               val_f1 0.66667
wandb:             val_loss 0.69439
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174834-ia7gynxs
wandb: Find logs at: /scratch/leuven/371/vsc37132/wandb/wandb/offline-run-20250429_174834-ia7gynxs/logs
Standard experiment completed successfully: layer_7_question_type_en
Warning: Results file not found: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_7/question_type/results.json
Running complexity experiment for language en, layer 7
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/launcher:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/runpy.py:197: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  return _run_code(code, main_globals, None,
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/hydra/main.py:94: UserWarning: 
'hydra/launcher/submitit_slurm' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
Using Dataset: rokokot/question-type-and-complexity
Cache Directory: /data/leuven/371/vsc37132/qtype-eval/data/cache
[2025-04-29 17:50:41,039][__main__][INFO] - Configuration:
seed: 42
output_dir: /scratch/leuven/371/vsc37132/layerwise_output/en/layer_7/complexity
experiment_name: layer_7_complexity_en
wandb:
  project: multilingual-question-probing
  entity: rokii-ku-leuven
  mode: offline
slurm:
  partition: gpu
  time: '24:00:00'
  gpus_per_node: 1
  cpus_per_task: 4
  mem_per_cpu: 8
  job_name: ${experiment_name}
  account: intro_vsc37132
data:
  dataset_name: rokokot/question-type-and-complexity
  cache_dir: /data/leuven/371/vsc37132/qtype-eval/data/cache
  vectors_dir: ./data/features
  languages:
  - en
  train_language: null
  eval_language: null
model:
  model_type: lm_probe
  lm_name: cis-lmu/glot500-base
  dropout: 0.3
  freeze_model: true
  layer_wise: true
  layer_index: 7
  num_outputs: 1
  probe_hidden_size: 96
training:
  task_type: regression
  batch_size: 16
  num_epochs: 15
  lr: 1.0e-05
  weight_decay: 0.01
  patience: 3
  scheduler_factor: 0.5
  scheduler_patience: 2
  random_state: 42
  num_workers: 4
experiment:
  type: lm_probe
  tasks: complexity
  use_controls: false
  control_index: null
  num_controls: 3
  eval_on_orig_test: true
  cross_lingual: false
  task_type: regression
  feature: lang_norm_complexity_score
  training:
    patience: 5
    scheduler_patience: 4
    scheduler_factor: 0.8
    dropout: 0.1

[2025-04-29 17:50:41,039][__main__][INFO] - Normalized task: complexity
[2025-04-29 17:50:41,040][__main__][INFO] - Using explicit task_type from config: regression
[2025-04-29 17:50:41,040][__main__][INFO] - Determined Task Type: regression
[2025-04-29 17:50:41,044][__main__][INFO] - Running LM probe experiment for task 'complexity' (type: regression) on languages: ['en']
[2025-04-29 17:50:41,045][__main__][INFO] - Processing language: en
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-04-29 17:50:44,060][src.data.datasets][INFO] - Creating dataloaders for language: 'en', task: 'complexity', submetric: 'None'
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-04-29 17:50:47,214][src.data.datasets][INFO] - Successfully loaded tokenizer for cis-lmu/glot500-base
[2025-04-29 17:50:47,215][src.data.datasets][INFO] - Loading 'base' dataset for en language (train)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:50:47,326][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,371][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,582][src.data.datasets][INFO] - Filtered from 7460 to 1192 examples for language 'en'
[2025-04-29 17:50:47,597][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:50:47,598][src.data.datasets][INFO] - Loaded 1192 examples for en (train)
[2025-04-29 17:50:47,599][src.data.datasets][INFO] - Loading 'base' dataset for en language (validation)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:50:47,670][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,737][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,749][src.data.datasets][INFO] - Filtered from 441 to 72 examples for language 'en'
[2025-04-29 17:50:47,750][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:50:47,751][src.data.datasets][INFO] - Loaded 72 examples for en (validation)
[2025-04-29 17:50:47,751][src.data.datasets][INFO] - Loading 'base' dataset for en language (test)
Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
[2025-04-29 17:50:47,791][datasets.load][WARNING] - Using the latest cached version of the dataset since rokokot/question-type-and-complexity couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,897][datasets.packaged_modules.cache.cache][WARNING] - Found the latest cached dataset configuration 'base' at /data/leuven/371/vsc37132/qtype-eval/data/cache/rokokot___question-type-and-complexity/base/0.0.0/73f7e9fabe3af1c8a61564a268551f52ed221358 (last modified on Mon Apr  7 15:43:17 2025).
[2025-04-29 17:50:47,909][src.data.datasets][INFO] - Filtered from 719 to 110 examples for language 'en'
[2025-04-29 17:50:47,911][src.data.datasets][INFO] - Columns in dataset: ['unique_id', 'text', 'language', 'avg_links_len', 'avg_max_depth', 'avg_subordinate_chain_len', 'avg_verb_edges', 'lexical_density', 'n_tokens', 'question_type', 'complexity_score', 'lang_norm_complexity_score']
[2025-04-29 17:50:47,911][src.data.datasets][INFO] - Loaded 110 examples for en (test)
[2025-04-29 17:50:47,912][src.data.datasets][INFO] - Loaded datasets: train=1192, val=72, test=110 examples
[2025-04-29 17:50:47,913][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:50:47,913][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:50:47,913][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:50:47,913][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:50:47,913][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:50:47,914][src.data.datasets][INFO] -   Mean: 0.3875, Std: 0.1638
[2025-04-29 17:50:47,914][src.data.datasets][INFO] - Sample text: Did Nvidia skip the 800 series for graphics cards?...
[2025-04-29 17:50:47,914][src.data.datasets][INFO] - Sample label: 0.5150214433670044
[2025-04-29 17:50:47,914][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:50:47,914][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:50:47,914][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:50:47,915][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:50:47,915][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:50:47,915][src.data.datasets][INFO] -   Mean: 0.3150, Std: 0.2046
[2025-04-29 17:50:47,915][src.data.datasets][INFO] - Sample text: We just did a deal for the rest of the month for 1...
[2025-04-29 17:50:47,915][src.data.datasets][INFO] - Sample label: 0.8405253291130066
[2025-04-29 17:50:47,915][src.data.datasets][INFO] - Task 'complexity' is classification: False
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Getting feature name for task: 'complexity', submetric: 'None'
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Selected feature name: 'lang_norm_complexity_score' for task: 'complexity'
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Label statistics for complexity (feature: lang_norm_complexity_score):
[2025-04-29 17:50:47,916][src.data.datasets][INFO] -   Min: 0.0000, Max: 1.0000
[2025-04-29 17:50:47,916][src.data.datasets][INFO] -   Mean: 0.3955, Std: 0.1963
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Sample text: What is the problem?...
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Sample label: 0.03787878900766373
[2025-04-29 17:50:47,916][src.data.datasets][INFO] - Created datasets: train=1192, val=72, test=110
[2025-04-29 17:50:47,917][src.data.datasets][INFO] - Creating dataloaders with 4 workers
[2025-04-29 17:50:47,917][src.data.datasets][INFO] - Successfully created all dataloaders
[2025-04-29 17:50:47,918][src.models.model_factory][INFO] - Creating lm_probe model for regression task
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/data/leuven/371/vsc37132/miniconda3/envs/qtype-eval/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Some weights of XLMRobertaModel were not initialized from the model checkpoint at cis-lmu/glot500-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-04-29 17:50:53,846][src.models.model_factory][INFO] - Loaded model from local cache: cis-lmu/glot500-base
[2025-04-29 17:50:53,847][src.models.model_factory][INFO] - Language model parameters frozen
[2025-04-29 17:50:53,848][src.models.model_factory][INFO] - Created regression head with 1 outputs
[2025-04-29 17:50:53,848][src.models.model_factory][INFO] - layer-wise probing: True, layer index: 7
[2025-04-29 17:50:53,849][__main__][INFO] - Successfully created model for en
Epoch 1/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 1/15:   1%|▏         | 1/75 [00:00<01:03,  1.17it/s]Epoch 1/15:   4%|▍         | 3/75 [00:00<00:19,  3.79it/s]Epoch 1/15:   7%|▋         | 5/75 [00:01<00:10,  6.36it/s]Epoch 1/15:   9%|▉         | 7/75 [00:01<00:07,  8.75it/s]Epoch 1/15:  12%|█▏        | 9/75 [00:01<00:06, 10.83it/s]Epoch 1/15:  15%|█▍        | 11/75 [00:01<00:05, 12.56it/s]Epoch 1/15:  17%|█▋        | 13/75 [00:01<00:04, 13.93it/s]Epoch 1/15:  20%|██        | 15/75 [00:01<00:04, 14.99it/s]Epoch 1/15:  23%|██▎       | 17/75 [00:01<00:03, 15.79it/s]Epoch 1/15:  25%|██▌       | 19/75 [00:01<00:03, 16.38it/s]Epoch 1/15:  28%|██▊       | 21/75 [00:01<00:03, 16.80it/s]Epoch 1/15:  31%|███       | 23/75 [00:02<00:03, 17.11it/s]Epoch 1/15:  33%|███▎      | 25/75 [00:02<00:02, 17.31it/s]Epoch 1/15:  36%|███▌      | 27/75 [00:02<00:02, 17.47it/s]Epoch 1/15:  39%|███▊      | 29/75 [00:02<00:02, 17.58it/s]Epoch 1/15:  41%|████▏     | 31/75 [00:02<00:02, 17.66it/s]Epoch 1/15:  44%|████▍     | 33/75 [00:02<00:02, 17.71it/s]Epoch 1/15:  47%|████▋     | 35/75 [00:02<00:02, 17.75it/s]Epoch 1/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 1/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.79it/s]Epoch 1/15:  55%|█████▍    | 41/75 [00:03<00:01, 17.80it/s]Epoch 1/15:  57%|█████▋    | 43/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  60%|██████    | 45/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  63%|██████▎   | 47/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  65%|██████▌   | 49/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  71%|███████   | 53/75 [00:03<00:01, 17.82it/s]Epoch 1/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.84it/s]Epoch 1/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.81it/s]Epoch 1/15:  79%|███████▊  | 59/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  81%|████████▏ | 61/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  84%|████████▍ | 63/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  87%|████████▋ | 65/75 [00:04<00:00, 17.81it/s]Epoch 1/15:  89%|████████▉ | 67/75 [00:04<00:00, 17.82it/s]Epoch 1/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.83it/s]Epoch 1/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.85it/s]Epoch 1/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.85it/s]Epoch 1/15: 100%|██████████| 75/75 [00:05<00:00, 14.87it/s]
[2025-04-29 17:51:01,922][src.training.lm_trainer][INFO] - Epoch 1/15, Train Loss: 0.1080
[2025-04-29 17:51:02,354][src.training.lm_trainer][INFO] - Epoch 1/15, Val Loss: 0.0763, Metrics: {'mse': 0.08207093179225922, 'rmse': 0.28648024677499007, 'r2': -0.9610170125961304}
Epoch 2/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 2/15:   1%|▏         | 1/75 [00:00<00:20,  3.53it/s]Epoch 2/15:   4%|▍         | 3/75 [00:00<00:08,  8.67it/s]Epoch 2/15:   7%|▋         | 5/75 [00:00<00:05, 11.78it/s]Epoch 2/15:   9%|▉         | 7/75 [00:00<00:04, 13.77it/s]Epoch 2/15:  12%|█▏        | 9/75 [00:00<00:04, 15.06it/s]Epoch 2/15:  15%|█▍        | 11/75 [00:00<00:04, 15.90it/s]Epoch 2/15:  17%|█▋        | 13/75 [00:00<00:03, 16.49it/s]Epoch 2/15:  20%|██        | 15/75 [00:01<00:03, 16.90it/s]Epoch 2/15:  23%|██▎       | 17/75 [00:01<00:03, 17.17it/s]Epoch 2/15:  25%|██▌       | 19/75 [00:01<00:03, 17.36it/s]Epoch 2/15:  28%|██▊       | 21/75 [00:01<00:03, 17.50it/s]Epoch 2/15:  31%|███       | 23/75 [00:01<00:02, 17.61it/s]Epoch 2/15:  33%|███▎      | 25/75 [00:01<00:02, 17.66it/s]Epoch 2/15:  36%|███▌      | 27/75 [00:01<00:02, 17.72it/s]Epoch 2/15:  39%|███▊      | 29/75 [00:01<00:02, 17.74it/s]Epoch 2/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 2/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 2/15:  47%|████▋     | 35/75 [00:02<00:02, 17.78it/s]Epoch 2/15:  49%|████▉     | 37/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.80it/s]Epoch 2/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.81it/s]Epoch 2/15:  60%|██████    | 45/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.80it/s]Epoch 2/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.82it/s]Epoch 2/15:  71%|███████   | 53/75 [00:03<00:01, 17.83it/s]Epoch 2/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.83it/s]Epoch 2/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.82it/s]Epoch 2/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.82it/s]Epoch 2/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.83it/s]Epoch 2/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.81it/s]Epoch 2/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.81it/s]Epoch 2/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.83it/s]Epoch 2/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.83it/s]Epoch 2/15: 100%|██████████| 75/75 [00:04<00:00, 16.74it/s]
[2025-04-29 17:51:07,424][src.training.lm_trainer][INFO] - Epoch 2/15, Train Loss: 0.0965
[2025-04-29 17:51:07,869][src.training.lm_trainer][INFO] - Epoch 2/15, Val Loss: 0.0692, Metrics: {'mse': 0.07456759363412857, 'rmse': 0.27307067516327815, 'r2': -0.7817310094833374}
Epoch 3/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 3/15:   1%|▏         | 1/75 [00:00<00:14,  5.06it/s]Epoch 3/15:   4%|▍         | 3/75 [00:00<00:06, 10.74it/s]Epoch 3/15:   7%|▋         | 5/75 [00:00<00:05, 13.50it/s]Epoch 3/15:   9%|▉         | 7/75 [00:00<00:04, 15.04it/s]Epoch 3/15:  12%|█▏        | 9/75 [00:00<00:04, 15.98it/s]Epoch 3/15:  15%|█▍        | 11/75 [00:00<00:03, 16.57it/s]Epoch 3/15:  17%|█▋        | 13/75 [00:00<00:03, 16.97it/s]Epoch 3/15:  20%|██        | 15/75 [00:00<00:03, 17.24it/s]Epoch 3/15:  23%|██▎       | 17/75 [00:01<00:03, 17.41it/s]Epoch 3/15:  25%|██▌       | 19/75 [00:01<00:03, 17.53it/s]Epoch 3/15:  28%|██▊       | 21/75 [00:01<00:03, 17.62it/s]Epoch 3/15:  31%|███       | 23/75 [00:01<00:02, 17.67it/s]Epoch 3/15:  33%|███▎      | 25/75 [00:01<00:02, 17.72it/s]Epoch 3/15:  36%|███▌      | 27/75 [00:01<00:02, 17.74it/s]Epoch 3/15:  39%|███▊      | 29/75 [00:01<00:02, 17.76it/s]Epoch 3/15:  41%|████▏     | 31/75 [00:01<00:02, 17.77it/s]Epoch 3/15:  44%|████▍     | 33/75 [00:01<00:02, 17.78it/s]Epoch 3/15:  47%|████▋     | 35/75 [00:02<00:02, 17.78it/s]Epoch 3/15:  49%|████▉     | 37/75 [00:02<00:02, 17.79it/s]Epoch 3/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.79it/s]Epoch 3/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.80it/s]Epoch 3/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 3/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 3/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.77it/s]Epoch 3/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.78it/s]Epoch 3/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.79it/s]Epoch 3/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.78it/s]Epoch 3/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 3/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 3/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.81it/s]Epoch 3/15: 100%|██████████| 75/75 [00:04<00:00, 17.08it/s]
[2025-04-29 17:51:13,103][src.training.lm_trainer][INFO] - Epoch 3/15, Train Loss: 0.0861
[2025-04-29 17:51:13,622][src.training.lm_trainer][INFO] - Epoch 3/15, Val Loss: 0.0627, Metrics: {'mse': 0.06757977604866028, 'rmse': 0.25996110487659546, 'r2': -0.6147627830505371}
Epoch 4/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 4/15:   1%|▏         | 1/75 [00:00<00:16,  4.40it/s]Epoch 4/15:   4%|▍         | 3/75 [00:00<00:07,  9.93it/s]Epoch 4/15:   7%|▋         | 5/75 [00:00<00:05, 12.85it/s]Epoch 4/15:   9%|▉         | 7/75 [00:00<00:04, 14.56it/s]Epoch 4/15:  12%|█▏        | 9/75 [00:00<00:04, 15.63it/s]Epoch 4/15:  15%|█▍        | 11/75 [00:00<00:03, 16.32it/s]Epoch 4/15:  17%|█▋        | 13/75 [00:00<00:03, 16.78it/s]Epoch 4/15:  20%|██        | 15/75 [00:01<00:03, 17.08it/s]Epoch 4/15:  23%|██▎       | 17/75 [00:01<00:03, 17.30it/s]Epoch 4/15:  25%|██▌       | 19/75 [00:01<00:03, 17.46it/s]Epoch 4/15:  28%|██▊       | 21/75 [00:01<00:03, 17.56it/s]Epoch 4/15:  31%|███       | 23/75 [00:01<00:02, 17.63it/s]Epoch 4/15:  33%|███▎      | 25/75 [00:01<00:02, 17.68it/s]Epoch 4/15:  36%|███▌      | 27/75 [00:01<00:02, 17.71it/s]Epoch 4/15:  39%|███▊      | 29/75 [00:01<00:02, 17.73it/s]Epoch 4/15:  41%|████▏     | 31/75 [00:01<00:02, 17.75it/s]Epoch 4/15:  44%|████▍     | 33/75 [00:02<00:02, 17.76it/s]Epoch 4/15:  47%|████▋     | 35/75 [00:02<00:02, 17.77it/s]Epoch 4/15:  49%|████▉     | 37/75 [00:02<00:02, 17.77it/s]Epoch 4/15:  52%|█████▏    | 39/75 [00:02<00:02, 17.78it/s]Epoch 4/15:  55%|█████▍    | 41/75 [00:02<00:01, 17.78it/s]Epoch 4/15:  57%|█████▋    | 43/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  60%|██████    | 45/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  63%|██████▎   | 47/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  65%|██████▌   | 49/75 [00:02<00:01, 17.79it/s]Epoch 4/15:  68%|██████▊   | 51/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  71%|███████   | 53/75 [00:03<00:01, 17.78it/s]Epoch 4/15:  73%|███████▎  | 55/75 [00:03<00:01, 17.79it/s]Epoch 4/15:  76%|███████▌  | 57/75 [00:03<00:01, 17.80it/s]Epoch 4/15:  79%|███████▊  | 59/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  81%|████████▏ | 61/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  84%|████████▍ | 63/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  87%|████████▋ | 65/75 [00:03<00:00, 17.80it/s]Epoch 4/15:  89%|████████▉ | 67/75 [00:03<00:00, 17.79it/s]Epoch 4/15:  92%|█████████▏| 69/75 [00:04<00:00, 17.79it/s]Epoch 4/15:  95%|█████████▍| 71/75 [00:04<00:00, 17.80it/s]Epoch 4/15:  97%|█████████▋| 73/75 [00:04<00:00, 17.80it/s]Epoch 4/15: 100%|██████████| 75/75 [00:04<00:00, 16.90it/s]
[2025-04-29 17:51:18,627][src.training.lm_trainer][INFO] - Epoch 4/15, Train Loss: 0.0766
[2025-04-29 17:51:19,093][src.training.lm_trainer][INFO] - Epoch 4/15, Val Loss: 0.0568, Metrics: {'mse': 0.06125050038099289, 'rmse': 0.2474883843354934, 'r2': -0.4635300636291504}
Epoch 5/15:   0%|          | 0/75 [00:00<?, ?it/s]Epoch 5/15:   1%|▏         | 1/75 [00:00<00:16,  4.50it/s]Epoch 5/15:   4%|▍         | 3/75 [00:00<00:07, 10.04it/s]Epoch 5/15:   7%|▋         | 5/75 [00:00<00:05, 12.94it/s]Epoch 5/15:   9%|▉         | 7/75 [00:00<00:04, 14.64it/s]Epoch 5/15:  12%|█▏        | 9/75 [00:00<00:04, 15.67it/s]Epoch 5/15:  15%|█▍        | 11/75 [00:00<00:03, 16.35it/s]slurmstepd: error: *** JOB 58113467 ON r22g41 CANCELLED AT 2025-04-29T17:51:20 ***
