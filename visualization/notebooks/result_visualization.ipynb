{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604a83f1",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8911bf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfadcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/Research/qtype-eval/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c4d90",
   "metadata": {},
   "source": [
    "### dataset table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c4c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language  Questions  Polar (%)  Content (%)  Avg. Complexity\n",
      "    Arabic        995       49.9         50.1             1.50\n",
      "   English       1192       50.0         50.0             1.60\n",
      "   Finnish       1195       50.0         50.0             1.37\n",
      "Indonesian        954       47.9         52.1             1.86\n",
      "  Japanese       1191       50.0         50.0             1.60\n",
      "    Korean        739       46.1         53.9             1.97\n",
      "   Russian       1194       50.0         50.0             1.76\n",
      "    Arabic         44       45.5         54.5             1.73\n",
      "   English         72       50.0         50.0             1.74\n",
      "   Finnish         63       47.6         52.4             1.64\n",
      "Indonesian         72       50.0         50.0             2.01\n",
      "  Japanese         46       52.2         47.8             1.71\n",
      "    Korean         72       50.0         50.0             2.05\n",
      "   Russian         72       50.0         50.0             1.83\n",
      "    Arabic         77       28.6         71.4             2.04\n",
      "   English        110       50.0         50.0             1.61\n",
      "   Finnish        110       50.0         50.0             1.58\n",
      "Indonesian        110       50.0         50.0             1.91\n",
      "  Japanese         92       59.8         40.2             2.38\n",
      "    Korean        110       50.0         50.0             2.00\n",
      "   Russian        110       50.0         50.0             1.74\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"rokokot/question-type-and-complexity\", name=\"base\", split=\"train\")\n",
    "lang_map = {'ar': 'Arabic', 'en': 'English', 'fi': 'Finnish','id': 'Indonesian', 'ja': 'Japanese','ko': 'Korean', 'ru': 'Russian'}\n",
    "\n",
    "splits = ['train', 'validation', 'test']\n",
    "all_results = []\n",
    "\n",
    "for split in splits:\n",
    "  dataset = load_dataset('rokokot/question-type-and-complexity', name='base', split=split)\n",
    "  \n",
    "  for lang in list(lang_map.keys()):\n",
    "    lang_data = dataset.filter(lambda x: x['language'] == lang)\n",
    "\n",
    "    n_questions = len(lang_data)\n",
    "\n",
    "    question_types = lang_data['question_type']\n",
    "\n",
    "    polar_count = sum(1 for qt in question_types if qt == 1)\n",
    "    content_count = sum(1 for qt in question_types if qt == 0)\n",
    "\n",
    "    polar_pct = round((polar_count / n_questions) * 100, 1)\n",
    "    content_pct = round((content_count / n_questions) * 100, 1)\n",
    "\n",
    "    avg_complexity = round(np.mean(lang_data['complexity_score']), 2)\n",
    "\n",
    "    all_results.append({'Language': lang_map[lang],'Questions': n_questions,'Polar (%)': polar_pct,'Content (%)': content_pct,'Avg. Complexity': avg_complexity})\n",
    "stats_df = pd.DataFrame(all_results)\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 14698.16 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 17265.90 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 16705.33 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 16333.39 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 16168.38 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 14513.94 examples/s]\n",
      "Filter: 100%|██████████| 7460/7460 [00:00<00:00, 10511.51 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 8500.91 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 5911.36 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 6433.41 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 7682.32 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 8276.27 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 8150.38 examples/s]\n",
      "Filter: 100%|██████████| 441/441 [00:00<00:00, 5701.61 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 8135.78 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 7307.40 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 9115.82 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 7286.12 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 9901.71 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 9706.54 examples/s]\n",
      "Filter: 100%|██████████| 719/719 [00:00<00:00, 9611.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language  Dataset %  Polar %  Content %  Avg. Complexity\n",
      "    Arabic       12.9     48.3       51.7             1.55\n",
      "   English       15.9     50.0       50.0             1.61\n",
      "   Finnish       15.9     49.9       50.1             1.40\n",
      "Indonesian       13.2     48.2       51.8             1.88\n",
      "  Japanese       15.4     50.8       49.2             1.66\n",
      "    Korean       10.7     46.9       53.1             1.98\n",
      "   Russian       16.0     50.0       50.0             1.76\n"
     ]
    }
   ],
   "source": [
    "def analyze_averages():\n",
    "    splits = [\"train\", \"validation\", \"test\"]\n",
    "    lang_map = {\n",
    "        'ar': 'Arabic', 'en': 'English', 'fi': 'Finnish',\n",
    "        'id': 'Indonesian', 'ja': 'Japanese',\n",
    "        'ko': 'Korean', 'ru': 'Russian'\n",
    "    }\n",
    "    \n",
    "    combined_stats = {lang: {'Questions': 0, 'Polar': 0, 'Content': 0, 'Complexity': []} \n",
    "                     for lang in lang_map.values()}\n",
    "    \n",
    "    total_questions = 0\n",
    "\n",
    "    for split in splits:\n",
    "        try:\n",
    "            dataset = load_dataset(\"rokokot/question-type-and-complexity\", name=\"base\", split=split)\n",
    "            \n",
    "            for lang_code, lang_name in lang_map.items():\n",
    "                lang_data = dataset.filter(lambda x: x['language'] == lang_code)\n",
    "                \n",
    "                if len(lang_data) == 0:\n",
    "                    print(f\"No data for {lang_name} in {split} split\")\n",
    "                    continue\n",
    "                \n",
    "                combined_stats[lang_name]['Questions'] += len(lang_data)\n",
    "                total_questions += len(lang_data)\n",
    "                \n",
    "                question_types = lang_data['question_type']\n",
    "                polar_count = sum(1 for qt in question_types if qt == 1)\n",
    "                combined_stats[lang_name]['Polar'] += polar_count\n",
    "                combined_stats[lang_name]['Content'] += (len(lang_data) - polar_count)\n",
    "                \n",
    "                combined_stats[lang_name]['Complexity'].extend(lang_data['complexity_score'])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {split} split: {e}\")\n",
    "    \n",
    "    results = []\n",
    "    for lang_name, stats in combined_stats.items():\n",
    "        if stats['Questions'] > 0:\n",
    "            polar_pct = round((stats['Polar'] / stats['Questions']) * 100, 1)\n",
    "            content_pct = round((stats['Content'] / stats['Questions']) * 100, 1)\n",
    "            avg_complexity = round(np.mean(stats['Complexity']), 2) if stats['Complexity'] else 0\n",
    "            dataset_pct = round((stats['Questions'] / total_questions) * 100, 1)\n",
    "\n",
    "            results.append({'Language': lang_name,'Dataset %': dataset_pct,'Polar %': polar_pct,'Content %': content_pct,'Avg. Complexity': avg_complexity\n",
    "            })\n",
    "    \n",
    "    stats_df = pd.DataFrame(results)\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "stats_df = analyze_averages()\n",
    "print(stats_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ab784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d7468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
