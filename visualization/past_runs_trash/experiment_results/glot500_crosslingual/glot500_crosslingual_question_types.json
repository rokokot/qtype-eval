{
  "glot500_lm_probe_question_type_ar_to_en": {
    "train_time": 43.84733700752258,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 1.0020365715026855,
      "accuracy": 0.6272727272727273,
      "f1": 0.4057971014492754
    },
    "train_language": "ar",
    "eval_language": "en",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_en/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ar_to_fi": {
    "train_time": 40.9966561794281,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 0.5147396070616586,
      "accuracy": 0.8,
      "f1": 0.7708333333333334
    },
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_fi/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ar",
    "eval_language": "fi",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ar_to_ru": {
    "train_time": 40.925052881240845,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 0.29994025613580433,
      "accuracy": 0.9,
      "f1": 0.8888888888888888
    },
    "train_language": "ar",
    "eval_language": "ru",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_ru/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ar_to_id": {
    "train_time": 41.069549798965454,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 0.5462460219860077,
      "accuracy": 0.7272727272727273,
      "f1": 0.6341463414634146
    },
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_id/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ar",
    "eval_language": "id",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ar_to_ja": {
    "train_time": 41.103312492370605,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 1.2893106937408447,
      "accuracy": 0.40217391304347827,
      "f1": 0.0
    },
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_ja/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ar",
    "eval_language": "ja",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ar_to_ko": {
    "train_time": 41.08480644226074,
    "train_metrics": {
      "loss": 0.08110813879304463,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "val_metrics": {
      "loss": 0.17452879001696905,
      "accuracy": 0.9772727272727273,
      "f1": 0.975609756097561
    },
    "test_metrics": {
      "loss": 0.8298325538635254,
      "accuracy": 0.5272727272727272,
      "f1": 0.16129032258064516
    },
    "train_language": "ar",
    "eval_language": "ko",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ar_to_ko/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_ko": {
    "train_time": 48.811392307281494,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 0.5662694488252912,
      "accuracy": 0.6818181818181818,
      "f1": 0.7407407407407407
    },
    "train_language": "en",
    "eval_language": "ko",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_ko/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_ja": {
    "train_time": 48.856398582458496,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 0.512558380762736,
      "accuracy": 0.7608695652173914,
      "f1": 0.8307692307692308
    },
    "train_language": "en",
    "eval_language": "ja",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_ja/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_id": {
    "train_time": 48.2353310585022,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 0.6261037460395268,
      "accuracy": 0.7272727272727273,
      "f1": 0.7222222222222222
    },
    "train_language": "en",
    "eval_language": "id",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_id/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_fi": {
    "train_time": 48.60630393028259,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 0.5878466197422573,
      "accuracy": 0.7636363636363637,
      "f1": 0.8088235294117647
    },
    "train_language": "en",
    "eval_language": "fi",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_fi/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_ar": {
    "train_time": 48.97351098060608,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 1.0288172006607055,
      "accuracy": 0.6103896103896104,
      "f1": 0.5588235294117647
    },
    "train_language": "en",
    "eval_language": "ar",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_ar/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_en_to_ru": {
    "train_time": 48.8096399307251,
    "train_metrics": {
      "loss": 0.03224476995567481,
      "accuracy": 0.9983221476510067,
      "f1": 0.998324958123953
    },
    "val_metrics": {
      "loss": 0.15795647203922272,
      "accuracy": 0.9444444444444444,
      "f1": 0.9473684210526315
    },
    "test_metrics": {
      "loss": 0.3314152615410941,
      "accuracy": 0.9272727272727272,
      "f1": 0.9322033898305084
    },
    "train_language": "en",
    "eval_language": "ru",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/en_to_ru/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_fi_to_ar": {
    "train_time": 80.55924201011658,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.7170207798480988,
      "accuracy": 0.7142857142857143,
      "f1": 0.6071428571428571
    },
    "train_language": "fi",
    "eval_language": "ar",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_ar/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },

  "glot500_lm_probe_question_type_fi_to_ru": {
    "train_time": 80.5735936164856,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.15382439350443228,
      "accuracy": 0.9363636363636364,
      "f1": 0.9369369369369369
    },
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_ru/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "fi",
    "eval_language": "ru",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_fi_to_ja": {
    "train_time": 80.369802236557,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.7335958083470663,
      "accuracy": 0.6413043478260869,
      "f1": 0.6732673267326733
    },
    "train_language": "fi",
    "eval_language": "ja",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_ja/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_fi_to_en": {
    "train_time": 80.53640747070312,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.5786604753562382,
      "accuracy": 0.7818181818181819,
      "f1": 0.7551020408163265
    },
    "train_language": "fi",
    "eval_language": "en",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_en/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_fi_to_ko": {
    "train_time": 79.85687565803528,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.7401685885020665,
      "accuracy": 0.7,
      "f1": 0.6857142857142857
    },
    "train_language": "fi",
    "eval_language": "ko",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_ko/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_fi_to_id": {
    "train_time": 80.33954071998596,
    "train_metrics": {
      "loss": 0.027578933636347454,
      "accuracy": 0.9933054393305439,
      "f1": 0.9932659932659933
    },
    "val_metrics": {
      "loss": 0.10537567688152194,
      "accuracy": 0.9523809523809523,
      "f1": 0.9491525423728814
    },
    "test_metrics": {
      "loss": 0.6893862187862396,
      "accuracy": 0.7090909090909091,
      "f1": 0.6097560975609756
    },
    "train_language": "fi",
    "eval_language": "id",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/fi_to_id/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_ja": {
    "train_time": 66.50450348854065,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 1.339702844619751,
      "accuracy": 0.40217391304347827,
      "f1": 0.12698412698412698
    },
    "train_language": "id",
    "eval_language": "ja",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/id_to_ja/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_ko": {
    "train_time": 66.4979956150055,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 1.1154766593660628,
      "accuracy": 0.5272727272727272,
      "f1": 0.23529411764705882
    },
    "train_language": "id",
    "eval_language": "ko",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/id_to_ko/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_en": {
    "train_time": 66.31157302856445,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 0.7284641776766095,
      "accuracy": 0.7090909090909091,
      "f1": 0.6444444444444445
    },
    "train_language": "id",
    "eval_language": "en",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/id_to_en/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_fi": {
    "train_time": 66.41832637786865,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 0.4564064954008375,
      "accuracy": 0.7727272727272727,
      "f1": 0.7706422018348624
    },
    "source": "glot500",
    "file_path": "cross_lingual/id_to_fi/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "id",
    "eval_language": "fi",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_ru": {
    "train_time": 66.31608629226685,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 0.21647548143352782,
      "accuracy": 0.9363636363636364,
      "f1": 0.9369369369369369
    },
    "train_language": "id",
    "eval_language": "ru",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/id_to_ru/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_id_to_ar": {
    "train_time": 66.15184926986694,
    "train_metrics": {
      "loss": 0.07611492052674293,
      "accuracy": 0.9874213836477987,
      "f1": 0.9868995633187773
    },
    "val_metrics": {
      "loss": 0.3570680171251297,
      "accuracy": 0.8611111111111112,
      "f1": 0.84375
    },
    "test_metrics": {
      "loss": 0.6219689071178436,
      "accuracy": 0.8181818181818182,
      "f1": 0.7407407407407407
    },
    "train_language": "id",
    "eval_language": "ar",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/id_to_ar/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_ar": {
    "train_time": 80.63900804519653,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 1.5955212116241455,
      "accuracy": 0.5974025974025974,
      "f1": 0.5507246376811594
    },
    "train_language": "ja",
    "eval_language": "ar",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_ar/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_fi": {
    "train_time": 80.61751246452332,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 0.7758827081748417,
      "accuracy": 0.8090909090909091,
      "f1": 0.8372093023255814
    },
    "train_language": "ja",
    "eval_language": "fi",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_fi/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_id": {
    "train_time": 80.62530326843262,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 0.45249280812484877,
      "accuracy": 0.8454545454545455,
      "f1": 0.8349514563106796
    },
    "train_language": "ja",
    "eval_language": "id",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_id/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_ko": {
    "train_time": 80.58088850975037,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 0.3667069013629641,
      "accuracy": 0.8727272727272727,
      "f1": 0.8679245283018868
    },
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_ko/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ja",
    "eval_language": "ko",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_ru": {
    "train_time": 80.63089966773987,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 0.48225374839135576,
      "accuracy": 0.8909090909090909,
      "f1": 0.9
    },
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_ru/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ja",
    "eval_language": "ru",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ja_to_en": {
    "train_time": 80.78356432914734,
    "train_metrics": {
      "loss": 0.012304918933659792,
      "accuracy": 0.9974811083123426,
      "f1": 0.9974768713204374
    },
    "val_metrics": {
      "loss": 0.005798588196436564,
      "accuracy": 1.0,
      "f1": 1.0
    },
    "test_metrics": {
      "loss": 0.3075958128486361,
      "accuracy": 0.9181818181818182,
      "f1": 0.9243697478991597
    },
    "source": "glot500",
    "file_path": "cross_lingual/ja_to_en/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ja",
    "eval_language": "en",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_ja": {
    "train_time": 54.28812789916992,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 0.3090060396740834,
      "accuracy": 0.9130434782608695,
      "f1": 0.9322033898305084
    },
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_ja/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ko",
    "eval_language": "ja",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_ru": {
    "train_time": 54.333086252212524,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 0.31826252170971464,
      "accuracy": 0.9545454545454546,
      "f1": 0.954954954954955
    },
    "train_language": "ko",
    "eval_language": "ru",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_ru/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_id": {
    "train_time": 54.67871427536011,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 0.41090482686247143,
      "accuracy": 0.8272727272727273,
      "f1": 0.8118811881188119
    },
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_id/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ko",
    "eval_language": "id",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_ar": {
    "train_time": 54.81186604499817,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 1.1958653926849365,
      "accuracy": 0.6233766233766234,
      "f1": 0.6027397260273972
    },
    "train_language": "ko",
    "eval_language": "ar",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_ar/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_fi": {
    "train_time": 54.32855248451233,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 0.34821154177188873,
      "accuracy": 0.8636363636363636,
      "f1": 0.8760330578512396
    },
    "train_language": "ko",
    "eval_language": "fi",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_fi/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ko_to_en": {
    "train_time": 54.3340048789978,
    "train_metrics": {
      "loss": 0.04159602257324026,
      "accuracy": 0.9972936400541272,
      "f1": 0.9970588235294118
    },
    "val_metrics": {
      "loss": 0.14360330924391745,
      "accuracy": 0.9444444444444444,
      "f1": 0.9444444444444444
    },
    "test_metrics": {
      "loss": 0.1173280126282147,
      "accuracy": 0.9727272727272728,
      "f1": 0.9734513274336283
    },
    "train_language": "ko",
    "eval_language": "en",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ko_to_en/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_fi": {
    "train_time": 48.80114197731018,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 0.4886584665094103,
      "accuracy": 0.7818181818181819,
      "f1": 0.8125
    },
    "train_language": "ru",
    "eval_language": "fi",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_fi/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_ja": {
    "train_time": 48.78376793861389,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 0.6598255882660548,
      "accuracy": 0.7391304347826086,
      "f1": 0.8181818181818182
    },
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_ja/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ru",
    "eval_language": "ja",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_id": {
    "train_time": 48.697012186050415,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 0.44653514666216715,
      "accuracy": 0.8454545454545455,
      "f1": 0.8571428571428571
    },
    "train_language": "ru",
    "eval_language": "id",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_id/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_ar": {
    "train_time": 48.57138657569885,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 1.164474904537201,
      "accuracy": 0.5064935064935064,
      "f1": 0.4864864864864865
    },
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_ar/question_type/results.json",
    "model_type": "lm_probe",
    "train_language": "ru",
    "eval_language": "ar",
    "task": "question_type",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_ko": {
    "train_time": 49.078227043151855,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 0.9155710254396711,
      "accuracy": 0.5818181818181818,
      "f1": 0.6973684210526315
    },
    "train_language": "ru",
    "eval_language": "ko",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_ko/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  },
  "glot500_lm_probe_question_type_ru_to_en": {
    "train_time": 48.60905647277832,
    "train_metrics": {
      "loss": 0.13519096185763677,
      "accuracy": 0.974036850921273,
      "f1": 0.9739714525608733
    },
    "val_metrics": {
      "loss": 0.2806080937385559,
      "accuracy": 0.8888888888888888,
      "f1": 0.8947368421052632
    },
    "test_metrics": {
      "loss": 0.27950021411691395,
      "accuracy": 0.9272727272727272,
      "f1": 0.9322033898305084
    },
    "train_language": "ru",
    "eval_language": "en",
    "task": "question_type",
    "task_type": "classification",
    "model_type": "lm_probe",
    "source": "glot500",
    "file_path": "cross_lingual/ru_to_en/question_type/cross_lingual_results.json",
    "experiment_type": "cross_lingual"
  }

}
